{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsarpongstreetor/2DayCourse/blob/master/letgo2ipynb_reward_calculations1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4i_dlI0pJgrt"
      },
      "id": "4i_dlI0pJgrt"
    },
    {
      "cell_type": "markdown",
      "id": "20326118",
      "metadata": {
        "id": "20326118"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2422f32f",
      "metadata": {
        "id": "2422f32f"
      },
      "source": [
        "## Install BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8b10fd32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b10fd32",
        "outputId": "0ac87f40-5777-4747-9dc6-db7f8249a3dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BenchMARL'...\n",
            "remote: Enumerating objects: 2342, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 2342 (delta 38), reused 42 (delta 20), pack-reused 2267 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2342/2342), 525.91 KiB | 8.48 MiB/s, done.\n",
            "Resolving deltas: 100% (1471/1471), done.\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!git clone https://github.com/facebookresearch/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6cd7b69b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cd7b69b",
        "outputId": "10c69067-29fc-4958-f569-eee94508d07d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BenchMARL\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "%cd /content/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4f32b88e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4f32b88e",
        "outputId": "444023fb-30b2-4bb1-905a-244d967e0187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0 torchvision-0.21.0 triton-3.2.0\n",
            "Obtaining file:///content/BenchMARL\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchrl~=0.7.0 (from benchmarl==1.4.0)\n",
            "  Downloading torchrl-0.7.1-cp311-cp311-manylinux1_x86_64.whl.metadata (39 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (4.67.1)\n",
            "Collecting hydra-core (from benchmarl==1.4.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (0.21.0)\n",
            "Collecting av<14 (from benchmarl==1.4.0)\n",
            "  Downloading av-13.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (3.1.1)\n",
            "Collecting tensordict>=0.7.0 (from torchrl~=0.7.0->benchmarl==1.4.0)\n",
            "  Downloading tensordict-0.7.1-cp311-cp311-manylinux1_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core->benchmarl==1.4.0)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core->benchmarl==1.4.0)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->benchmarl==1.4.0) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core->benchmarl==1.4.0) (6.0.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.7.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.10.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.0.2)\n",
            "Downloading av-13.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.0/34.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchrl-0.7.1-cp311-cp311-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensordict-0.7.1-cp311-cp311-manylinux1_x86_64.whl (399 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: benchmarl, antlr4-python3-runtime\n",
            "  Building editable for benchmarl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benchmarl: filename=benchmarl-1.4.0-0.editable-py3-none-any.whl size=3797 sha256=7893b3711c317b7f82056ce82f399f57468df9b886fd8f663240798fae9e20d9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7md7p246/wheels/d1/dc/58/2f83c40b8458f8cd6be0bee519061fa93523762dfc8aad5e9b\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=3948464933b37ab65926cde525844c5182f78d1eccbbe0ed5e06829726a4dfc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built benchmarl antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf, av, hydra-core, tensordict, torchrl, benchmarl\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 av-13.1.0 benchmarl-1.4.0 hydra-core-1.3.2 omegaconf-2.3.0 tensordict-0.7.1 torchrl-0.7.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "dc6e7e7cccf447c090c0aecad280ecce"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title\n",
        "!pip install -U torch torchvision\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "585d3a35",
      "metadata": {
        "id": "585d3a35"
      },
      "source": [
        "## Install VMAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d2e551b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2e551b1",
        "outputId": "22548abb-86cf-4073-ffa0-6728695ad109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vmas in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vmas) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from vmas) (2.6.0)\n",
            "Requirement already satisfied: pyglet<=1.5.27 in /usr/local/lib/python3.11/dist-packages (from vmas) (1.5.27)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (from vmas) (0.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from vmas) (1.17.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym->vmas) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym->vmas) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->vmas) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->vmas) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!pip install vmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "33d72783",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33d72783",
        "outputId": "d7c273e7-cf08-4266-9790-b4683d49627d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,317 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,692 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,661 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,610 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,939 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n",
            "Fetched 389 kB in 6s (59.9 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libfontenc1 libglu1-mesa libxfont2 libxkbfile1 libxtst6 libxxf86dga1 x11-xkb-utils\n",
            "  xfonts-base xfonts-encodings xfonts-utils xserver-common\n",
            "Suggested packages:\n",
            "  libgle3 python3-numpy mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libfontenc1 libglu1-mesa libxfont2 libxkbfile1 libxtst6 libxxf86dga1 python3-opengl\n",
            "  x11-utils x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 15 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 8,871 kB of archives.\n",
            "After this operation, 20.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-opengl all 3.1.5+dfsg-1 [605 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.12 [864 kB]\n",
            "Fetched 8,871 kB in 1s (6,845 kB/s)\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../00-freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../01-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../02-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../03-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../04-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../05-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../06-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package python3-opengl.\n",
            "Preparing to unpack .../07-python3-opengl_3.1.5+dfsg-1_all.deb ...\n",
            "Unpacking python3-opengl (3.1.5+dfsg-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../08-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../09-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../10-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../11-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../12-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../13-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../14-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up python3-opengl (3.1.5+dfsg-1) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x783dac64f110>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#@title\n",
        "!apt-get update\n",
        "!apt-get install -y x11-utils python3-opengl xvfb\n",
        "!pip install pyvirtualdisplay\n",
        "import pyvirtualdisplay\n",
        "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install torch\n",
        "!pip install torchrl\n",
        "!pip install  tensorboard\n",
        "!pip install wandb\n",
        "!pip install TensorDict\n",
        "!pip install pyyaml\n",
        "!pip install torch_geometric\n",
        "!apt-get install python3-opengl\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-yMWldyWGMO",
        "outputId": "a702a4b2-a0aa-4b05-9a34-7cde1fda01c9"
      },
      "id": "l-yMWldyWGMO",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.11/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchrl) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl) (3.1.1)\n",
            "Requirement already satisfied: tensordict>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from torchrl) (0.7.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.7.0->torchrl) (3.10.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->torchrl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->torchrl) (3.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: TensorDict in /usr/local/lib/python3.11/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from TensorDict) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from TensorDict) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from TensorDict) (3.1.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from TensorDict) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from TensorDict) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->TensorDict) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->TensorDict) (3.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-opengl is already the newest version (3.1.5+dfsg-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install BenchMARL\n",
        "!git clone https://github.com/facebookresearch/BenchMARL\n",
        "%cd /content/BenchMARL # Navigate into the BenchMARL directory\n",
        "!pip install -e BenchMARL  # Install the package in editable mode\n",
        "%cd /content #Navigate back to original directory\n"
      ],
      "metadata": {
        "id": "qveXPf2YcdSW"
      },
      "id": "qveXPf2YcdSW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find / -name \"anfuelpriceenv\" -type d -exec rm -rf {} +"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu7z3s4rdOH4",
        "outputId": "01820d8e-ecae-4326-c261-fab81b3ec15c"
      },
      "id": "mu7z3s4rdOH4",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find: ‘/proc/74/task/74/net’: Invalid argument\n",
            "find: ‘/proc/74/net’: Invalid argument\n",
            "find: ‘/proc/5662/task/5662/net’: Invalid argument\n",
            "find: ‘/proc/5662/net’: Invalid argument\n",
            "find: ‘/proc/6133/task/6133/net’: Invalid argument\n",
            "find: ‘/proc/6133/net’: Invalid argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install custom environment package\n",
        "!git clone https://github.com/rsarpongstreetor/anfuelpriceenv\n",
        "%cd anfuelpriceenv # Navigate to the anfuelpriceenv directory\n",
        "!touch __init__.py # Create __init__.py\n",
        "%cd .. # Navigate back to the previous directory\n",
        "!pip install -e anfuelpriceenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBfAjCWvdMnu",
        "outputId": "f7731d9f-2bd4-416d-910d-ab1406c28416"
      },
      "id": "QBfAjCWvdMnu",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'anfuelpriceenv' already exists and is not an empty directory.\n",
            "[Errno 2] No such file or directory: 'anfuelpriceenv # Navigate to the anfuelpriceenv directory'\n",
            "/content\n",
            "[Errno 2] No such file or directory: '.. # Navigate back to the previous directory'\n",
            "/content\n",
            "Obtaining file:///content/anfuelpriceenv\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (2.6.0)\n",
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: tensordict in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->AnFuelpriceEnv==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->AnFuelpriceEnv==0.1.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->AnFuelpriceEnv==0.1.0) (2025.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tensordict->AnFuelpriceEnv==0.1.0) (3.1.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict->AnFuelpriceEnv==0.1.0) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensordict->AnFuelpriceEnv==0.1.0) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->AnFuelpriceEnv==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->AnFuelpriceEnv==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->AnFuelpriceEnv==0.1.0) (3.0.2)\n",
            "Installing collected packages: AnFuelpriceEnv\n",
            "  Attempting uninstall: AnFuelpriceEnv\n",
            "    Found existing installation: AnFuelpriceEnv 0.1.0\n",
            "    Uninstalling AnFuelpriceEnv-0.1.0:\n",
            "      Successfully uninstalled AnFuelpriceEnv-0.1.0\n",
            "  Running setup.py develop for AnFuelpriceEnv\n",
            "Successfully installed AnFuelpriceEnv-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyvirtualdisplay\n",
        "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "display.start()\n",
        "# %%\n",
        "import pyvirtualdisplay\n",
        "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "display.start()\n",
        "import multiprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import NormalParamExtractor\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.envs import (Compose, DoubleToFloat, ObservationNorm, StepCounter, TransformedEnv)\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type, step_mdp\n",
        "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from tqdm import tqdm\n",
        "import google.colab\n",
        "import pygame\n",
        "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
        "import random\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "import plotly.express as px\n",
        "import pandas\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "from google.colab import drive\n",
        "google.colab.drive.mount('/content/drive')\n",
        "from collections import defaultdict\n",
        "from typing import Optional, Any, Dict, List, Union, TypedDict\n",
        "import torchrl\n",
        "import numpy as np\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "from torchrl.modules import MultiAgentConvNet\n",
        "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec, DiscreteTensorSpec\n",
        "from torchrl.envs import (\n",
        "    CatTensors,\n",
        "    EnvBase,\n",
        "    Transform,\n",
        "    TransformedEnv,\n",
        "    UnsqueezeTransform,\n",
        ")\n",
        "\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "import tensordict as td\n",
        "import yaml # Import the yaml library for loading YAML files\n",
        "from benchmarl.algorithms import MappoConfig\n",
        "from benchmarl.environments import VmasTask # Import VmasTask instead of CustomEnvTask\n",
        "from benchmarl.experiment import Experiment, ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30FNjZrog_df",
        "outputId": "9e6303e8-1c85-4b79-b91f-f98ff3f5dadc"
      },
      "id": "30FNjZrog_df",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.6.1 (SDL 2.28.4, Python 3.11.11)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Assuming you are in the main project directory\n",
        "file_path = 'anfuelpriceenv/task_1.yaml'\n",
        "\n",
        "# Open and load the YAML file\n",
        "with open(file_path, 'r') as file:\n",
        "    task_1_data = yaml.safe_load(file)\n",
        "\n",
        "# Access the data (e.g., printing it)\n",
        "print(task_1_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBpjjwyzh04h",
        "outputId": "ff696407-fea6-46be-c785-0e25d36965d3"
      },
      "id": "YBpjjwyzh04h",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'defaults': [None, '_self_'], 'max_steps': 100, 'supports_continuous_actions': True, 'supports_discrete_actions': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CustomEnvTask"
      ],
      "metadata": {
        "id": "AjcEWkuLiQKu"
      },
      "id": "AjcEWkuLiQKu"
    },
    {
      "source": [
        "from benchmarl.models import SequenceModelConfig, GnnConfig, MlpConfig\n",
        "from benchmarl.algorithms import IppoConfig, MappoConfig, QmixConfig, MasacConfig\n",
        "from typing import Callable, Dict, List, Optional\n",
        "\n",
        "from benchmarl.environments.common import Task\n",
        "from benchmarl.utils import DEVICE_TYPING\n",
        "\n",
        "from tensordict import TensorDictBase\n",
        "from torchrl.data import CompositeSpec, DiscreteTensorSpec, TensorSpec, UnboundedContinuousTensorSpec\n",
        "from torchrl.envs import EnvBase\n",
        "from anfuelpriceenv.AnFuelpriceEnv import AnFuelpriceEnv\n",
        "# from benchmarl.environments.customenv.common import CustomEnvTask\n",
        "# from benchmarl.task.customenv import task_1\n",
        "import yaml  # Import the yaml module\n",
        "\n",
        "\n",
        "# AnFuelpriceEnv =AnFuelpriceEnv ()\n",
        "\n",
        "class CustomEnvTask(Task):\n",
        "    # Your task names.\n",
        "    # Their config will be loaded from conf/task/customenv\n",
        "\n",
        "    TASK_1 = None  # Loaded automatically from conf/task/customenv/task_1\n",
        "    TASK_2 = None  # Loaded automatically from conf/task/customenv/task_2\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)  # Initialize the parent class\n",
        "\n",
        "        # Ensure self.config is a dictionary; load from YAML if necessary\n",
        "        if self.config is None:\n",
        "            with open(f\"anfuelpriceenv/{self.name.lower()}.yaml\", 'r') as file:\n",
        "                self.config = yaml.safe_load(file)\n",
        "        elif not isinstance(self.config, dict):\n",
        "            self.config = {}\n",
        "\n",
        "    def get_env_fun( self,num_envs: int, continuous_actions: bool, seed: Optional[int], device: DEVICE_TYPING,) -> Callable[[], EnvBase]:\n",
        "        return lambda: AnFuelpriceEnv(\n",
        "            scenario=self.name.lower(),\n",
        "            # num_envs=num_envs,  # Number of vectorized envs (do not use this param if the env is not vectorized)\n",
        "            continuous_actions=continuous_actions,  # Ignore this param if your env does not have this choice\n",
        "            seed=seed,\n",
        "            device=device,\n",
        "            categorical_actions=True,  # If your env has discrete actions, they need to be categorical (TorchRL can help with this)\n",
        "            **self.config,  # Pass the loaded config (this is what is in your yaml\n",
        "        )\n",
        "\n",
        "    def supports_continuous_actions(self) -> bool:\n",
        "        # Does the environment support continuous actions?\n",
        "        return True\n",
        "\n",
        "    def supports_discrete_actions(self) -> bool:\n",
        "        # Does the environment support discrete actions?\n",
        "        return True\n",
        "\n",
        "    def has_render(self, env: EnvBase) -> bool:\n",
        "        # Does the env have a env.render(mode=\"rgb_array\") or env.render() function?\n",
        "        return True\n",
        "\n",
        "    def max_steps(self, env: EnvBase) -> int:\n",
        "        # Maximum number of steps for a rollout during evaluation\n",
        "        return 100\n",
        "\n",
        "    def group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "       # The group map mapping group names to agent names\n",
        "        # The data in the tensordict will havebe presented this way\n",
        "        # Access agent names from dictionary keys if env.agents is a dictionary\n",
        "        \"\"\" if hasattr(env, 'n_agents'):\n",
        "            return {\"agents\": list(range(env.n_agents))}  # Changed to a list of agent indices\n",
        "        elif isinstance(env.agents, dict):\n",
        "            return {\"agents\": list(env.agents.keys())}  # Get keys from dictionary if it's a dictionary\n",
        "        elif hasattr(env, 'possible_agents'):  # Check if 'possible_agents' exists\n",
        "            return {\"agents\": env.possible_agents}  # Use 'possible_agents' if available\n",
        "        else:  # Fallback if neither condition is met\n",
        "            return {\"agents\": [agent.name for agent in env.agents]}  # This is unlikely to happen, but here as a fallback\"\"\"\n",
        "        return {\"agents\": [agent[\"name\"] for agent in env.agents]}  # This is unlikely to happen, but here as a fallback\n",
        "\n",
        "        \"\"\" def observation_spec(self, env: EnvBase) -> CompositeSpec:\n",
        "        \"Get the observation spec for a single agent.\"\"\n",
        "        agent_obs_spec = env.observation_spec[\"agents\"][\"observation\"][\"observat\"]  # Accessing \"observat\" directly\n",
        "        agent_pos_spec = env.observation_spec[\"agents\"][\"observation\"][\"position_key\"]  # Accessing \"position_key\" (Date)\n",
        "\n",
        "        # Assuming your observation space is continuous and bounded:\n",
        "        if isinstance(agent_obs_spec, BoundedTensorSpec) and isinstance(agent_pos_spec, BoundedTensorSpec):\n",
        "            return CompositeSpec(\n",
        "                agents=CompositeSpec(\n",
        "                    observation=CompositeSpec(\n",
        "                        observat=agent_obs_spec,\n",
        "                        position_key=agent_pos_spec\n",
        "                    ),\n",
        "                )\n",
        "            )\n",
        "        # If it's DiscreteTensorSpec (unlikely for both, but handling for completeness):\n",
        "        elif isinstance(agent_obs_spec, DiscreteTensorSpec) and isinstance(agent_pos_spec, DiscreteTensorSpec):\n",
        "            return CompositeSpec(\n",
        "                agents=CompositeSpec(\n",
        "                    observation=CompositeSpec(\n",
        "                        observat=agent_obs_spec,\n",
        "                        position_key=agent_pos_spec\n",
        "                    ),\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            # Handle other cases or raise an error if unexpected type\n",
        "            raise TypeError(f\"Unexpected type for agent_obs_spec or agent_pos_spec: {type(agent_obs_spec)}, {type(agent_pos_spec)}\")\n",
        "\n",
        "\n",
        "        agent_obs_spec = env.observation_spec[\"agents\"][\"observation\"][\"observat\"]  # Accessing \"observat\" directly\n",
        "\n",
        "\n",
        "        # Assuming \"observation\" is a key within agent_obs_spec that holds the actual spec\n",
        "        # Navigate to the relevant BoundedTensorSpec or BoundedContinuous\n",
        "        if isinstance(agent_obs_spec, CompositeSpec) and \"observation\" in agent_obs_spec:\n",
        "            agent_obs_spec = agent_obs_spec[\"observation\"]\n",
        "        if isinstance(agent_obs_spec, CompositeSpec):\n",
        "            agent_obs_spec = agent_obs_spec[list(agent_obs_spec.keys())[0]]\n",
        "\n",
        "        # Get the observation space\n",
        "        observation_space = agent_obs_spec.space\n",
        "\n",
        "\n",
        "      # Check if observation space has 'low' and 'high' attribute\n",
        "        if hasattr(observation_space, 'low') and hasattr(observation_space, 'high'):\n",
        "          low_bound = observation_space.low\n",
        "          high_bound = observation_space.high\n",
        "\n",
        "            # Ensure low_bound and high_bound have the same shape\n",
        "          if low_bound.shape != high_bound.shape:\n",
        "            raise ValueError(\"low_bound and high_bound must have the same shape.\")\n",
        "            # **Change here: Use the shape of low_bound or high_bound directly**\n",
        "            shape = low_bound.shape  # or high_bound.shape\n",
        "          else:\n",
        "                return CompositeSpec(\n",
        "                            agents=CompositeSpec(\n",
        "                                observation=BoundedTensorSpec(\n",
        "                                    low=low_bound,\n",
        "                                    high=high_bound,\n",
        "                                    dtype=agent_obs_spec.dtype,\n",
        "                                    device=env.device,\n",
        "                                ),\n",
        "                            )\n",
        "                        )\n",
        "\n",
        "        else:\n",
        "            # Assum ing your Discrete space has an 'n' attribute (number of discrete values)\n",
        "            n = observation_space.n\n",
        "            shape = (env.n_agents,)  # Assuming observation shape is (n_agents,)\n",
        "\n",
        "            return CompositeSpec(\n",
        "                agents=CompositeSpec(\n",
        "                    observation=DiscreteTensorSpec(n=n, shape=shape, device=env.device),\n",
        "                )\n",
        "            )\"\"\"\n",
        "\n",
        "\n",
        "    def observation_spec(self, env: EnvBase) -> CompositeSpec:\n",
        "        \"\"\"Get the observation spec for a single agent.\"\"\"\n",
        "        # Assuming your observation spec is already nested correctly:\n",
        "        return env.observation_spec[\"agents\", \"observation\"]\n",
        "\n",
        "\n",
        "    def state_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the state.\n",
        "        # If provided, must be a CompositeSpec with one \"state\" entry\n",
        "        return None\n",
        "\n",
        "    def action_mask_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the action mask.\n",
        "        # If provided, must be a CompositeSpec with one (group_name, \"action_mask\") entry per group.\n",
        "        return None\n",
        "\n",
        "    def info_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the info.\n",
        "        # If provided, must be a CompositeSpec with one (group_name, \"info\") entry per group (this entry can be composite).\n",
        "        return None\n",
        "\n",
        "    def action_spec(self, env: EnvBase) -> CompositeSpec:\n",
        "        #Example of an action_spec\n",
        "        #return CompositeSpec(agents=DiscreteTensorSpec(5,shape=(1,)))\n",
        "        return env.action_spec  # Modified line\n",
        "        \"\"\"This method needs to be implemented to define the action space\n",
        "        of your custom environment. It should return a `CompositeSpec`\n",
        "        representing the action space.\n",
        "\n",
        "        For example, if your environment has a discrete action space\n",
        "        with 5 actions for each of 2 agents, you would return:\"\"\"\n",
        "\n",
        "    def env_name(self) -> str:\n",
        "          # Provide the name of your custom environment here\n",
        "          return \"AnFuelpriceEnv\" #or any suitable name"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "qmBGr1m-39Cn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "661b30d9-4328-47be-b84c-ea6cef7b84cd"
      },
      "id": "qmBGr1m-39Cn",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*action_spec: Composite(\n",
            "    agent_0: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_1: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_2: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*reward_spec: Composite(\n",
            "    agent_0: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_2: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*done_spec: Composite(\n",
            "    done: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*observation_spec: Composite(\n",
            "    agents: Composite(\n",
            "        observat: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_2: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        position_key: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_2: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "-action_keys: ['agent_0', 'agent_1', 'agent_2']\n",
            "\n",
            "-reward_keys: ['agent_0', 'agent_1', 'agent_2']\n",
            "\n",
            "-done_keys: ['done', 'terminated']\n",
            "input_spec: Composite(\n",
            "    full_state_spec: Composite(\n",
            "    ,\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    full_action_spec: Composite(\n",
            "        agent_0: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        agent_1: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        agent_2: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "reward_spec: Composite(\n",
            "    agent_0: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_2: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "action_spec (as defined by input_spec): Composite(\n",
            "    agent_0: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_1: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_2: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "reset tensordict TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                agent_0: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False),\n",
            "                agent_1: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False),\n",
            "                agent_2: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False)},\n",
            "            batch_size=torch.Size([10, 10]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10, 10]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The DiscreteTensorSpec has been deprecated and will be removed in v0.8. Please use Categorical instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.8. Please use Bounded instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Transform list must contain only transforms or callable. Got a element of type <class 'list'>.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3c98825fadec>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompositeSpec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiscreteTensorSpec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorSpec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnboundedContinuousTensorSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnvBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0manfuelpriceenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAnFuelpriceEnv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnFuelpriceEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# from benchmarl.environments.customenv.common import CustomEnvTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# from benchmarl.task.customenv import task_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/anfuelpriceenv/AnFuelpriceEnv.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    449\u001b[0m env = TransformedEnv(\n\u001b[1;32m    450\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m     Compose(  # Use Compose to combine transforms\n\u001b[0m\u001b[1;32m    452\u001b[0m         [\n\u001b[1;32m    453\u001b[0m             \u001b[0mRewardSum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"agents\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"agent_0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"agents\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"agent_0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"episode_reward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/transforms/transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *transforms)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             )\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmap_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrsf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrsf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/transforms/transforms.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             )\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmap_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrsf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrsf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/transforms/transforms.py\u001b[0m in \u001b[0;36mmap_transform\u001b[0;34m(trsf)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrsf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_CallableTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrsf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1190\u001b[0m                 \u001b[0;34mf\"Transform list must contain only transforms or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;34mf\"callable. Got a element of type {type(trsf)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Transform list must contain only transforms or callable. Got a element of type <class 'list'>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric  # Make sure the torch_geometric package is installed\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.13.0+cu118.html #Install torch-scatter\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu118.html #Install torch-sparse\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-1.13.0+cu118.html #Install torch-cluster\n",
        "\n",
        "import torch_geometric # explicitly import the library in your code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lJ32ST6jX6R",
        "outputId": "2b7f09ee-493a-49c4-a806-14c338528005"
      },
      "id": "1lJ32ST6jX6R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=547369 sha256=f107e322fd08e7493c181cc4ddef2f1346aeb5d09a6dde83023d673efe5fdc1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp311-cp311-linux_x86_64.whl size=1127935 sha256=e4aaf25b514dba92211e461778cc87ed0f1157718ca608a8b92f5a59df916d9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/e2/1e/299c596063839303657c211f587f05591891cc6cf126d94d21\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu118.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of CustomEnvTask\n",
        "custom_env_task = CustomEnvTask.TASK_1\n",
        "\n",
        "  # Set the task name\n",
        "\n",
        "# Get the task from YAML using the instance and its member\n",
        "task =custom_env_task\n",
        "\n",
        "experiment = Experiment(\n",
        "    algorithm_config=MappoConfig.get_from_yaml(),\n",
        "    model_config=GnnConfig(\n",
        "        topology=\"full\",\n",
        "        self_loops=False,\n",
        "        position_key=None,\n",
        "        pos_features=0,\n",
        "        exclude_pos_from_node_features=False,\n",
        "        gnn_class=torch_geometric.nn.conv.GATv2Conv,\n",
        "        gnn_kwargs={},),\n",
        "\n",
        "\n",
        "    critic_model_config=SequenceModelConfig(\n",
        "        model_configs=[\n",
        "            MlpConfig(num_cells=[8], activation_class=nn.Tanh, layer_class=nn.Linear),\n",
        "            GnnConfig( # Using GnnConfig here (removed CriticGnnConfig)\n",
        "                topology=\"full\",\n",
        "                self_loops=False,\n",
        "                gnn_class=torch_geometric.nn.conv.GraphConv,\n",
        "            ),\n",
        "            MlpConfig(num_cells=[6], activation_class=nn.Tanh, layer_class=nn.Linear),\n",
        "        ],\n",
        "        intermediate_sizes=[5, 3],\n",
        "    ),\n",
        "    seed=0,\n",
        "    config=ExperimentConfig.get_from_yaml(),\n",
        "\n",
        "    task=task,\n",
        "    #loggers=[\"tensorboard\"],\n",
        "    #save_folder='C:\\\\Users\\\\Richard Sarpong-Stre\\\\OneDrive\\\\Desktop\\\\usreslts\\\\results' #Replace with valid path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ")\n",
        "experiment.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "wk1_tDh5lhys",
        "outputId": "cdf7de81-e134-40ec-e700-becccb8ca02f"
      },
      "id": "wk1_tDh5lhys",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CustomEnvTask' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-29796f3d6ad5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create an instance of CustomEnvTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcustom_env_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomEnvTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTASK_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# Set the task name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CustomEnvTask' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict as TypingDict, Any, Union, List, Optional\n",
        "from torchrl.envs import EnvBase, TransformedEnv\n",
        "from torchrl.data import CompositeSpec, BoundedTensorSpec, DiscreteTensorSpec, UnboundedContinuousTensorSpec\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "from torchrl.envs.utils import check_env_specs\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "import os  # Import os for file existence check\n",
        "from typing import Dict, List # Import Dict and List here\n",
        "from torchrl.envs.transforms import RewardSum #changed the location of the import\n",
        "\n",
        "class DDataenv:\n",
        "    def __init__(self, data_path: str, data_columns: List[str], data_type: Any = np.float32):\n",
        "        self.data_path = data_path\n",
        "        self.data_columns = data_columns\n",
        "        self.data_type = data_type\n",
        "        self.data = None\n",
        "\n",
        "    def load_data(self) -> pd.DataFrame:\n",
        "        if not os.path.exists(self.data_path):\n",
        "            raise FileNotFoundError(f\"Data file not found at {self.data_path}\")\n",
        "\n",
        "        with open(self.data_path, 'rb') as f:\n",
        "            self.data = torch.load(f, weights_only=False)\n",
        "\n",
        "        self.data = np.array(self.data)\n",
        "        if len(self.data.shape) >= 3:\n",
        "            self.data = self.data.reshape(self.data.shape[1], self.data.shape[2])\n",
        "\n",
        "        if not isinstance(self.data, pd.DataFrame):\n",
        "            self.data = pd.DataFrame(self.data, columns=self.data_columns)\n",
        "\n",
        "        return self.data\n",
        "\n",
        "    def get_observation(self) -> TypingDict[str, Union[np.ndarray, TypingDict[str, float]]]:\n",
        "        if self.data is None:\n",
        "            self.load_data()\n",
        "\n",
        "        random_row_index = np.random.choice(self.data.shape[0], 1, replace=False)[0]\n",
        "        observation = self.data.iloc[random_row_index, :].to_numpy().astype(self.data_type)\n",
        "        describe_data = self.data.describe()\n",
        "\n",
        "        observation_dict = {\n",
        "            'obsState&Fuel': observation[0:13],\n",
        "            'Date': observation[-1],\n",
        "            'rewardState&reward': observation[13:26],\n",
        "            'actionState&action': observation[26:39],\n",
        "            'obsState&Fuel_max': describe_data.loc['max'][0:13].values,\n",
        "            'obsState&Fuel_min': describe_data.loc['min'][0:13].values,\n",
        "            'Date_max': describe_data['Date'].max(),\n",
        "            'Date_min': describe_data['Date'].min(),\n",
        "            'rewardState&reward_max': describe_data.loc['max'][13:26].values,\n",
        "            'rewardState&reward_min': describe_data.loc['min'][13:26].values,\n",
        "            'actionState&action_max': describe_data.loc['max'][26:39].values,\n",
        "            'actionState&action_min': describe_data.loc['min'][26:39].values,\n",
        "        }\n",
        "        return observation_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _step(tensordict):\n",
        "    td = env.gen_params()\n",
        "    n_agents = env.n_agents\n",
        "\n",
        "\n",
        "    # Initialize a dictionary to store agent data\n",
        "    agent= {f\"agent_{i}\": {} for i in range(n_agents)}\n",
        "\n",
        "    for j in range(n_agents):\n",
        "          # Initialize lists to store data for each agent within the batch\n",
        "        agent_i_date = []\n",
        "        agent_i_action = []\n",
        "        agent_i_rew = []\n",
        "        agent_i_new_obs = []\n",
        "\n",
        "        for convo_dim in range(env.batch_size[0]):\n",
        "            current_td = env.gen_params(env.batch_size)\n",
        "            obs = td['params', 'obsState&Fuel'].clone().detach()\n",
        "            reward = td['params', 'rewardState&reward'].clone().detach()\n",
        "            action = td['params', 'actionState&action'].clone().detach()\n",
        "            Date = td['params', 'Date'].clone().detach()\n",
        "\n",
        "            new_obs = torch.add(obs, torch.stack([action_i * reward_i for action_i, reward_i in zip(action, reward)]))\n",
        "            new_obs = torch.reshape(new_obs, (13,))\n",
        "\n",
        "                # Append data to agent-specific lists\n",
        "            agent_i_new_obs.append(new_obs)\n",
        "            agent_i_rew.append(reward)\n",
        "            agent_i_date.append(Date)\n",
        "            agent_i_action.append(action)\n",
        "\n",
        "            # Stack data for the current agent\n",
        "        en_Date = torch.stack(agent_i_date, dim=0) if agent_i_date else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        en_action = torch.stack(agent_i_action, dim=0) if agent_i_action else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        en_reward = torch.stack(agent_i_rew, dim=0)\n",
        "        en_new_obs = torch.stack(agent_i_new_obs, dim=0) if agent_i_new_obs else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        #print(en_new_obs.shape)\n",
        "\n",
        "            # Expansion for batch size and convolution\n",
        "        expanded_agent_new_obs = en_new_obs.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim)) # Corrected expand call\n",
        "        expanded_agent_reward = en_reward.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim)) # Corrected expand call\n",
        "        expanded_agent_action = en_action.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim))  # Corrected expand call\n",
        "\n",
        "        expanded_agent_Date = en_Date.reshape(*en_Date.shape, 1, 1).expand(tuple(env.batch_size) + (en_Date.shape[-1], *env.convo_dim)) # Corrected expand call\n",
        "\n",
        "\n",
        "        en_reward = torch.stack(agent_i_rew, dim=0)\n",
        "        if en_reward is None:\n",
        "            # Log or raise an error if en_reward is None\n",
        "            print(\"Warning: en_reward is None for agent\", j)\n",
        "            en_reward = torch.zeros(env.batch_size, 13, device=env.device)  # Or assign a default value\n",
        "\n",
        "        # Ensure en_reward has the expected shape:\n",
        "        expected_reward_shape = (env.batch_size[0], 13)  # or whatever the expected shape is\n",
        "        if en_reward.shape != expected_reward_shape:\n",
        "            # Log or raise an error if the shape is incorrect\n",
        "            print(\"Warning: en_reward shape mismatch for agent\", j, \"Expected:\", expected_reward_shape, \"Actual:\", en_reward.shape)\n",
        "            en_reward = torch.zeros(expected_reward_shape, device=env.device)  # Or assign a default value\n",
        "\n",
        "\n",
        "        # Store data in agent-specific dictionary\n",
        "        agent[f\"agent_{j}\"][\"observation\"] = {\"observat\": expanded_agent_new_obs,\"position_key\": expanded_agent_Date}\n",
        "          # Ensure 'reward' is under the \"agents\" key\n",
        "        agent[f\"agent_{j}\"][\"reward\"] = expanded_agent_reward\n",
        "        agent[f\"agent_{j}\"][\"action\"] = expanded_agent_action  # Assuming you need action here\n",
        "        #print( agent[f\"agent_{j}\"][\"reward\"] )\n",
        "\n",
        "    reward_vector = torch.zeros(13, device=env.device, dtype=torch.float32)\n",
        "    dones = torch.zeros((*env.batch_size, 1), dtype=torch.bool)\n",
        "\n",
        "    next_tensordict = TensorDict(\n",
        "        {\n",
        "            \"agents\": {\n",
        "                f\"agent_{j}\": {\n",
        "                    \"observation\": agent[f\"agent_{j}\"][\"observation\"],\n",
        "\n",
        "                    \"reward\":  agent[f\"agent_{j}\"][\"reward\"], # Ensure reward is present and under \"agents\"\n",
        "                }  for j in range(env.n_agents)\n",
        "\n",
        "            },\n",
        "            \"terminated\": dones.clone(),\n",
        "\n",
        "        },\n",
        "        batch_size=env.batch_size,\n",
        "        device=env.device,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    return next_tensordict\n",
        "\n",
        "\n",
        "def _reset(self, tensordict=None):\n",
        "    if tensordict is not None and \"_reset\" not in tensordict:\n",
        "        tensordict.clear()\n",
        "    else:\n",
        "        tensordict = TensorDict({}, batch_size=self.batch_size, device=self.device)\n",
        "\n",
        "        td = self.gen_params(self.batch_size)\n",
        "\n",
        "        obs_max = td['params', 'obsState&Fuel_max'].clone().detach()\n",
        "        obs_min = td['params', 'obsState&Fuel_min'].clone().detach()\n",
        "        Date = td['params', 'Date_max'].clone().detach()\n",
        "\n",
        "        n_agents = self.n_agents\n",
        "\n",
        "        # Create a dictionary to store agent data\n",
        "        agent_data = {f\"agent_{i}\": {} for i in range(n_agents)}\n",
        "\n",
        "        for i in range(n_agents):\n",
        "            random_numbers = torch.rand(1, device=self.device)\n",
        "            obs = torch.add(torch.mul(random_numbers, torch.add(obs_max, -obs_min)), obs_min)\n",
        "            Date=  td['params', 'Date_max'].clone().detach()\n",
        "\n",
        "            obs = obs.reshape (tuple(self.batch_size) + (13,))\n",
        "            Date = Date.reshape (tuple(self.batch_size) + (1,))\n",
        "\n",
        "\n",
        "\n",
        "            # Expand to include batch size\n",
        "            expanded_obs = obs.unsqueeze(-1).unsqueeze(-1).expand(tuple(self.batch_size) + ( 13, *self.convo_dim))\n",
        "            expanded_Date = Date.unsqueeze(-1).unsqueeze(-1).expand(tuple(self.batch_size) + (1, *self.convo_dim))\n",
        "\n",
        "            # Store data in the agent_data dictionary\n",
        "            agent_data[f\"agent_{i}\"][\"observation\"] = {\n",
        "                \"observat\": expanded_obs,\n",
        "                \"position_key\": expanded_Date,\n",
        "            }\n",
        "\n",
        "        # Create the tensordict with agent data\n",
        "        expanded_agent_observations = TensorDict(\n",
        "            {\"agents\": agent_data},\n",
        "            batch_size=self.batch_size,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        dones = torch.zeros((*self.batch_size, 1), dtype=torch.bool, device=self.device)\n",
        "\n",
        "        # Construct the final tensordict\n",
        "        return TensorDict(\n",
        "            {\n",
        "                **expanded_agent_observations,  # Include agent data\n",
        "                \"terminated\": dones.clone()\n",
        "            },\n",
        "            batch_size=self.batch_size,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def make_composite_from_td(td):\n",
        "    composite = CompositeSpec(\n",
        "        {\n",
        "            key: make_composite_from_td(tensor)\n",
        "            if isinstance(tensor, TensorDictBase)\n",
        "            else UnboundedContinuousTensorSpec(\n",
        "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
        "            )\n",
        "            for key, tensor in td.items()\n",
        "        },\n",
        "        shape=td.shape,\n",
        "    )\n",
        "    return composite\n",
        "\n",
        "def _make_spec(self, td_agents):\n",
        "\n",
        "    action_specs = []\n",
        "    observation_specs = []\n",
        "    reward_specs = []\n",
        "    info_specs = []\n",
        "\n",
        "    sobservat_spec_updated = CompositeSpec()\n",
        "    Date_spec_updated = CompositeSpec()\n",
        "    observation_updated = CompositeSpec()\n",
        "    reward_spec_updated = CompositeSpec()\n",
        "    done_spec_updated = CompositeSpec()\n",
        "    info_spec_updated = CompositeSpec()\n",
        "    action_spec_updated = CompositeSpec()\n",
        "    td_agents = self.gen_params()  # Or td_agents = self.gen_params() if no batch size is needed\n",
        "    agent = {f\"agent_{i}\": {} for i in range(self.n_agents)}\n",
        "\n",
        "    obs_max = td_agents['params', 'obsState&Fuel_max'].clone().detach()\n",
        "    obs_min = td_agents['params', 'obsState&Fuel_min'].clone().detach()\n",
        "    reward_max = td_agents['params', 'rewardState&reward_max'].clone().detach()\n",
        "    reward_min = td_agents['params', 'rewardState&reward_min'].clone().detach()\n",
        "    action_max = td_agents['params', 'actionState&action_max'].clone().detach()\n",
        "    action_min = td_agents['params', 'actionState&action_min'].clone().detach()\n",
        "    Date_max = td_agents['params', 'Date_max'].clone().detach()\n",
        "    Date_min = td_agents['params', 'Date_min'].clone().detach()\n",
        "\n",
        "    # Reshape the tensors to (n_agents, 13, *convo_dim) before the loop\n",
        "    # Assuming obs_max, obs_min, reward_max, reward_min, action_max, action_min have shape (13,)\n",
        "    # and Date_max, Date_min have shape (1,)\n",
        "\n",
        "    obs_max = obs_max.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    obs_min = obs_min.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    reward_max = reward_max.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    reward_min = reward_min.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    action_max = action_max.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    action_min = action_min.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    Date_max = Date_max.reshape(1, 1, 1, 1).expand(self.n_agents, 1, *self.convo_dim)\n",
        "    Date_min = Date_min.reshape(1, 1, 1, 1).expand(self.n_agents, 1, *self.convo_dim)\n",
        "\n",
        "    for i in range(self.n_agents):\n",
        "        # Creating action, reward, observation, and date specs for each agent\n",
        "        agent[f\"agent_{i}\"][\"action_spec\"] = DiscreteTensorSpec(n=3, shape=action_max[i].shape, dtype=torch.float32)  # Use action_max[i].shape directly\n",
        "        agent[f\"agent_{i}\"][\"reward_spec\"] = BoundedTensorSpec(low=reward_min[i], high=reward_max[i], shape=reward_max[i].shape, dtype=torch.float32)  # Use reward_min[i], reward_max[i], and reward_max[i].shape directly\n",
        "        agent[f\"agent_{i}\"][\"observat_spec\"] = BoundedTensorSpec(low=obs_min[i], high=obs_max[i], shape=obs_max[i].shape, dtype=torch.float32)  # Use obs_min[i], obs_max[i], and obs_max[i].shape directly\n",
        "        agent[f\"agent_{i}\"][\"Date_spec\"] = BoundedTensorSpec(low=Date_min[i], high=Date_max[i], shape=Date_max[i].shape, dtype=torch.float32)  # Use Date_min[i], Date_max[i], and Date_max[i].shape directly\n",
        "\n",
        "\n",
        "    # Creating CompositeSpecs for action, reward, observation, and date\n",
        "    action_spec_updated = CompositeSpec({k: v[\"action_spec\"] for k, v in agent.items()})\n",
        "    reward_spec_updated = CompositeSpec({k: v[\"reward_spec\"] for k, v in agent.items()})\n",
        "    observat_spec_updated = CompositeSpec({k: v[\"observat_spec\"] for k, v in agent.items()})\n",
        "    Date_spec_updated = CompositeSpec({k: v[\"Date_spec\"] for k, v in agent.items()})\n",
        "\n",
        "    # Creating unbatched observation, action, and reward specs\n",
        "    unbatched_observation_spec = CompositeSpec(\n",
        "        agents=CompositeSpec(\n",
        "            observat=observat_spec_updated,\n",
        "            position_key=Date_spec_updated,\n",
        "        )\n",
        "    )\n",
        "    unbatched_action_spec = action_spec_updated\n",
        "    unbatched_reward_spec = reward_spec_updated\n",
        "    unbatched_done_spec = DiscreteTensorSpec(n=2, shape=torch.Size([1]), dtype=torch.bool).to(self.device)\n",
        "    # # Expanding specs to include batch size\n",
        "\n",
        "    self.action_spec = unbatched_action_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "    self.observation_spec = unbatched_observation_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "    self.reward_spec = unbatched_reward_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "    self.done_spec = unbatched_done_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "\n",
        "    # Creating a CompositeSpec to represent the environment's spec\n",
        "    return CompositeSpec(\n",
        "        agents=CompositeSpec(\n",
        "            observation=CompositeSpec(\n",
        "                observat=self.observation_spec[\"agents\"][\"observat\"],\n",
        "                position_key=self.observation_spec[\"agents\"][\"position_key\"],\n",
        "            ),\n",
        "            reward=self.reward_spec,\n",
        "\n",
        "        ),\n",
        "        terminated=self.done_spec,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Creating unbatched done spec\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def gen_params(batch_size=torch.Size()) -> TensorDictBase:\n",
        "    if batch_size is None or (isinstance(batch_size, list) and len(batch_size) == 0):\n",
        "        batch_size = torch.Size([])\n",
        "    data_path = '/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/DataDic.pt'\n",
        "    data_columns = ['Forex', 'WTI', 'Brent', 'OPEC', 'Fuelprice5', 'Fuelprice6', 'Fuelprice7', 'Fuelprice8', 'Fuelprice9', 'Fuelprice10', 'Fuelprice11', 'Fuelprice12', 'Fuelprice13',\n",
        "                    'reward0', 'reward1', 'reward2', 'reward3', 'reward4', 'reward5', 'reward6', 'reward7', 'reward8', 'reward9', 'reward10', 'reward11', 'reward12',\n",
        "                    'action0', 'action1', 'action2', 'action3', 'action4', 'action5', 'action6', 'action7', 'action8', 'action9', 'action10', 'action11', 'action12', 'Date']\n",
        "    envv = DDataenv(data_path, data_columns)  # Assuming DDataenv is your data environment class\n",
        "\n",
        "    ac = envv.get_observation()\n",
        "\n",
        "    if batch_size:\n",
        "       # Change here: Convert batch_size to a tuple if it's not already\n",
        "        if not isinstance(batch_size, tuple):\n",
        "            batch_size = (batch_size,)  # Convert to tuple\n",
        "        ac = {k: torch.tensor(v).expand(*batch_size, *torch.tensor(v).shape) for k, v in ac.items()}\n",
        "\n",
        "    td = TensorDict({\"params\": ac}, batch_size=batch_size, device=torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    if batch_size:\n",
        "        td = td.expand(batch_size).contiguous()\n",
        "    return td\n",
        "\n",
        "\n",
        "def _set_seed(self, seed: 45):\n",
        "    self.rng = torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "def full_info_spec(self):\n",
        "    return {}\n",
        "\n",
        "\n",
        "def group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "    return {\"agents\": [agent[\"name\"] for agent in env.agents]}\n",
        "\n",
        "\n",
        "\n",
        "class AnFuelpriceEnv(EnvBase):\n",
        "    metadata = {\n",
        "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
        "        \"render_fps\": 30,\n",
        "    }\n",
        "    Scenario = \"USDATA_1\"\n",
        "    batch_locked = False\n",
        "\n",
        "    def __init__(self, td_params=None, seed=None, device=\"cpu\", categorical_actions=True, continuous_actions=True, **kwargs):\n",
        "        if td_params is None:\n",
        "            td_params = self.gen_params()\n",
        "\n",
        "        _ = kwargs.pop(\"scenario\", None)\n",
        "\n",
        "\n",
        "\n",
        "        self.n_agents = 3\n",
        "        self.convo_dim = [9, 9]\n",
        "        self.batch_size = (10,10) # Corrected batch size to a single-element tuple\n",
        "        self.batch_size_tuple = torch.Size([self.batch_size]) if isinstance(self.batch_size, int) else torch.Size(self.batch_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        super().__init__(device=device, batch_size=self.batch_size,)\n",
        "\n",
        "\n",
        "        self._make_spec(td_params)\n",
        "\n",
        "        if seed is None:\n",
        "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
        "        self.set_seed(seed)\n",
        "\n",
        "    def get_supports_continuous_actions(self):\n",
        "        return hasattr(env.full_action_spec, 'shape') and len(env.full_action_spec.shape) > 0\n",
        "\n",
        "    def get_supports_discrete_actions(self):\n",
        "        return isinstance(env.full_action_spec, DiscreteTensorSpec)\n",
        "\n",
        "    def get_observation_spec(self):\n",
        "        return self.observation_spec\n",
        "\n",
        "    def get_full_action_spec(self):\n",
        "        return self.full_action_spec\n",
        "\n",
        "    def get_full_reward_spec(self):\n",
        "        return self.full_reward_spec\n",
        "\n",
        "    def get_done_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    def get_group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "        return {\"agents\": [agent[\"name\"] for agent in env.agents]}\n",
        "\n",
        "    def get_full_info_spec(self):\n",
        "        return {}\n",
        "\n",
        "    def get_discount_spec(self):\n",
        "        return self.discount_spec\n",
        "\n",
        "    @property\n",
        "    def terminated_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    @property\n",
        "    def truncated_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    @property\n",
        "    def get_env_name(self):\n",
        "        return \"AnFuelpriceEnv\"\n",
        "\n",
        "    gen_params = staticmethod(gen_params)\n",
        "    _make_spec = _make_spec\n",
        "    _reset = _reset\n",
        "    _step = staticmethod(_step)\n",
        "    _set_seed = _set_seed\n",
        "    full_info_spec = full_info_spec\n",
        "\n",
        "\n",
        "env = AnFuelpriceEnv()\n",
        "\n",
        "print(\"\\n*action_spec:\", env.full_action_spec)\n",
        "print(\"\\n*reward_spec:\", env.full_reward_spec)\n",
        "print(\"\\n*done_spec:\", env.full_done_spec)\n",
        "print(\"\\n*observation_spec:\", env.observation_spec)\n",
        "\n",
        "print(\"\\n-action_keys:\", env.action_keys)\n",
        "print(\"\\n-reward_keys:\", env.reward_keys)\n",
        "print(\"\\n-done_keys:\", env.done_keys)\n",
        "\n",
        "print(\"input_spec:\", env.input_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "print(\"action_spec (as defined by input_spec):\", env.action_spec)\n",
        "td = env.reset()\n",
        "print(\"reset tensordict\", td)\n",
        "\n",
        "\n",
        "\n",
        "check_env_specs(env)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EjnZs_l-J8YX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e051021-b564-4813-df9d-4bb0905e8974"
      },
      "id": "EjnZs_l-J8YX",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The DiscreteTensorSpec has been deprecated and will be removed in v0.8. Please use Categorical instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.8. Please use Bounded instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*action_spec: Composite(\n",
            "    agent_0: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_1: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_2: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*reward_spec: Composite(\n",
            "    agent_0: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_2: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*done_spec: Composite(\n",
            "    done: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*observation_spec: Composite(\n",
            "    agents: Composite(\n",
            "        observat: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_2: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        position_key: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_2: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "-action_keys: ['agent_0', 'agent_1', 'agent_2']\n",
            "\n",
            "-reward_keys: ['agent_0', 'agent_1', 'agent_2']\n",
            "\n",
            "-done_keys: ['done', 'terminated']\n",
            "input_spec: Composite(\n",
            "    full_state_spec: Composite(\n",
            "    ,\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    full_action_spec: Composite(\n",
            "        agent_0: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        agent_1: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        agent_2: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "reward_spec: Composite(\n",
            "    agent_0: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_2: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "action_spec (as defined by input_spec): Composite(\n",
            "    agent_0: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_1: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_2: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "reset tensordict TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                agent_0: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False),\n",
            "                agent_1: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False),\n",
            "                agent_2: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False)},\n",
            "            batch_size=torch.Size([10, 10]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10, 10]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-db2628940589>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m \u001b[0mcheck_env_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/utils.py\u001b[0m in \u001b[0;36mcheck_env_specs\u001b[0;34m(env, return_contiguous, check_dtype, seed, tensordict)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0mfake_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_tensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m     real_tensordict = env.rollout(\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mreturn_contiguous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_contiguous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[0m\n\u001b[1;32m   3129\u001b[0m         }\n\u001b[1;32m   3130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbreak_when_any_done\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3131\u001b[0;31m             tensordicts = self._rollout_stop_early(\n\u001b[0m\u001b[1;32m   3132\u001b[0m                 \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m                 \u001b[0mbreak_when_any_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbreak_when_any_done\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m_rollout_stop_early\u001b[0;34m(self, break_when_any_done, break_when_all_done, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[0m\n\u001b[1;32m   3270\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3271\u001b[0m                     \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_device_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3272\u001b[0;31m             \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3273\u001b[0m             \u001b[0mtd_append\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1974\u001b[0;31m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_proc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext_preset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m             \u001b[0;31m# tensordict could already have a \"next\" key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m_step_proc_data\u001b[0;34m(self, next_tensordict_out)\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 ]\n\u001b[1;32m   2066\u001b[0m             )\n\u001b[0;32m-> 2067\u001b[0;31m             \u001b[0mactual_reward_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2068\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mactual_reward_shape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_reward_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m                 \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_reward_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchrl.envs import Transform\n",
        "Class RewardEmbeddingTransform(Transform):\n",
        "\n",
        "  def __init__(self, num_features=13, device=\"cpu\"):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.device = device\n",
        "\n",
        "    def _call(self, tensordict):\n",
        "        # Extract the current reward (example: assuming it's a scalar)\n",
        "        reward = tensordict[\"agents\", \"agent_0\", \"reward\"]\n",
        "\n",
        "        # Calculate the 13-feature embedding (example: simple linear transformation)\n",
        "        embedding = torch.randn(self.num_features, device=self.device) * reward\n",
        "\n",
        "        # Update the tensordict with the embedding\n",
        "        tensordict[\"agents\", \"agent_0\", \"reward\"] = embedding\n",
        "\n",
        "        return tensordict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "h3tjAE8gjOs_",
        "outputId": "ff8eacf8-134c-4323-f80d-5d3e689e4b2a"
      },
      "id": "h3tjAE8gjOs_",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    def _call(self, tensordict):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchrl.envs import Transform\n",
        "\n",
        "class RewardEmbeddingTransform(Transform):\n",
        "    def __init__(self, num_features=13, device=\"cpu\"):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.device = device\n",
        "\n",
        "    def _call(self, tensordict):\n",
        "        # Extract the current reward (example: assuming it's a scalar)\n",
        "        reward = tensordict[\"agents\", \"agent_0\", \"reward\"]\n",
        "\n",
        "        # Calculate the 13-feature embedding (example: simple linear transformation)\n",
        "        embedding = torch.randn(self.num_features, device=self.device) * reward\n",
        "\n",
        "        # Update the tensordict with the embedding\n",
        "        tensordict[\"agents\", \"agent_0\", \"reward\"] = embedding\n",
        "\n",
        "        return tensordict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "3ghhTdqyZ6HF",
        "outputId": "a4474802-e1b1-4cd4-e8f6-091d9865a6a9"
      },
      "id": "3ghhTdqyZ6HF",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchrl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a601a01a38f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRewardEmbeddingTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchrl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torchrl.envs import Compose # Import Compose\n",
        "\n",
        "env = TransformedEnv(\n",
        "    env,\n",
        "    Compose(  # Use Compose to combine transforms\n",
        "        [\n",
        "            RewardSum(in_keys=[(\"agents\", \"agent_0\", \"reward\")], out_keys=[(\"agents\", \"agent_0\", \"episode_reward\")]),\n",
        "            RewardSum(in_keys=[(\"agents\", \"agent_1\", \"reward\")], out_keys=[(\"agents\", \"agent_1\", \"episode_reward\")]),\n",
        "            RewardSum(in_keys=[(\"agents\", \"agent_2\", \"reward\")], out_keys=[(\"agents\", \"agent_2\", \"episode_reward\")]),\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dSaQ3raDN0cL"
      },
      "id": "dSaQ3raDN0cL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "caa7225f",
      "metadata": {
        "id": "caa7225f"
      },
      "source": [
        "# Launch from command line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30075032",
      "metadata": {
        "id": "30075032"
      },
      "source": [
        "To launch an experiment from the command line you can do"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5369898f",
      "metadata": {
        "scrolled": false,
        "id": "5369898f"
      },
      "outputs": [],
      "source": [
        "!python benchmarl/run.py algorithm=mappo task=vmas/balance experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23f9338f",
      "metadata": {
        "id": "23f9338f"
      },
      "source": [
        "You can run benchmarks as multi-runs like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90a135ea",
      "metadata": {
        "scrolled": false,
        "id": "90a135ea"
      },
      "outputs": [],
      "source": [
        "!python benchmarl/run.py -m algorithm=mappo,qmix,masac task=vmas/balance,vmas/sampling seed=0,1 experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b01091a",
      "metadata": {
        "id": "0b01091a"
      },
      "source": [
        "# Launch from a python script"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c6dc69",
      "metadata": {
        "id": "67c6dc69"
      },
      "source": [
        "You can also load and launch your experiments from within a script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c5b5fcd",
      "metadata": {
        "id": "2c5b5fcd"
      },
      "outputs": [],
      "source": [
        "from benchmarl.algorithms import MappoConfig\n",
        "from benchmarl.environments import VmasTask\n",
        "from benchmarl.experiment import Experiment, ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas/balance.yaml\"\n",
        "task = VmasTask.BALANCE.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/algorithm/mappo.yaml\"\n",
        "algorithm_config = MappoConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/model/layers/mlp.yaml\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "experiment = Experiment(\n",
        "    task=task,\n",
        "    algorithm_config=algorithm_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        "    seed=0,\n",
        "    config=experiment_config,\n",
        ")\n",
        "experiment.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20864e3",
      "metadata": {
        "id": "a20864e3"
      },
      "source": [
        "You can also run multiple experiments in a Benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec3bd4b",
      "metadata": {
        "id": "6ec3bd4b"
      },
      "outputs": [],
      "source": [
        "from benchmarl.algorithms import MappoConfig, MasacConfig, QmixConfig\n",
        "from benchmarl.benchmark import Benchmark\n",
        "from benchmarl.environments import VmasTask\n",
        "from benchmarl.experiment import ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas\"\n",
        "tasks = [VmasTask.BALANCE.get_from_yaml(), VmasTask.SAMPLING.get_from_yaml()]\n",
        "# Loads from \"benchmarl/conf/algorithm\"\n",
        "algorithm_configs = [\n",
        "    MappoConfig.get_from_yaml(),\n",
        "    QmixConfig.get_from_yaml(),\n",
        "    MasacConfig.get_from_yaml(),\n",
        "]\n",
        "# Loads from \"benchmarl/conf/model/layers\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "benchmark = Benchmark(\n",
        "    algorithm_configs=algorithm_configs,\n",
        "    tasks=tasks,\n",
        "    seeds={0, 1},\n",
        "    experiment_config=experiment_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        ")\n",
        "benchmark.run_sequential()"
      ]
    },
    {
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict as TypingDict, Any, Union, List, Optional\n",
        "from torchrl.envs import EnvBase, TransformedEnv\n",
        "from torchrl.data import CompositeSpec, BoundedTensorSpec, DiscreteTensorSpec, UnboundedContinuousTensorSpec\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "from torchrl.envs.utils import check_env_specs\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "import os  # Import os for file existence check\n",
        "from typing import Dict, List # Import Dict and List here\n",
        "from torchrl.envs.transforms import RewardSum #changed the location of the import\n",
        "\n",
        "class DDataenv:\n",
        "    def __init__(self, data_path: str, data_columns: List[str], data_type: Any = np.float32):\n",
        "        self.data_path = data_path\n",
        "        self.data_columns = data_columns\n",
        "        self.data_type = data_type\n",
        "        self.data = None\n",
        "\n",
        "    def load_data(self) -> pd.DataFrame:\n",
        "        if not os.path.exists(self.data_path):\n",
        "            raise FileNotFoundError(f\"Data file not found at {self.data_path}\")\n",
        "\n",
        "        with open(self.data_path, 'rb') as f:\n",
        "            self.data = torch.load(f, weights_only=False)\n",
        "\n",
        "        self.data = np.array(self.data)\n",
        "        if len(self.data.shape) >= 3:\n",
        "            self.data = self.data.reshape(self.data.shape[1], self.data.shape[2])\n",
        "\n",
        "        if not isinstance(self.data, pd.DataFrame):\n",
        "            self.data = pd.DataFrame(self.data, columns=self.data_columns)\n",
        "\n",
        "        return self.data\n",
        "\n",
        "    def get_observation(self) -> TypingDict[str, Union[np.ndarray, TypingDict[str, float]]]:\n",
        "        if self.data is None:\n",
        "            self.load_data()\n",
        "\n",
        "        random_row_index = np.random.choice(self.data.shape[0], 1, replace=False)[0]\n",
        "        observation = self.data.iloc[random_row_index, :].to_numpy().astype(self.data_type)\n",
        "        describe_data = self.data.describe()\n",
        "\n",
        "        observation_dict = {\n",
        "            'obsState&Fuel': observation[0:13],\n",
        "            'Date': observation[-1],\n",
        "            'rewardState&reward': observation[13:26],\n",
        "            'actionState&action': observation[26:39],\n",
        "            'obsState&Fuel_max': describe_data.loc['max'][0:13].values,\n",
        "            'obsState&Fuel_min': describe_data.loc['min'][0:13].values,\n",
        "            'Date_max': describe_data['Date'].max(),\n",
        "            'Date_min': describe_data['Date'].min(),\n",
        "            'rewardState&reward_max': describe_data.loc['max'][13:26].values,\n",
        "            'rewardState&reward_min': describe_data.loc['min'][13:26].values,\n",
        "            'actionState&action_max': describe_data.loc['max'][26:39].values,\n",
        "            'actionState&action_min': describe_data.loc['min'][26:39].values,\n",
        "        }\n",
        "        return observation_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _step(tensordict):\n",
        "    td = env.gen_params()\n",
        "    n_agents = env.n_agents\n",
        "\n",
        "\n",
        "    # Initialize a dictionary to store agent data\n",
        "    agent= {f\"agent_{i}\": {} for i in range(n_agents)}\n",
        "\n",
        "    for j in range(n_agents):\n",
        "          # Initialize lists to store data for each agent within the batch\n",
        "        agent_i_date = []\n",
        "        agent_i_action = []\n",
        "        agent_i_rew = []\n",
        "        agent_i_new_obs = []\n",
        "\n",
        "        for convo_dim in range(env.batch_size[0]):\n",
        "            current_td = env.gen_params(env.batch_size)\n",
        "            obs = td['params', 'obsState&Fuel'].clone().detach()\n",
        "            reward = td['params', 'rewardState&reward'].clone().detach()\n",
        "            action = td['params', 'actionState&action'].clone().detach()\n",
        "            Date = td['params', 'Date'].clone().detach()\n",
        "\n",
        "            new_obs = torch.add(obs, torch.stack([action_i * reward_i for action_i, reward_i in zip(action, reward)]))\n",
        "            new_obs = torch.reshape(new_obs, (13,))\n",
        "\n",
        "                # Append data to agent-specific lists\n",
        "            agent_i_new_obs.append(new_obs)\n",
        "            agent_i_rew.append(reward)\n",
        "            agent_i_date.append(Date)\n",
        "            agent_i_action.append(action)\n",
        "\n",
        "            # Stack data for the current agent\n",
        "        en_Date = torch.stack(agent_i_date, dim=0) if agent_i_date else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        en_action = torch.stack(agent_i_action, dim=0) if agent_i_action else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        en_reward = torch.stack(agent_i_rew, dim=0)\n",
        "        en_new_obs = torch.stack(agent_i_new_obs, dim=0) if agent_i_new_obs else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        #print(en_new_obs.shape)\n",
        "\n",
        "            # Expansion for batch size and convolution\n",
        "        expanded_agent_new_obs = en_new_obs.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim)) # Corrected expand call\n",
        "        expanded_agent_reward = en_reward.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim)) # Corrected expand call\n",
        "        expanded_agent_action = en_action.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim))  # Corrected expand call\n",
        "\n",
        "        expanded_agent_Date = en_Date.reshape(*en_Date.shape, 1, 1).expand(tuple(env.batch_size) + (en_Date.shape[-1], *env.convo_dim)) # Corrected expand call\n",
        "\n",
        "\n",
        "\n",
        "        # Store data in agent-specific dictionary\n",
        "        agent[f\"agent_{j}\"][\"observation\"] = {\"observat\": expanded_agent_new_obs,\"position_key\": expanded_agent_Date}\n",
        "          # Ensure 'reward' is under the \"agents\" key\n",
        "        agent[f\"agent_{j}\"][\"reward\"] = expanded_agent_reward\n",
        "        agent[f\"agent_{j}\"][\"action\"] = expanded_agent_action  # Assuming you need action here\n",
        "        #print( agent[f\"agent_{j}\"][\"reward\"] )\n",
        "\n",
        "\n",
        "    dones = torch.zeros((*env.batch_size, 1), dtype=torch.bool)\n",
        "\n",
        "    next_tensordict = TensorDict(\n",
        "        {\n",
        "            \"agents\": agent,\n",
        "            \"terminated\": dones.clone(),\n",
        "        },\n",
        "        batch_size=env.batch_size,\n",
        "        device=env.device,\n",
        "    )\n",
        "\n",
        "    # Explicitly setting the reward key\n",
        "    #next_tensordict[\"next\", \"reward\"] = next_tensordict[\"agents\", \"reward\"]\n",
        "\n",
        "    return next_tensordict\n",
        "\n",
        "\n",
        "def _reset(self, tensordict=None):\n",
        "    if tensordict is not None and \"_reset\" not in tensordict:\n",
        "        tensordict.clear()\n",
        "    else:\n",
        "        tensordict = TensorDict({}, batch_size=self.batch_size, device=self.device)\n",
        "\n",
        "        td = self.gen_params(self.batch_size)\n",
        "\n",
        "        obs_max = td['params', 'obsState&Fuel_max'].clone().detach()\n",
        "        obs_min = td['params', 'obsState&Fuel_min'].clone().detach()\n",
        "        Date = td['params', 'Date_max'].clone().detach()\n",
        "\n",
        "        n_agents = self.n_agents\n",
        "\n",
        "        # Create a dictionary to store agent data\n",
        "        agent_data = {f\"agent_{i}\": {} for i in range(n_agents)}\n",
        "\n",
        "        for i in range(n_agents):\n",
        "            random_numbers = torch.rand(1, device=self.device)\n",
        "            obs = torch.add(torch.mul(random_numbers, torch.add(obs_max, -obs_min)), obs_min)\n",
        "            Date=  td['params', 'Date_max'].clone().detach()\n",
        "\n",
        "            obs = obs.reshape (tuple(self.batch_size) + (13,))\n",
        "            Date = Date.reshape (tuple(self.batch_size) + (1,))\n",
        "\n",
        "\n",
        "\n",
        "            # Expand to include batch size\n",
        "            expanded_obs = obs.unsqueeze(-1).unsqueeze(-1).expand(tuple(self.batch_size) + ( 13, *self.convo_dim))\n",
        "            expanded_Date = Date.unsqueeze(-1).unsqueeze(-1).expand(tuple(self.batch_size) + (1, *self.convo_dim))\n",
        "\n",
        "            # Store data in the agent_data dictionary\n",
        "            agent_data[f\"agent_{i}\"][\"observation\"] = {\n",
        "                \"observat\": expanded_obs,\n",
        "                \"position_key\": expanded_Date,\n",
        "            }\n",
        "\n",
        "        # Create the tensordict with agent data\n",
        "        expanded_agent_observations = TensorDict(\n",
        "            {\"agents\": agent_data},\n",
        "            batch_size=self.batch_size,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        dones = torch.zeros((*self.batch_size, 1), dtype=torch.bool, device=self.device)\n",
        "\n",
        "        # Construct the final tensordict\n",
        "        return TensorDict(\n",
        "            {\n",
        "                **expanded_agent_observations,  # Include agent data\n",
        "                \"terminated\": dones.clone()\n",
        "            },\n",
        "            batch_size=self.batch_size,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def make_composite_from_td(td):\n",
        "    if isinstance(td, TensorDictBase):\n",
        "        return CompositeSpec({key: make_composite_from_td(tensor) for key, tensor in td.items()})\n",
        "    if not isinstance(td, TensorDictBase):\n",
        "        #This is the fixed line\n",
        "        composite = UnboundedContinuousTensorSpec(\n",
        "                    dtype=td.dtype, device=td.device, shape=td.shape\n",
        "                )\n",
        "\n",
        "        return composite\n",
        "\n",
        "\n",
        "def _make_spec(self, td_agents):\n",
        "\n",
        "    action_specs = []\n",
        "    observation_specs = []\n",
        "    reward_specs = []\n",
        "    info_specs = []\n",
        "    done_specs = []\n",
        "    discount_specs = []\n",
        "\n",
        "    td_agents = self.gen_params()  # Or td_agents = self.gen_params() if no batch size is needed\n",
        "    agent = {f\"agent_{i}\": {} for i in range(self.n_agents)}\n",
        "\n",
        "    obs_max = td_agents['params', 'obsState&Fuel_max'].clone().detach()\n",
        "    obs_min = td_agents['params', 'obsState&Fuel_min'].clone().detach()\n",
        "    reward_max = td_agents['params', 'rewardState&reward_max'].clone().detach()\n",
        "    reward_min = td_agents['params', 'rewardState&reward_min'].clone().detach()\n",
        "    action_max = td_agents['params', 'actionState&action_max'].clone().detach()\n",
        "    action_min = td_agents['params', 'actionState&action_min'].clone().detach()\n",
        "    Date_max = td_agents['params', 'Date_max'].clone().detach()\n",
        "    Date_min = td_agents['params', 'Date_min'].clone().detach()\n",
        "\n",
        "    # Reshape the tensors to (n_agents, 13, *convo_dim) before the loop\n",
        "    # Assuming obs_max, obs_min, reward_max, reward_min, action_max, action_min have shape (13,)\n",
        "    # and Date_max, Date_min have shape (1,)\n",
        "\n",
        "     #Reshape the tensors to include batch dimensions\n",
        "    def reshape_and_expand(tensor, shape, convo_dim):\n",
        "        return torch.zeros((self.n_agents, *shape, *convo_dim), dtype=tensor.dtype, device=tensor.device)\n",
        "\n",
        "    obs_max = reshape_and_expand(obs_max, (13,), self.convo_dim)\n",
        "    obs_min = reshape_and_expand(obs_min, (13,), self.convo_dim)\n",
        "    reward_max = reshape_and_expand(reward_max, (13,), self.convo_dim)\n",
        "    reward_min = reshape_and_expand(reward_min, (13,), self.convo_dim)\n",
        "    action_max = reshape_and_expand(action_max, (13,), self.convo_dim)\n",
        "    action_min = reshape_and_expand(action_min, (13,), self.convo_dim)\n",
        "    Date_max = reshape_and_expand(Date_max, (1,), self.convo_dim)\n",
        "    Date_min = reshape_and_expand(Date_min, (1,), self.convo_dim)\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(self.n_agents):\n",
        "        shape = obs_max[i].shape  # Or the shape of reward_max[i], Date_max[i], etc. - they should be the same\n",
        "        shape1= Date_max[i].shape\n",
        "        agent[f\"agent_{i}\"][\"action_spec\"] = DiscreteTensorSpec(n=3, shape=tuple(shape), dtype=torch.float32)\n",
        "        # Applying sum to reward_min and reward_max to match the reward shape after sum in _step\n",
        "        agent[f\"agent_{i}\"][\"observat_spec\"] = BoundedTensorSpec(low=obs_min[i], high=obs_max[i], shape=tuple(shape), dtype=torch.float32)\n",
        "        agent[f\"agent_{i}\"][\"Date_spec\"] = BoundedTensorSpec(low=Date_min[i], high=Date_max[i], shape=tuple(shape1), dtype=torch.float32)\n",
        "        agent[f\"agent_{i}\"][\"reward_spec\"] = BoundedTensorSpec(low=reward_min[i], high=reward_max[i], shape=tuple(shape), dtype=torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    self.observation_spec = self.observation_spec.to(self.device)\n",
        "    self.reward_spec = self.reward_spec.to(self.device)\n",
        "    self.full_action_spec = self.full_action_spec.to(self.device)\n",
        "    self.done_spec = self.done_spec.to(self.device)\n",
        "    self.discount_spec = self.discount_spec.to(self.device)\n",
        "\n",
        "\n",
        "      # Move thself.observation_spec.shape = torch.Size(self.batch_size)  # Convert to torch.Size\n",
        "    self.observation_spec = self.observation_spec[self.batch_size]\n",
        "    self.reward_spec = self.reward_spec[self.batch_size]\n",
        "    self.full_action_spec = self.full_action_spec[self.batch_size]\n",
        "    self.done_spec = self.done_spec[self.batch_size]\n",
        "    self.discount_spec = self.discount_spec[self.batch_size]\n",
        "\n",
        "\n",
        "    #\n",
        "\n",
        "    self.observation_spec = CompositeSpec(\n",
        "        agents=CompositeSpec(\n",
        "            observat=CompositeSpec({k: v[\"observat_spec\"] for k, v in agent.items()}),\n",
        "            position_key=CompositeSpec({k: v[\"Date_spec\"] for k, v in agent.items()}),\n",
        "        ),\n",
        "        device=self.device,\n",
        "    )\n",
        "    self.observation_spec = self.observation_spec.expand(self.batch_size).to(self.device)\n",
        "\n",
        "    self.reward_spec = CompositeSpec(\n",
        "        agents=CompositeSpec(\n",
        "            {k: v[\"reward_spec\"] for k, v in agent.items()}\n",
        "        ),\n",
        "        device=self.device,\n",
        "    )\n",
        "    self.reward_spec = self.reward_spec.expand(self.batch_size).to(self.device)  # Applying batch size after moving to device\n",
        "\n",
        "    self.full_action_spec = CompositeSpec(\n",
        "        agents=CompositeSpec(\n",
        "            {k: v[\"action_spec\"] for k, v in agent.items()}\n",
        "        ),\n",
        "        device=self.device,\n",
        "    )\n",
        "    self.full_action_spec = self.full_action_spec.expand(self.batch_size).to(self.device)\n",
        "\n",
        "    self.done_spec = DiscreteTensorSpec(n=2, shape=torch.Size([1]), dtype=torch.bool).to(self.device)# Spec for the 'done' flag\n",
        "    self.discount_spec = BoundedTensorSpec(low=0.0, high=1.0, shape=torch.Size([1]), dtype=torch.float32).to(self.device) # Spec for the discount factor\n",
        "\n",
        "     # Add this line to set output_spec:\n",
        "    self.output_spec = CompositeSpec(full_done_spec=self.done_spec, full_reward_spec=self.reward_spec)\n",
        "      # Move the spec to the device first\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def gen_params(batch_size=torch.Size()) -> TensorDictBase:\n",
        "    if batch_size is None or (isinstance(batch_size, list) and len(batch_size) == 0):\n",
        "        batch_size = torch.Size([])\n",
        "    data_path = '/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/DataDic.pt'\n",
        "    data_columns = ['Forex', 'WTI', 'Brent', 'OPEC', 'Fuelprice5', 'Fuelprice6', 'Fuelprice7', 'Fuelprice8', 'Fuelprice9', 'Fuelprice10', 'Fuelprice11', 'Fuelprice12', 'Fuelprice13',\n",
        "                    'reward0', 'reward1', 'reward2', 'reward3', 'reward4', 'reward5', 'reward6', 'reward7', 'reward8', 'reward9', 'reward10', 'reward11', 'reward12',\n",
        "                    'action0', 'action1', 'action2', 'action3', 'action4', 'action5', 'action6', 'action7', 'action8', 'action9', 'action10', 'action11', 'action12', 'Date']\n",
        "    envv = DDataenv(data_path, data_columns)  # Assuming DDataenv is your data environment class\n",
        "\n",
        "    ac = envv.get_observation()\n",
        "\n",
        "    if batch_size:\n",
        "       # Change here: Convert batch_size to a tuple if it's not already\n",
        "        if not isinstance(batch_size, tuple):\n",
        "            batch_size = (batch_size,)  # Convert to tuple\n",
        "        ac = {k: torch.tensor(v).expand(*batch_size, *torch.tensor(v).shape) for k, v in ac.items()}\n",
        "\n",
        "    td = TensorDict({\"params\": ac}, batch_size=batch_size, device=torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    if batch_size:\n",
        "        td = td.expand(batch_size).contiguous()\n",
        "    return td\n",
        "\n",
        "\n",
        "def _set_seed(self, seed: 45):\n",
        "    self.rng = torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "def full_info_spec(self):\n",
        "    return {}\n",
        "\n",
        "\n",
        "def group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "    return {\"agents\": [agent[\"name\"] for agent in env.agents]}\n",
        "\n",
        "\n",
        "\n",
        "class AnFuelpriceEnv(EnvBase):\n",
        "    metadata = {\n",
        "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
        "        \"render_fps\": 30,\n",
        "    }\n",
        "    Scenario = \"USDATA_1\"\n",
        "    batch_locked = False\n",
        "\n",
        "    def __init__(self, td_params=None, seed=None, device=\"cpu\", categorical_actions=True, continuous_actions=True, **kwargs):\n",
        "        if td_params is None:\n",
        "            td_params = self.gen_params()\n",
        "\n",
        "        _ = kwargs.pop(\"scenario\", None)\n",
        "\n",
        "\n",
        "\n",
        "        self.n_agents = 3\n",
        "        self.convo_dim = [9, 9]\n",
        "        self.batch_size = (10,10) # Corrected batch size to a single-element tuple\n",
        "        self.batch_size_tuple = torch.Size([self.batch_size]) if isinstance(self.batch_size, int) else torch.Size(self.batch_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        super().__init__(device=device, batch_size=self.batch_size,)\n",
        "\n",
        "\n",
        "        self._make_spec(td_params)\n",
        "\n",
        "        if seed is None:\n",
        "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
        "        self.set_seed(seed)\n",
        "\n",
        "    def get_supports_continuous_actions(self):\n",
        "        return hasattr(env.full_action_spec, 'shape') and len(env.full_action_spec.shape) > 0\n",
        "\n",
        "    def get_supports_discrete_actions(self):\n",
        "        return isinstance(env.full_action_spec, DiscreteTensorSpec)\n",
        "\n",
        "    def get_observation_spec(self):\n",
        "        return self.observation_spec\n",
        "\n",
        "    def get_full_action_spec(self):\n",
        "        return self.full_action_spec\n",
        "\n",
        "    def get_full_reward_spec(self):\n",
        "        return self.full_reward_spec\n",
        "\n",
        "    def get_done_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    def get_group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "        return {\"agents\": [agent[\"name\"] for agent in env.agents]}\n",
        "\n",
        "    def get_full_info_spec(self):\n",
        "        return {}\n",
        "\n",
        "    def get_discount_spec(self):\n",
        "        return self.discount_spec\n",
        "\n",
        "    @property\n",
        "    def terminated_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    @property\n",
        "    def truncated_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    @property\n",
        "    def get_env_name(self):\n",
        "        return \"AnFuelpriceEnv\"\n",
        "\n",
        "    gen_params = staticmethod(gen_params)\n",
        "    _make_spec = _make_spec\n",
        "    _reset = _reset\n",
        "    _step = staticmethod(_step)\n",
        "    _set_seed = _set_seed\n",
        "    full_info_spec = full_info_spec\n",
        "\n",
        "\n",
        "env = AnFuelpriceEnv()\n",
        "\n",
        "print(\"\\n*action_spec:\", env.full_action_spec)\n",
        "print(\"\\n*reward_spec:\", env.full_reward_spec)\n",
        "print(\"\\n*done_spec:\", env.full_done_spec)\n",
        "print(\"\\n*observation_spec:\", env.observation_spec)\n",
        "\n",
        "print(\"\\n-action_keys:\", env.action_keys)\n",
        "print(\"\\n-reward_keys:\", env.reward_keys)\n",
        "print(\"\\n-done_keys:\", env.done_keys)\n",
        "\n",
        "print(\"input_spec:\", env.input_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "print(\"action_spec (as defined by input_spec):\", env.action_spec)\n",
        "td = env.reset()\n",
        "print(\"reset tensordict\", td)\n",
        "\n",
        "check_env_specs(env)\n",
        "from torchrl.envs import Compose # Import Compose\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "yr2lrl0PoFXJ",
        "outputId": "12163965-8a8d-4b0a-c94d-d60160688eab"
      },
      "id": "yr2lrl0PoFXJ",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The DiscreteTensorSpec has been deprecated and will be removed in v0.8. Please use Categorical instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.8. Please use Bounded instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'full_done_spec'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-3f1377b757e8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnFuelpriceEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n*action_spec:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_action_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mauto_reset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto_reset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mauto_reset_replace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto_reset_replace\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0minstance\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEnvBase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_cache\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-3f1377b757e8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, td_params, seed, device, categorical_actions, continuous_actions, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-3f1377b757e8>\u001b[0m in \u001b[0;36m_make_spec\u001b[0;34m(self, td_agents)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_action_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_action_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mdone_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1512\u001b[0m                 domain=discrete)\n\u001b[1;32m   1513\u001b[0m         \"\"\"\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0mdone_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_done_spec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdone_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m   4909\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx_unravel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"device\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"space\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4910\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Composite has no key {idx_unravel}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4911\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_specs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_unravel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4913\u001b[0m         \u001b[0mindexed_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'full_done_spec'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = TransformedEnv(\n",
        "    env,\n",
        "    Compose(\n",
        "            RewardSum(in_keys=[(\"agents\", \"agent_0\", \"reward\")], out_keys=[(\"agents\", \"agent_0\", \"episode_reward\")]),\n",
        "            RewardSum(in_keys=[(\"agents\", \"agent_1\", \"reward\")], out_keys=[(\"agents\", \"agent_1\", \"episode_reward\")]),\n",
        "            RewardSum(in_keys=[(\"agents\", \"agent_2\", \"reward\")], out_keys=[(\"agents\", \"agent_2\", \"episode_reward\")]),\n",
        "    )\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "_wsvAXtpJorm"
      },
      "id": "_wsvAXtpJorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5RiFOx02pEt5"
      },
      "id": "5RiFOx02pEt5",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict as TypingDict, Any, Union, List, Optional\n",
        "from torchrl.envs import EnvBase, TransformedEnv\n",
        "from torchrl.data import CompositeSpec, BoundedTensorSpec, DiscreteTensorSpec, UnboundedContinuousTensorSpec\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "from torchrl.envs.utils import check_env_specs\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "import os  # Import os for file existence check\n",
        "from typing import Dict, List # Import Dict and List here\n",
        "from torchrl.envs.transforms import RewardSum #changed the location of the import\n",
        "\n",
        "class DDataenv:\n",
        "    def __init__(self, data_path: str, data_columns: List[str], data_type: Any = np.float32):\n",
        "        self.data_path = data_path\n",
        "        self.data_columns = data_columns\n",
        "        self.data_type = data_type\n",
        "        self.data = None\n",
        "\n",
        "    def load_data(self) -> pd.DataFrame:\n",
        "        if not os.path.exists(self.data_path):\n",
        "            raise FileNotFoundError(f\"Data file not found at {self.data_path}\")\n",
        "\n",
        "        with open(self.data_path, 'rb') as f:\n",
        "            self.data = torch.load(f, weights_only=False)\n",
        "\n",
        "        self.data = np.array(self.data)\n",
        "        if len(self.data.shape) >= 3:\n",
        "            self.data = self.data.reshape(self.data.shape[1], self.data.shape[2])\n",
        "\n",
        "        if not isinstance(self.data, pd.DataFrame):\n",
        "            self.data = pd.DataFrame(self.data, columns=self.data_columns)\n",
        "\n",
        "        return self.data\n",
        "\n",
        "    def get_observation(self) -> TypingDict[str, Union[np.ndarray, TypingDict[str, float]]]:\n",
        "        if self.data is None:\n",
        "            self.load_data()\n",
        "\n",
        "        random_row_index = np.random.choice(self.data.shape[0], 1, replace=False)[0]\n",
        "        observation = self.data.iloc[random_row_index, :].to_numpy().astype(self.data_type)\n",
        "        describe_data = self.data.describe()\n",
        "\n",
        "        observation_dict = {\n",
        "            'obsState&Fuel': observation[0:13],\n",
        "            'Date': observation[-1],\n",
        "            'rewardState&reward': observation[13:26],\n",
        "            'actionState&action': observation[26:39],\n",
        "            'obsState&Fuel_max': describe_data.loc['max'][0:13].values,\n",
        "            'obsState&Fuel_min': describe_data.loc['min'][0:13].values,\n",
        "            'Date_max': describe_data['Date'].max(),\n",
        "            'Date_min': describe_data['Date'].min(),\n",
        "            'rewardState&reward_max': describe_data.loc['max'][13:26].values,\n",
        "            'rewardState&reward_min': describe_data.loc['min'][13:26].values,\n",
        "            'actionState&action_max': describe_data.loc['max'][26:39].values,\n",
        "            'actionState&action_min': describe_data.loc['min'][26:39].values,\n",
        "        }\n",
        "        return observation_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _step(tensordict):\n",
        "    td = env.gen_params()\n",
        "    n_agents = env.n_agents\n",
        "\n",
        "\n",
        "    # Initialize a dictionary to store agent data\n",
        "    agent= {f\"agent_{i}\": {} for i in range(n_agents)}\n",
        "\n",
        "    for j in range(n_agents):\n",
        "          # Initialize lists to store data for each agent within the batch\n",
        "        agent_i_date = []\n",
        "        agent_i_action = []\n",
        "        agent_i_rew = []\n",
        "        agent_i_new_obs = []\n",
        "\n",
        "        for convo_dim in range(env.batch_size[0]):\n",
        "            current_td = env.gen_params(env.batch_size)\n",
        "            obs = td['params', 'obsState&Fuel'].clone().detach()\n",
        "            reward = td['params', 'rewardState&reward'].clone().detach()\n",
        "            action = td['params', 'actionState&action'].clone().detach()\n",
        "            Date = td['params', 'Date'].clone().detach()\n",
        "\n",
        "            new_obs = torch.add(obs, torch.stack([action_i * reward_i for action_i, reward_i in zip(action, reward)]))\n",
        "            new_obs = torch.reshape(new_obs, (13,))\n",
        "\n",
        "                # Append data to agent-specific lists\n",
        "            agent_i_new_obs.append(new_obs)\n",
        "            agent_i_rew.append(reward)\n",
        "            agent_i_date.append(Date)\n",
        "            agent_i_action.append(action)\n",
        "\n",
        "            # Stack data for the current agent\n",
        "        en_Date = torch.stack(agent_i_date, dim=0) if agent_i_date else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        en_action = torch.stack(agent_i_action, dim=0) if agent_i_action else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        en_reward = torch.stack(agent_i_rew, dim=0)\n",
        "        en_new_obs = torch.stack(agent_i_new_obs, dim=0) if agent_i_new_obs else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        #print(en_new_obs.shape)\n",
        "\n",
        "            # Expansion for batch size and convolution\n",
        "        expanded_agent_new_obs = en_new_obs.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim)) # Corrected expand call\n",
        "        expanded_agent_reward = en_reward.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim)) # Corrected expand call\n",
        "        expanded_agent_action = en_action.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim))  # Corrected expand call\n",
        "\n",
        "        expanded_agent_Date = en_Date.reshape(*en_Date.shape, 1, 1).expand(tuple(env.batch_size) + (en_Date.shape[-1], *env.convo_dim)) # Corrected expand call\n",
        "\n",
        "\n",
        "\n",
        "        # Store data in agent-specific dictionary\n",
        "        agent[f\"agent_{j}\"][\"observation\"] = {\"observat\": expanded_agent_new_obs,\"position_key\": expanded_agent_Date}\n",
        "          # Ensure 'reward' is under the \"agents\" key\n",
        "        agent[f\"agent_{j}\"][\"reward\"] = expanded_agent_reward\n",
        "        agent[f\"agent_{j}\"][\"action\"] = expanded_agent_action  # Assuming you need action here\n",
        "        #print( agent[f\"agent_{j}\"][\"reward\"] )\n",
        "\n",
        "\n",
        "    dones = torch.zeros((*env.batch_size, 1), dtype=torch.bool)\n",
        "\n",
        "    next_tensordict = TensorDict(\n",
        "        {\n",
        "            \"agents\": agent,\n",
        "            \"terminated\": dones.clone(),\n",
        "        },\n",
        "        batch_size=env.batch_size,\n",
        "        device=env.device,\n",
        "    )\n",
        "\n",
        "    # Explicitly setting the reward key\n",
        "    #next_tensordict[\"next\", \"reward\"] = next_tensordict[\"agents\", \"reward\"]\n",
        "\n",
        "    return next_tensordict\n",
        "\n",
        "\n",
        "def _reset(self, tensordict=None):\n",
        "    if tensordict is not None and \"_reset\" not in tensordict:\n",
        "        tensordict.clear()\n",
        "    else:\n",
        "        tensordict = TensorDict({}, batch_size=self.batch_size, device=self.device)\n",
        "\n",
        "        td = self.gen_params(self.batch_size)\n",
        "\n",
        "        obs_max = td['params', 'obsState&Fuel_max'].clone().detach()\n",
        "        obs_min = td['params', 'obsState&Fuel_min'].clone().detach()\n",
        "        Date = td['params', 'Date_max'].clone().detach()\n",
        "\n",
        "        n_agents = self.n_agents\n",
        "\n",
        "        # Create a dictionary to store agent data\n",
        "        agent_data = {f\"agent_{i}\": {} for i in range(n_agents)}\n",
        "\n",
        "        for i in range(n_agents):\n",
        "            random_numbers = torch.rand(1, device=self.device)\n",
        "            obs = torch.add(torch.mul(random_numbers, torch.add(obs_max, -obs_min)), obs_min)\n",
        "            Date=  td['params', 'Date_max'].clone().detach()\n",
        "\n",
        "            obs = obs.reshape (tuple(self.batch_size) + (13,))\n",
        "            Date = Date.reshape (tuple(self.batch_size) + (1,))\n",
        "\n",
        "\n",
        "\n",
        "            # Expand to include batch size\n",
        "            expanded_obs = obs.unsqueeze(-1).unsqueeze(-1).expand(tuple(self.batch_size) + ( 13, *self.convo_dim))\n",
        "            expanded_Date = Date.unsqueeze(-1).unsqueeze(-1).expand(tuple(self.batch_size) + (1, *self.convo_dim))\n",
        "\n",
        "            # Store data in the agent_data dictionary\n",
        "            agent_data[f\"agent_{i}\"][\"observation\"] = {\n",
        "                \"observat\": expanded_obs,\n",
        "                \"position_key\": expanded_Date,\n",
        "            }\n",
        "\n",
        "        # Create the tensordict with agent data\n",
        "        expanded_agent_observations = TensorDict(\n",
        "            {\"agents\": agent_data},\n",
        "            batch_size=self.batch_size,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        dones = torch.zeros((*self.batch_size, 1), dtype=torch.bool, device=self.device)\n",
        "\n",
        "        # Construct the final tensordict\n",
        "        return TensorDict(\n",
        "            {\n",
        "                **expanded_agent_observations,  # Include agent data\n",
        "                \"terminated\": dones.clone()\n",
        "            },\n",
        "            batch_size=self.batch_size,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def make_composite_from_td(td):\n",
        "    if isinstance(td, TensorDictBase):\n",
        "        return CompositeSpec({key: make_composite_from_td(tensor) for key, tensor in td.items()})\n",
        "    if not isinstance(td, TensorDictBase):\n",
        "        #This is the fixed line\n",
        "        composite = UnboundedContinuousTensorSpec(\n",
        "                    dtype=td.dtype, device=td.device, shape=td.shape\n",
        "                )\n",
        "\n",
        "        return composite\n",
        "\n",
        "\n",
        "def _make_spec(self, td_agents):\n",
        "\n",
        "    action_specs = []\n",
        "    observation_specs = []\n",
        "    reward_specs = []\n",
        "    info_specs = []\n",
        "    done_specs = []\n",
        "    discount_specs = []\n",
        "\n",
        "    td_agents = self.gen_params()  # Or td_agents = self.gen_params() if no batch size is needed\n",
        "    agent = {f\"agent_{i}\": {} for i in range(self.n_agents)}\n",
        "\n",
        "    obs_max = td_agents['params', 'obsState&Fuel_max'].clone().detach()\n",
        "    obs_min = td_agents['params', 'obsState&Fuel_min'].clone().detach()\n",
        "    reward_max = td_agents['params', 'rewardState&reward_max'].clone().detach()\n",
        "    reward_min = td_agents['params', 'rewardState&reward_min'].clone().detach()\n",
        "    action_max = td_agents['params', 'actionState&action_max'].clone().detach()\n",
        "    action_min = td_agents['params', 'actionState&action_min'].clone().detach()\n",
        "    Date_max = td_agents['params', 'Date_max'].clone().detach()\n",
        "    Date_min = td_agents['params', 'Date_min'].clone().detach()\n",
        "\n",
        "    \"\"\"\n",
        "    Reshapes and expands a tensor to include batch size and convolution dimensions.\n",
        "    Batch size is now the leading dimension.\n",
        "\n",
        "    Args:\n",
        "        tensor: The input tensor.\n",
        "        shape: The desired shape excluding batch size and convolution dimensions.\n",
        "        convo_dim: The convolution dimensions.\n",
        "        batch_size: The batch size.\n",
        "\n",
        "    Returns:\n",
        "        The reshaped and expanded tensor.\n",
        "    \"\"\"\n",
        "    def reshape_and_expand(tensor, shape, convo_dim, batch_size):\n",
        "        expanded_tensor = tensor.repeat(*batch_size, *torch.ones(len(shape), dtype=int),*self.convo_dim)\n",
        "        reshaped_tensor = expanded_tensor.reshape((*batch_size, *shape, *self.convo_dim))\n",
        "        return reshaped_tensor.clone().detach()\n",
        "\n",
        "    obs_max = reshape_and_expand(obs_max, (13,), self.convo_dim,self.batch_size)\n",
        "    obs_min = reshape_and_expand(obs_min, (13,), self.convo_dim,self.batch_size)\n",
        "    reward_max = reshape_and_expand(reward_max , (13,), self.convo_dim,self.batch_size)\n",
        "    reward_min = reshape_and_expand(reward_min, (13,), self.convo_dim,self.batch_size)\n",
        "    action_max = reshape_and_expand(action_max, (13,), self.convo_dim,self.batch_size)\n",
        "    action_min = reshape_and_expand(action_min, (13,), self.convo_dim,self.batch_size)\n",
        "    Date_max = reshape_and_expand(Date_max, (1,), self.convo_dim,self.batch_size)\n",
        "    Date_min = reshape_and_expand(Date_min, (1,), self.convo_dim,self.batch_size)\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(self.n_agents):\n",
        "        shape = obs_max[i].shape  # Or the shape of reward_max[i], Date_max[i], etc. - they should be the same\n",
        "        shape1= Date_max[i].shape\n",
        "        agent[f\"agent_{i}\"][\"action_spec\"] = DiscreteTensorSpec(n=3, shape=tuple(shape), dtype=torch.float32)\n",
        "        # Applying sum to reward_min and reward_max to match the reward shape after sum in _step\n",
        "        agent[f\"agent_{i}\"][\"observat_spec\"] = BoundedTensorSpec(low=obs_min[i], high=obs_max[i], shape=tuple(shape), dtype=torch.float32)\n",
        "        agent[f\"agent_{i}\"][\"Date_spec\"] = BoundedTensorSpec(low=Date_min[i], high=Date_max[i], shape=tuple(shape1), dtype=torch.float32)\n",
        "        agent[f\"agent_{i}\"][\"reward_spec\"] = BoundedTensorSpec(low=reward_min[i], high=reward_max[i], shape=tuple(shape), dtype=torch.float32)\n",
        "\n",
        "    self.observation_spec = CompositeSpec(\n",
        "        agents=CompositeSpec(\n",
        "            observat=CompositeSpec({k: v[\"observat_spec\"] for k, v in agent.items()}),\n",
        "            position_key=CompositeSpec({k: v[\"Date_spec\"] for k, v in agent.items()}),\n",
        "        ),\n",
        "          shape=torch.Size([10,]), # comment this line\n",
        "        #batch_size=self.batch_size, # comment this line\n",
        "        device=self.device,\n",
        "    )\n",
        "\n",
        "    self.reward_spec = CompositeSpec(\n",
        "        agents=CompositeSpec(\n",
        "            {k: v[\"reward_spec\"] for k, v in agent.items()}\n",
        "        ),\n",
        "        #batch_size=self.batch_size, # comment this line\n",
        "        device=self.device,\n",
        "    )\n",
        "\n",
        "    self.full_action_spec = CompositeSpec(\n",
        "        agents=CompositeSpec(\n",
        "            {k: v[\"action_spec\"] for k, v in agent.items()}\n",
        "        ),\n",
        "        #batch_size=self.batch_size, # comment this line\n",
        "        device=self.device,\n",
        "    )\n",
        "\n",
        "    self.done_spec = DiscreteTensorSpec(n=2, shape=torch.Size([1]), dtype=torch.bool).to(self.device)\n",
        "    self.discount_spec = BoundedTensorSpec(low=0.0, high=1.0, shape=torch.Size([1]), dtype=torch.float32).to(self.device)\n",
        "\n",
        "    # Move the spec to the device first\n",
        "    env.observation_spec = self.observation_spec.to(self.device)\n",
        "    env.reward_spec = self.reward_spec.to(self.device)\n",
        "    env.full_action_spec = self.full_action_spec.to(self.device)\n",
        "    env.discount_spec = self.discount_spec.to(self.device)\n",
        "\n",
        "    # Applying batch size after moving to device\n",
        "    # Update: Expand the specs after the assignment is done\n",
        "    self.observation_spec = self.observation_spec.expand(self.batch_size) # Convert to torch.Size # Expand observation_spec to the batch size\n",
        "    self.reward_spec = self.reward_spec.expand(self.batch_size)  # Expand reward_spec to the batch size\n",
        "    self.full_action_spec = self.full_action_spec.expand(self.batch_size) # Expand full_action_spec to the batch size\n",
        "    self.done_spec = self.done_spec.expand(self.batch_size) # Expand done_spec to the batch size\n",
        "    self.discount_spec = self.discount_spec.expand(self.batch_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    self.output_spec = CompositeSpec(full_done_spec=self.done_spec, full_reward_spec=self.reward_spec)  # Define output_spec here\n",
        "\n",
        "    #self.done_spec = DiscreteTensorSpec(n=2, shape=torch.Size([1]), dtype=torch.bool).to(self.device)# Spec for the 'done' flag\n",
        "    #self.discount_spec = BoundedTensorSpec(low=0.0, high=1.0, shape=torch.Size([1]), dtype=torch.float32).to(self.device) # Spec for the discount factor\n",
        "\n",
        "     # Add this line to set output_spec:\n",
        "    #self.output_spec = CompositeSpec(full_done_spec=self.done_spec, full_reward_spec=self.reward_spec)\n",
        "      # Move the spec to the device first\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def gen_params(batch_size=torch.Size()) -> TensorDictBase:\n",
        "    if batch_size is None or (isinstance(batch_size, list) and len(batch_size) == 0):\n",
        "        batch_size = torch.Size([])\n",
        "    data_path = '/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/DataDic.pt'\n",
        "    data_columns = ['Forex', 'WTI', 'Brent', 'OPEC', 'Fuelprice5', 'Fuelprice6', 'Fuelprice7', 'Fuelprice8', 'Fuelprice9', 'Fuelprice10', 'Fuelprice11', 'Fuelprice12', 'Fuelprice13',\n",
        "                    'reward0', 'reward1', 'reward2', 'reward3', 'reward4', 'reward5', 'reward6', 'reward7', 'reward8', 'reward9', 'reward10', 'reward11', 'reward12',\n",
        "                    'action0', 'action1', 'action2', 'action3', 'action4', 'action5', 'action6', 'action7', 'action8', 'action9', 'action10', 'action11', 'action12', 'Date']\n",
        "    envv = DDataenv(data_path, data_columns)  # Assuming DDataenv is your data environment class\n",
        "\n",
        "    ac = envv.get_observation()\n",
        "\n",
        "    if batch_size:\n",
        "       # Change here: Convert batch_size to a tuple if it's not already\n",
        "        if not isinstance(batch_size, tuple):\n",
        "            batch_size = (batch_size,)  # Convert to tuple\n",
        "        ac = {k: torch.tensor(v).expand(*batch_size, *torch.tensor(v).shape) for k, v in ac.items()}\n",
        "\n",
        "    td = TensorDict({\"params\": ac}, batch_size=batch_size, device=torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    if batch_size:\n",
        "        td = td.expand(batch_size).contiguous()\n",
        "    return td\n",
        "\n",
        "\n",
        "def _set_seed(self, seed: 45):\n",
        "    self.rng = torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "def full_info_spec(self):\n",
        "    return {}\n",
        "\n",
        "\n",
        "def group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "    return {\"agents\": [agent[\"name\"] for agent in env.agents]}\n",
        "\n",
        "\n",
        "\n",
        "class AnFuelpriceEnv(EnvBase):\n",
        "    metadata = {\n",
        "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
        "        \"render_fps\": 30,\n",
        "    }\n",
        "    Scenario = \"USDATA_1\"\n",
        "    batch_locked = False\n",
        "\n",
        "    def __init__(self, td_params=None, seed=None, device=\"cpu\", categorical_actions=True, continuous_actions=True, **kwargs):\n",
        "        if td_params is None:\n",
        "            td_params = self.gen_params()\n",
        "\n",
        "        _ = kwargs.pop(\"scenario\", None)\n",
        "\n",
        "\n",
        "\n",
        "        self.n_agents = 3\n",
        "        self.convo_dim = [9, 9]\n",
        "        self.batch_size = (10,10) # Corrected batch size to a single-element tuple\n",
        "        self.batch_size_tuple = torch.Size([self.batch_size]) if isinstance(self.batch_size, int) else torch.Size(self.batch_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        super().__init__(device=device, batch_size=self.batch_size,)\n",
        "\n",
        "\n",
        "        self._make_spec(td_params)\n",
        "\n",
        "        if seed is None:\n",
        "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
        "        self.set_seed(seed)\n",
        "\n",
        "    def get_supports_continuous_actions(self):\n",
        "        return hasattr(env.full_action_spec, 'shape') and len(env.full_action_spec.shape) > 0\n",
        "\n",
        "    def get_supports_discrete_actions(self):\n",
        "        return isinstance(env.full_action_spec, DiscreteTensorSpec)\n",
        "\n",
        "    def get_observation_spec(self):\n",
        "        return self.observation_spec\n",
        "\n",
        "    def get_full_action_spec(self):\n",
        "        return self.full_action_spec\n",
        "\n",
        "    def get_full_reward_spec(self):\n",
        "        return self.full_reward_spec\n",
        "\n",
        "    def get_done_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    def get_group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "        return {\"agents\": [agent[\"name\"] for agent in env.agents]}\n",
        "\n",
        "    def get_full_info_spec(self):\n",
        "        return {}\n",
        "\n",
        "    def get_discount_spec(self):\n",
        "        return self.discount_spec\n",
        "\n",
        "    @property\n",
        "    def terminated_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    @property\n",
        "    def truncated_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    @property\n",
        "    def get_env_name(self):\n",
        "        return \"AnFuelpriceEnv\"\n",
        "\n",
        "    gen_params = staticmethod(gen_params)\n",
        "    _make_spec = _make_spec\n",
        "    _reset = _reset\n",
        "    _step = staticmethod(_step)\n",
        "    _set_seed = _set_seed\n",
        "    full_info_spec = full_info_spec\n",
        "\n",
        "\n",
        "env = AnFuelpriceEnv()\n",
        "\n",
        "print(\"\\n*action_spec:\", env.full_action_spec)\n",
        "print(\"\\n*reward_spec:\", env.full_reward_spec)\n",
        "print(\"\\n*done_spec:\", env.full_done_spec)\n",
        "print(\"\\n*observation_spec:\", env.observation_spec)\n",
        "\n",
        "print(\"\\n-action_keys:\", env.action_keys)\n",
        "print(\"\\n-reward_keys:\", env.reward_keys)\n",
        "print(\"\\n-done_keys:\", env.done_keys)\n",
        "\n",
        "print(\"input_spec:\", env.input_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "print(\"action_spec (as defined by input_spec):\", env.action_spec)\n",
        "td = env.reset()\n",
        "print(\"reset tensordict\", td)\n",
        "\n",
        "check_env_specs(env)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "8A2z232KpGZT",
        "outputId": "cf2e84d2-20fd-403f-dd11-3034ca319bcb"
      },
      "id": "8A2z232KpGZT",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The DiscreteTensorSpec has been deprecated and will be removed in v0.8. Please use Categorical instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.8. Please use Bounded instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The value of spec.shape (torch.Size([10])) must match the env batch size (torch.Size([10, 10])).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-fe58af2bab31>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnFuelpriceEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n*action_spec:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_action_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mauto_reset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto_reset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mauto_reset_replace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto_reset_replace\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0minstance\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEnvBase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_cache\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-fe58af2bab31>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, td_params, seed, device, categorical_actions, continuous_actions, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-fe58af2bab31>\u001b[0m in \u001b[0;36m_make_spec\u001b[0;34m(self, td_agents)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"agent_{i}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reward_spec\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoundedTensorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward_min\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward_max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     self.observation_spec = CompositeSpec(\n\u001b[0m\u001b[1;32m    267\u001b[0m         agents=CompositeSpec(\n\u001b[1;32m    268\u001b[0m             \u001b[0mobservat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCompositeSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observat_spec\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    756\u001b[0m                 \u001b[0;34m\" underscore).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             )\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2027\u001b[0m                     \u001b[0;31m# === HACK END ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2028\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2029\u001b[0;31m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2031\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_locked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_spec_lock_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_locked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mobservation_spec\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1669\u001b[0m             )\n\u001b[1;32m   1670\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1671\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1672\u001b[0m                 \u001b[0;34mf\"The value of spec.shape ({value.shape}) must match the env batch size ({self.batch_size}).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: The value of spec.shape (torch.Size([10])) must match the env batch size (torch.Size([10, 10]))."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict as TypingDict, Any, Union, List, Optional\n",
        "from torchrl.envs import EnvBase, TransformedEnv\n",
        "from torchrl.data import CompositeSpec, BoundedTensorSpec, DiscreteTensorSpec, UnboundedContinuousTensorSpec\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "from torchrl.envs.utils import check_env_specs\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "import os  # Import os for file existence check\n",
        "from typing import Dict, List # Import Dict and List here\n",
        "from torchrl.envs.transforms import RewardSum #changed the location of the import\n",
        "\n",
        "class DDataenv:\n",
        "    def __init__(self, data_path: str, data_columns: List[str], data_type: Any = np.float32):\n",
        "        self.data_path = data_path\n",
        "        self.data_columns = data_columns\n",
        "        self.data_type = data_type\n",
        "        self.data = None\n",
        "\n",
        "    def load_data(self) -> pd.DataFrame:\n",
        "        if not os.path.exists(self.data_path):\n",
        "            raise FileNotFoundError(f\"Data file not found at {self.data_path}\")\n",
        "\n",
        "        with open(self.data_path, 'rb') as f:\n",
        "            self.data = torch.load(f, weights_only=False)\n",
        "\n",
        "        self.data = np.array(self.data)\n",
        "        if len(self.data.shape) >= 3:\n",
        "            self.data = self.data.reshape(self.data.shape[1], self.data.shape[2])\n",
        "\n",
        "        if not isinstance(self.data, pd.DataFrame):\n",
        "            self.data = pd.DataFrame(self.data, columns=self.data_columns)\n",
        "\n",
        "        return self.data\n",
        "\n",
        "    def get_observation(self) -> TypingDict[str, Union[np.ndarray, TypingDict[str, float]]]:\n",
        "        if self.data is None:\n",
        "            self.load_data()\n",
        "\n",
        "        random_row_index = np.random.choice(self.data.shape[0], 1, replace=False)[0]\n",
        "        observation = self.data.iloc[random_row_index, :].to_numpy().astype(self.data_type)\n",
        "        describe_data = self.data.describe()\n",
        "\n",
        "        observation_dict = {\n",
        "            'obsState&Fuel': observation[0:13],\n",
        "            'Date': observation[-1],\n",
        "            'rewardState&reward': observation[13:26],\n",
        "            'actionState&action': observation[26:39],\n",
        "            'obsState&Fuel_max': describe_data.loc['max'][0:13].values,\n",
        "            'obsState&Fuel_min': describe_data.loc['min'][0:13].values,\n",
        "            'Date_max': describe_data['Date'].max(),\n",
        "            'Date_min': describe_data['Date'].min(),\n",
        "            'rewardState&reward_max': describe_data.loc['max'][13:26].values,\n",
        "            'rewardState&reward_min': describe_data.loc['min'][13:26].values,\n",
        "            'actionState&action_max': describe_data.loc['max'][26:39].values,\n",
        "            'actionState&action_min': describe_data.loc['min'][26:39].values,\n",
        "        }\n",
        "        return observation_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _step(tensordict):\n",
        "    td = env.gen_params()\n",
        "    n_agents = env.n_agents\n",
        "\n",
        "\n",
        "    # Initialize a dictionary to store agent data\n",
        "    agent= {f\"agent_{i}\": {} for i in range(n_agents)}\n",
        "\n",
        "    for j in range(n_agents):\n",
        "          # Initialize lists to store data for each agent within the batch\n",
        "        agent_i_date = []\n",
        "        agent_i_action = []\n",
        "        agent_i_rew = []\n",
        "        agent_i_new_obs = []\n",
        "\n",
        "        for convo_dim in range(env.batch_size[0]):\n",
        "            current_td = env.gen_params(env.batch_size)\n",
        "            obs = td['params', 'obsState&Fuel'].clone().detach()\n",
        "            reward = td['params', 'rewardState&reward'].clone().detach()\n",
        "            action = td['params', 'actionState&action'].clone().detach()\n",
        "            Date = td['params', 'Date'].clone().detach()\n",
        "\n",
        "            new_obs = torch.add(obs, torch.stack([action_i * reward_i for action_i, reward_i in zip(action, reward)]))\n",
        "            new_obs = torch.reshape(new_obs, (13,))\n",
        "\n",
        "                # Append data to agent-specific lists\n",
        "            agent_i_new_obs.append(new_obs)\n",
        "            agent_i_rew.append(reward)\n",
        "            agent_i_date.append(Date)\n",
        "            agent_i_action.append(action)\n",
        "\n",
        "            # Stack data for the current agent\n",
        "        en_Date = torch.stack(agent_i_date, dim=0) if agent_i_date else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        en_action = torch.stack(agent_i_action, dim=0) if agent_i_action else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        en_reward = torch.stack(agent_i_rew, dim=0)\n",
        "        en_new_obs = torch.stack(agent_i_new_obs, dim=0) if agent_i_new_obs else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        #print(en_new_obs.shape)\n",
        "\n",
        "            # Expansion for batch size and convolution\n",
        "        expanded_agent_new_obs = en_new_obs.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim)) # Corrected expand call\n",
        "        expanded_agent_reward = en_reward.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim)) # Corrected expand call\n",
        "        expanded_agent_action = en_action.reshape(*en_new_obs.shape,1,1).expand(tuple(env.batch_size) + ( 13, *env.convo_dim))  # Corrected expand call\n",
        "\n",
        "        expanded_agent_Date = en_Date.reshape(*en_Date.shape, 1, 1).expand(tuple(env.batch_size) + (en_Date.shape[-1], *env.convo_dim)) # Corrected expand call\n",
        "\n",
        "\n",
        "        en_reward = torch.stack(agent_i_rew, dim=0)\n",
        "        if en_reward is None:\n",
        "            # Log or raise an error if en_reward is None\n",
        "            print(\"Warning: en_reward is None for agent\", j)\n",
        "            en_reward = torch.zeros(env.batch_size, 13, device=env.device)  # Or assign a default value\n",
        "\n",
        "        # Ensure en_reward has the expected shape:\n",
        "        expected_reward_shape = (env.batch_size[0], 13)  # or whatever the expected shape is\n",
        "        if en_reward.shape != expected_reward_shape:\n",
        "            # Log or raise an error if the shape is incorrect\n",
        "            print(\"Warning: en_reward shape mismatch for agent\", j, \"Expected:\", expected_reward_shape, \"Actual:\", en_reward.shape)\n",
        "            en_reward = torch.zeros(expected_reward_shape, device=env.device)  # Or assign a default value\n",
        "\n",
        "\n",
        "        # Store data in agent-specific dictionary\n",
        "        agent[f\"agent_{j}\"][\"observation\"] = {\"observat\": expanded_agent_new_obs,\"position_key\": expanded_agent_Date}\n",
        "          # Ensure 'reward' is under the \"agents\" key\n",
        "        agent[f\"agent_{j}\"][\"reward\"] = expanded_agent_reward ### Rename reward an da calculate one feature scaler reward from13 feature using sumation\n",
        "        agent[f\"agent_{j}\"][\"action\"] = expanded_agent_action  # Assuming you need action here\n",
        "        agent[f\"agent_{j}\"][\"reward\"] = torch.sum(expanded_agent_reward) #Sum the 13 feature rewards\n",
        "        # Change the expand call\n",
        "        expanded_agent_reward = agent[f\"agent_{j}\"][\"reward\"].reshape(*self.batch_size, 1, *self.convo_dim)\n",
        "\n",
        "\n",
        "       #print( agent[f\"agent_{j}\"][\"reward\"] )\n",
        "\n",
        "    #reward_vector = torch.zeros(13, device=env.device, dtype=torch.float32)\n",
        "\n",
        "    ################################reward calculation######################################################3\n",
        "\n",
        "    #def calculate_reward(feature_vector):\n",
        "            # Example: Sum the features across the convolutional dimensions\n",
        "    #    reward = torch.sum(feature_vector, dim=(2, 3)) # Sum across channels and spatial dimensions\n",
        "    #    return reward\n",
        "     # Calculate the reward for each agent (considering batch size)\n",
        "     #   for j in range(self.n_agents):\n",
        "      #      feature_vector = agent[f\"agent_{j}\"][\"reward13\"] # Assuming this is your 13-feature vector reward\n",
        "\n",
        "            # Apply the reward function to get the reward value (considering batch size)\n",
        "   #         reward_value = calculate_reward(feature_vector)\n",
        "\n",
        "            # Ensure reward_value has the correct shape (batch_size, 13)\n",
        "   #         reward_value = reward_value.view(*self.batch_size,1, *self.convo_dim) # Assuming batch_size is a tuple\n",
        "\n",
        "            # Use the calculated reward value in the next_tensordict\n",
        "\n",
        "   #         agent[f\"agent_{j}\"][\"reward\"] = reward_value\n",
        "      ########################################################################################################\n",
        "    dones = torch.zeros((*env.batch_size, 1), dtype=torch.bool)\n",
        "\n",
        "    next_tensordict = TensorDict(\n",
        "        {\n",
        "            \"agents\": {\n",
        "                f\"agent_{j}\": {\n",
        "                    \"observation\": agent[f\"agent_{j}\"][\"observation\"],\n",
        "\n",
        "                    \"reward\":  agent[f\"agent_{j}\"][\"reward\"], # Ensure reward is present and under \"agents\"\n",
        "                }  for j in range(env.n_agents)\n",
        "\n",
        "            },\n",
        "            \"terminated\": dones.clone(),\n",
        "\n",
        "        },\n",
        "        batch_size=env.batch_size,\n",
        "        device=env.device,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    return next_tensordict\n",
        "\n",
        "\n",
        "def _reset(self, tensordict=None):\n",
        "    if tensordict is not None and \"_reset\" not in tensordict:\n",
        "        tensordict.clear()\n",
        "    else:\n",
        "        tensordict = TensorDict({}, batch_size=self.batch_size, device=self.device)\n",
        "\n",
        "        td = self.gen_params(self.batch_size)\n",
        "\n",
        "        obs_max = td['params', 'obsState&Fuel_max'].clone().detach()\n",
        "        obs_min = td['params', 'obsState&Fuel_min'].clone().detach()\n",
        "        Date = td['params', 'Date_max'].clone().detach()\n",
        "\n",
        "        n_agents = self.n_agents\n",
        "\n",
        "        # Create a dictionary to store agent data\n",
        "        agent_data = {f\"agent_{i}\": {} for i in range(n_agents)}\n",
        "\n",
        "        for i in range(n_agents):\n",
        "            random_numbers = torch.rand(1, device=self.device)\n",
        "            obs = torch.add(torch.mul(random_numbers, torch.add(obs_max, -obs_min)), obs_min)\n",
        "            Date=  td['params', 'Date_max'].clone().detach()\n",
        "\n",
        "            obs = obs.reshape (tuple(self.batch_size) + (13,))\n",
        "            Date = Date.reshape (tuple(self.batch_size) + (1,))\n",
        "\n",
        "\n",
        "\n",
        "            # Expand to include batch size\n",
        "            expanded_obs = obs.unsqueeze(-1).unsqueeze(-1).expand(tuple(self.batch_size) + ( 13, *self.convo_dim))\n",
        "            expanded_Date = Date.unsqueeze(-1).unsqueeze(-1).expand(tuple(self.batch_size) + (1, *self.convo_dim))\n",
        "\n",
        "            # Store data in the agent_data dictionary\n",
        "            agent_data[f\"agent_{i}\"][\"observation\"] = {\n",
        "                \"observat\": expanded_obs,\n",
        "                \"position_key\": expanded_Date,\n",
        "            }\n",
        "\n",
        "        # Create the tensordict with agent data\n",
        "        expanded_agent_observations = TensorDict(\n",
        "            {\"agents\": agent_data},\n",
        "            batch_size=self.batch_size,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        dones = torch.zeros((*self.batch_size, 1), dtype=torch.bool, device=self.device)\n",
        "\n",
        "        # Construct the final tensordict\n",
        "        return TensorDict(\n",
        "            {\n",
        "                **expanded_agent_observations,  # Include agent data\n",
        "                \"terminated\": dones.clone()\n",
        "            },\n",
        "            batch_size=self.batch_size,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def make_composite_from_td(td):\n",
        "    composite = CompositeSpec(\n",
        "        {\n",
        "            key: make_composite_from_td(tensor)\n",
        "            if isinstance(tensor, TensorDictBase)\n",
        "            else UnboundedContinuousTensorSpec(\n",
        "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
        "            )\n",
        "            for key, tensor in td.items()\n",
        "        },\n",
        "        shape=td.shape,\n",
        "    )\n",
        "    return composite\n",
        "\n",
        "def _make_spec(self, td_agents):\n",
        "\n",
        "    action_spec = []\n",
        "    observation_spec = []\n",
        "    reward_spec = []\n",
        "    info_spec = []\n",
        "\n",
        "\n",
        "    td_agents = self.gen_params()  # Or td_agents = self.gen_params() if no batch size is needed\n",
        "    agent = {f\"agent_{i}\": {} for i in range(self.n_agents)}\n",
        "\n",
        "    obs_max = td_agents['params', 'obsState&Fuel_max'].clone().detach()\n",
        "    obs_min = td_agents['params', 'obsState&Fuel_min'].clone().detach()\n",
        "    reward_max = td_agents['params', 'rewardState&reward_max'].clone().detach()\n",
        "    reward_min = td_agents['params', 'rewardState&reward_min'].clone().detach()\n",
        "    action_max = td_agents['params', 'actionState&action_max'].clone().detach()\n",
        "    action_min = td_agents['params', 'actionState&action_min'].clone().detach()\n",
        "    Date_max = td_agents['params', 'Date_max'].clone().detach()\n",
        "    Date_min = td_agents['params', 'Date_min'].clone().detach()\n",
        "\n",
        "    # Reshape the tensors to (n_agents, 13, *convo_dim) before the loop\n",
        "    # Assuming obs_max, obs_min, reward_max, reward_min, action_max, action_min have shape (13,)\n",
        "    # and Date_max, Date_min have shape (1,)\n",
        "\n",
        "    obs_max = obs_max.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    obs_min = obs_min.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    reward_max = reward_max.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    reward_min = reward_min.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    action_max = action_max.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    action_min = action_min.reshape(1, 13, 1, 1).expand(self.n_agents, 13, *self.convo_dim)\n",
        "    Date_max = Date_max.reshape(1, 1, 1, 1).expand(self.n_agents, 1, *self.convo_dim)\n",
        "    Date_min = Date_min.reshape(1, 1, 1, 1).expand(self.n_agents, 1, *self.convo_dim)\n",
        "\n",
        "\n",
        "    for i in range(self.n_agents):\n",
        "        # Creating action, reward, observation, and date specs for each agent\n",
        "         # Creating action, reward, observation, and date specs for each agent\n",
        "        agent[f\"agent_{i}\"][\"action_spec\"] = DiscreteTensorSpec(n=3, shape=action_max[i].shape, dtype=torch.float32)  # Use action_max[i].shape directly\n",
        "        agent[f\"agent_{i}\"][\"reward_spec\"] = BoundedTensorSpec(low=reward_min[i], high=reward_max[i], shape=reward_max[i].shape, dtype=torch.float32)  # Use reward_min[i], reward_max[i], and reward_max[i].shape directly\n",
        "        agent[f\"agent_{i}\"][\"observat_spec\"] = BoundedTensorSpec(low=obs_min[i], high=obs_max[i], shape=obs_max[i].shape, dtype=torch.float32)  # Use obs_min[i], obs_max[i], and obs_max[i].shape directly\n",
        "        agent[f\"agent_{i}\"][\"Date_spec\"] = BoundedTensorSpec(low=Date_min[i], high=Date_max[i], shape=Date_max[i].shape, dtype=torch.float32)  # Use Date_min[i], Date_max[i], and Date_max[i].shape directly\n",
        "\n",
        "        # Calculate the reward value by summing across the convolutional dimensions\n",
        "        reward_value = torch.sum(agent[f\"agent_{i}\"][\"reward_spec\"].low) # sum the reward.low along all axes other than batch axis.\n",
        "        # Assuming low and high are the same, otherwise sum reward.high similarly and define BoundedTensorSpec\n",
        "        agent[f\"agent_{i}\"][\"reward_spec\"] = UnboundedContinuousTensorSpec(shape=(1, *self.convo_dim), dtype=torch.float32)\n",
        "\n",
        "    # Creating CompositeSpecs for action, reward, observation, and date\n",
        "    self.action_spec_updated = CompositeSpec({k: v[\"action_spec\"] for k, v in agent.items()})\n",
        "    self.reward_spec_updated = CompositeSpec({k: v[\"reward_spec\"] for k, v in agent.items()})\n",
        "    self.observat_spec_updated = CompositeSpec({k: v[\"observat_spec\"] for k, v in agent.items()})\n",
        "    self.Date_spec_updated = CompositeSpec({k: v[\"Date_spec\"] for k, v in agent.items()})\n",
        "\n",
        "    # Creating unbatched observation, action, and reward specs\n",
        "    unbatched_observation_spec = CompositeSpec(\n",
        "        agents=CompositeSpec(\n",
        "            observat=self.observat_spec_updated,\n",
        "            position_key=self.Date_spec_updated,\n",
        "        )\n",
        "    )\n",
        "    unbatched_action_spec =self.action_spec_updated\n",
        "    unbatched_reward_spec =self. reward_spec_updated\n",
        "    unbatched_done_spec = DiscreteTensorSpec(n=2, shape=torch.Size([1]), dtype=torch.bool).to(self.device)\n",
        "    # # Expanding specs to include batch size\n",
        "    print( unbatched_action_spec)\n",
        "    self.action_spec = unbatched_action_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "    self.observation_spec = unbatched_observation_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "    self.reward_spec = unbatched_reward_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "    self.done_spec = unbatched_done_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "\n",
        "\n",
        "    # Creating a CompositeSpec to represent the environment's spec\n",
        "    return CompositeSpec(\n",
        "        agents=CompositeSpec(\n",
        "            observation=CompositeSpec(\n",
        "                observat=self.observation_spec[\"agents\"][\"observat\"],\n",
        "                position_key=self.observation_spec[\"agents\"][\"position_key\"],\n",
        "            ),\n",
        "            reward=self.reward_spec,\n",
        "            action=self.action_spec,\n",
        "\n",
        "        ),\n",
        "        terminated=self.done_spec,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Creating unbatched done spec\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def gen_params(batch_size=torch.Size()) -> TensorDictBase:\n",
        "    if batch_size is None or (isinstance(batch_size, list) and len(batch_size) == 0):\n",
        "        batch_size = torch.Size([])\n",
        "    data_path = '/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/DataDic.pt'\n",
        "    data_columns = ['Forex', 'WTI', 'Brent', 'OPEC', 'Fuelprice5', 'Fuelprice6', 'Fuelprice7', 'Fuelprice8', 'Fuelprice9', 'Fuelprice10', 'Fuelprice11', 'Fuelprice12', 'Fuelprice13',\n",
        "                    'reward0', 'reward1', 'reward2', 'reward3', 'reward4', 'reward5', 'reward6', 'reward7', 'reward8', 'reward9', 'reward10', 'reward11', 'reward12',\n",
        "                    'action0', 'action1', 'action2', 'action3', 'action4', 'action5', 'action6', 'action7', 'action8', 'action9', 'action10', 'action11', 'action12', 'Date']\n",
        "    envv = DDataenv(data_path, data_columns)  # Assuming DDataenv is your data environment class\n",
        "\n",
        "    ac = envv.get_observation()\n",
        "\n",
        "    if batch_size:\n",
        "       # Change here: Convert batch_size to a tuple if it's not already\n",
        "        if not isinstance(batch_size, tuple):\n",
        "            batch_size = (batch_size,)  # Convert to tuple\n",
        "        ac = {k: torch.tensor(v).expand(*batch_size, *torch.tensor(v).shape) for k, v in ac.items()}\n",
        "\n",
        "    td = TensorDict({\"params\": ac}, batch_size=batch_size, device=torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    if batch_size:\n",
        "        td = td.expand(batch_size).contiguous()\n",
        "    return td\n",
        "\n",
        "\n",
        "def _set_seed(self, seed: 45):\n",
        "    self.rng = torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "def full_info_spec(self):\n",
        "    return {}\n",
        "\n",
        "\n",
        "def group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "    return {\"agents\": [agent[\"name\"] for agent in env.agents]}\n",
        "\n",
        "\n",
        "\n",
        "class AnFuelpriceEnv(EnvBase):\n",
        "    metadata = {\n",
        "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
        "        \"render_fps\": 30,\n",
        "    }\n",
        "    Scenario = \"USDATA_1\"\n",
        "    batch_locked = False\n",
        "\n",
        "    def __init__(self, td_params=None, seed=None, device=\"cpu\", categorical_actions=True, continuous_actions=True, **kwargs):\n",
        "        if td_params is None:\n",
        "            td_params = self.gen_params()\n",
        "\n",
        "        _ = kwargs.pop(\"scenario\", None)\n",
        "\n",
        "\n",
        "\n",
        "        self.n_agents = 3\n",
        "        self.convo_dim = [9, 9]\n",
        "        self.batch_size = (10,10) # Corrected batch size to a single-element tuple\n",
        "        self.batch_size_tuple = torch.Size([self.batch_size]) if isinstance(self.batch_size, int) else torch.Size(self.batch_size)\n",
        "        self.observat_spec_updated = CompositeSpec()\n",
        "        self.Date_spec_updated = CompositeSpec()\n",
        "        self.observation_updated = CompositeSpec()\n",
        "        self.reward_spec_updated = CompositeSpec()\n",
        "        self.done_spec_updated = CompositeSpec()\n",
        "        self.info_spec_updated = CompositeSpec()\n",
        "        self.action_spec_updated = CompositeSpec()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        super().__init__(device=device, batch_size=self.batch_size,)\n",
        "\n",
        "\n",
        "        self._make_spec(td_params)\n",
        "\n",
        "        if seed is None:\n",
        "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
        "        self.set_seed(seed)\n",
        "\n",
        "\n",
        "\n",
        "    def get_supports_continuous_actions(self):\n",
        "        return hasattr(env.full_action_spec, 'shape') and len(env.full_action_spec.shape) > 0\n",
        "\n",
        "    def get_supports_discrete_actions(self):\n",
        "        return isinstance(env.full_action_spec, DiscreteTensorSpec)\n",
        "\n",
        "    def get_observation_spec(self):\n",
        "        return self.observation_spec\n",
        "\n",
        "    def get_full_action_spec(self):\n",
        "        return self.full_action_spec\n",
        "\n",
        "    def get_full_reward_spec(self):\n",
        "        return self.full_reward_spec\n",
        "\n",
        "    def get_done_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    def get_group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "        return {\"agents\": [agent[\"name\"] for agent in env.agents]}\n",
        "\n",
        "    def get_full_info_spec(self):\n",
        "        return {}\n",
        "\n",
        "    def get_discount_spec(self):\n",
        "        return self.discount_spec\n",
        "\n",
        "    @property\n",
        "    def terminated_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    @property\n",
        "    def truncated_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    @property\n",
        "    def get_env_name(self):\n",
        "        return \"AnFuelpriceEnv\"\n",
        "\n",
        "    gen_params = staticmethod(gen_params)\n",
        "    _make_spec = _make_spec\n",
        "    _reset = _reset\n",
        "    _step = staticmethod(_step)\n",
        "    _set_seed = _set_seed\n",
        "    full_info_spec = full_info_spec\n",
        "\n",
        "\n",
        "env = AnFuelpriceEnv()\n",
        "\n",
        "print(\"\\n*action_spec:\", env.full_action_spec)\n",
        "print(\"\\n*reward_spec:\", env.full_reward_spec)\n",
        "print(\"\\n*done_spec:\", env.full_done_spec)\n",
        "print(\"\\n*observation_spec:\", env.observation_spec)\n",
        "\n",
        "print(\"\\n-action_keys:\", env.action_keys)\n",
        "print(\"\\n-reward_keys:\", env.reward_keys)\n",
        "print(\"\\n-done_keys:\", env.done_keys)\n",
        "\n",
        "print(\"input_spec:\", env.input_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "print(\"action_spec (as defined by input_spec):\", env.action_spec)\n",
        "td = env.reset()\n",
        "print(\"reset tensordict\", td)\n",
        "\n",
        "\n",
        "\n",
        "check_env_specs(env)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fu2RUDlZnEt8",
        "outputId": "5066f4b0-c43b-4b71-9812-903cb4a488bd"
      },
      "id": "fu2RUDlZnEt8",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The DiscreteTensorSpec has been deprecated and will be removed in v0.8. Please use Categorical instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.8. Please use Bounded instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The UnboundedContinuousTensorSpec has been deprecated and will be removed in v0.8. Please use Unbounded instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Composite(\n",
            "    agent_0: DiscreteTensorSpec(\n",
            "        shape=torch.Size([13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_1: DiscreteTensorSpec(\n",
            "        shape=torch.Size([13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_2: DiscreteTensorSpec(\n",
            "        shape=torch.Size([13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    device=None,\n",
            "    shape=torch.Size([]))\n",
            "\n",
            "*action_spec: Composite(\n",
            "    agent_0: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_1: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_2: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*reward_spec: Composite(\n",
            "    agent_0: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_2: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*done_spec: Composite(\n",
            "    done: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*observation_spec: Composite(\n",
            "    agents: Composite(\n",
            "        observat: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_2: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        position_key: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_2: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "-action_keys: ['agent_0', 'agent_1', 'agent_2']\n",
            "\n",
            "-reward_keys: ['agent_0', 'agent_1', 'agent_2']\n",
            "\n",
            "-done_keys: ['done', 'terminated']\n",
            "input_spec: Composite(\n",
            "    full_state_spec: Composite(\n",
            "    ,\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    full_action_spec: Composite(\n",
            "        agent_0: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        agent_1: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        agent_2: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "reward_spec: Composite(\n",
            "    agent_0: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_2: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "action_spec (as defined by input_spec): Composite(\n",
            "    agent_0: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_1: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_2: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "reset tensordict TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                agent_0: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False),\n",
            "                agent_1: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False),\n",
            "                agent_2: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False)},\n",
            "            batch_size=torch.Size([10, 10]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10, 10]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-70e24e043e47>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m \u001b[0mcheck_env_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/utils.py\u001b[0m in \u001b[0;36mcheck_env_specs\u001b[0;34m(env, return_contiguous, check_dtype, seed, tensordict)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0mfake_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_tensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m     real_tensordict = env.rollout(\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mreturn_contiguous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_contiguous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[0m\n\u001b[1;32m   3129\u001b[0m         }\n\u001b[1;32m   3130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbreak_when_any_done\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3131\u001b[0;31m             tensordicts = self._rollout_stop_early(\n\u001b[0m\u001b[1;32m   3132\u001b[0m                 \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m                 \u001b[0mbreak_when_any_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbreak_when_any_done\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m_rollout_stop_early\u001b[0;34m(self, break_when_any_done, break_when_all_done, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[0m\n\u001b[1;32m   3270\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3271\u001b[0m                     \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_device_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3272\u001b[0;31m             \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3273\u001b[0m             \u001b[0mtd_append\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   1971\u001b[0m         \u001b[0mnext_preset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"next\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1974\u001b[0m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_proc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext_preset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-70e24e043e47>\u001b[0m in \u001b[0;36m_step\u001b[0;34m(tensordict)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"agent_{j}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reward\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_agent_reward\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Sum the 13 feature rewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Change the expand call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mexpanded_agent_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"agent_{j}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reward\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvo_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict as TypingDict, Any, Union, List, Optional\n",
        "from torchrl.envs import EnvBase, TransformedEnv\n",
        "\n",
        "from torchrl.data import CompositeSpec, BoundedTensorSpec, DiscreteTensorSpec\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "from torchrl.envs.utils import check_env_specs\n",
        "\n",
        "class DDataenv:\n",
        "    def __init__(self, data_path: str, data_columns: List[str], data_type: Any = np.float32):\n",
        "        self.data_path = data_path\n",
        "        self.data_columns = data_columns\n",
        "        self.data_type = data_type\n",
        "        self.data = None\n",
        "\n",
        "    def load_data(self) -> pd.DataFrame:\n",
        "        if not os.path.exists(self.data_path):\n",
        "            raise FileNotFoundError(f\"Data file not found at {self.data_path}\")\n",
        "\n",
        "        with open(self.data_path, 'rb') as f:\n",
        "            self.data = torch.load(f, weights_only=False)\n",
        "\n",
        "        self.data = np.array(self.data)\n",
        "        if len(self.data.shape) >= 3:\n",
        "            self.data = self.data.reshape(self.data.shape[1], self.data.shape[2])\n",
        "\n",
        "        if not isinstance(self.data, pd.DataFrame):\n",
        "            self.data = pd.DataFrame(self.data, columns=self.data_columns)\n",
        "\n",
        "        return self.data\n",
        "\n",
        "    def get_observation(self) -> TypingDict[str, Union[np.ndarray, TypingDict[str, float]]]:\n",
        "        if self.data is None:\n",
        "            self.load_data()\n",
        "\n",
        "        random_row_index = np.random.choice(self.data.shape[0], 1, replace=False)[0]\n",
        "        observation = self.data.iloc[random_row_index, :].to_numpy().astype(self.data_type)\n",
        "        describe_data = self.data.describe()\n",
        "\n",
        "        observation_dict = {\n",
        "            'obsState&Fuel': observation[0:13],\n",
        "            'Date': observation[-1],\n",
        "            'rewardState&reward': observation[13:26],\n",
        "            'actionState&action': observation[26:39],\n",
        "            'obsState&Fuel_max': describe_data.loc['max'][0:13].values,\n",
        "            'obsState&Fuel_min': describe_data.loc['min'][0:13].values,\n",
        "            'Date_max': self.data['Date'].max(),\n",
        "            'Date_min': self.data['Date'].min(),\n",
        "            'rewardState&reward_max': describe_data.loc['max'][13:26].values,\n",
        "            'rewardState&reward_min': describe_data.loc['min'][13:26].values,\n",
        "            'actionState&action_max': describe_data.loc['max'][26:39].values,\n",
        "            'actionState&action_min': describe_data.loc['min'][26:39].values,\n",
        "        }\n",
        "\n",
        "        return observation_dict\n",
        "\n",
        "def _step(env, tensordict):\n",
        "    td = env.gen_params()\n",
        "    n_agents = env.n_agents\n",
        "\n",
        "    agent_obs_list, agent_reward_list, agent_date_list, agent_action_list = [], [], [], []\n",
        "\n",
        "    for j in range(n_agents):\n",
        "        for convo_dim in range(env.convo_dim[0]):\n",
        "            current_td = env.gen_params(env.convo_dim[0])\n",
        "\n",
        "            obs = torch.reshape(td['params', 'obsState&Fuel'], (13,))\n",
        "            reward = torch.reshape(td['params', 'rewardState&reward'], (13,))\n",
        "            action = torch.reshape(td['params', 'actionState&action'], (13,))\n",
        "            date = torch.reshape(td['params', 'Date'], (1,))\n",
        "\n",
        "            new_obs = torch.add(obs, torch.stack([a * r for a, r in zip(action, reward)]))\n",
        "            new_obs = torch.reshape(new_obs, (13,))\n",
        "\n",
        "            agent_obs_list.append(new_obs)\n",
        "            agent_reward_list.append(reward)\n",
        "            agent_date_list.append(date)\n",
        "            agent_action_list.append(action)\n",
        "\n",
        "    agent_obs = torch.stack(agent_obs_list, dim=-1)\n",
        "    agent_reward = torch.stack(agent_reward_list, dim=-1)\n",
        "    agent_date = torch.stack(agent_date_list, dim=-1)\n",
        "    agent_action = torch.stack(agent_action_list, dim=-1)\n",
        "\n",
        "    expanded_agent_obs = agent_obs.reshape(env.n_agents, 13, env.convo_dim[0], 1).expand(env.n_agents, 13, *env.convo_dim)\n",
        "    expanded_agent_reward = agent_reward.reshape(env.n_agents, 13, env.convo_dim[0], 1).expand(env.n_agents, 13, *env.convo_dim)\n",
        "    expanded_agent_action = agent_action.reshape(env.n_agents, 13, env.convo_dim[0], 1).expand(env.n_agents, 13, *env.convo_dim)\n",
        "    expanded_agent_date = agent_date.reshape(env.n_agents, 1, env.convo_dim[0], 1).expand(env.n_agents, 1, *env.convo_dim)\n",
        "\n",
        "    expanded_agent_obs = expanded_agent_obs.expand(tuple(env.batch_size) + expanded_agent_obs.shape)\n",
        "    expanded_agent_reward = expanded_agent_reward.expand(tuple(env.batch_size) + expanded_agent_reward.shape)\n",
        "    expanded_agent_action = expanded_agent_action.expand(tuple(env.batch_size) + expanded_agent_action.shape)\n",
        "    expanded_agent_date = expanded_agent_date.expand(tuple(env.batch_size) + expanded_agent_date.shape)\n",
        "\n",
        "    dones = torch.zeros((*env.batch_size, env.n_agents), dtype=torch.bool, device=env.device)\n",
        "\n",
        "    nextt = TensorDict(\n",
        "        {\n",
        "            \"agents\": {\n",
        "                \"observation\": {\n",
        "                    \"observat\": expanded_agent_obs,\n",
        "                    \"position_key\": expanded_agent_date,\n",
        "                    \"reward\": expanded_agent_reward,\n",
        "                }\n",
        "            },\n",
        "            \"terminated\": dones.clone(),\n",
        "        },\n",
        "        batch_size=env.batch_size,\n",
        "        device=env.device,\n",
        "    )\n",
        "    return nextt\n",
        "\n",
        "class AnFuelpriceEnv(EnvBase):\n",
        "    def __init__(self, td_params=None, seed=None, device=\"cpu\", **kwargs):\n",
        "        if td_params is None:\n",
        "            td_params = self.gen_params()\n",
        "\n",
        "        self.n_agents = 1\n",
        "        self.convo_dim = [9, 9]\n",
        "        self.batch_size = (10,)\n",
        "        self.batch_size_tuple = torch.Size(self.batch_size)\n",
        "        self.device = device\n",
        "        self.action_keys = [\"agents\"]\n",
        "\n",
        "        super().__init__(device=device, batch_size=self.batch_size)\n",
        "\n",
        "        self._make_spec(td_params)\n",
        "\n",
        "        if seed is None:\n",
        "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
        "        self.set_seed(seed)\n",
        "\n",
        "    def gen_params(self, batch_size=torch.Size()) -> TensorDictBase:\n",
        "        data_path = '/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/DataDic.pt'\n",
        "        data_columns = ['Forex', 'WTI', 'Brent', 'OPEC', 'Fuelprice5', 'Fuelprice6', 'Fuelprice7', 'Fuelprice8',\n",
        "                        'Fuelprice9', 'Fuelprice10', 'Fuelprice11', 'Fuelprice12', 'Fuelprice13', 'reward0', 'reward1',\n",
        "                        'reward2', 'reward3', 'reward4', 'reward5', 'reward6', 'reward7', 'reward8', 'reward9',\n",
        "                        'reward10', 'reward11', 'reward12', 'action0', 'action1', 'action2', 'action3', 'action4',\n",
        "                        'action5', 'action6', 'action7', 'action8', 'action9', 'action10', 'action11', 'action12', 'Date']\n",
        "\n",
        "        envv = DDataenv(data_path, data_columns)\n",
        "        ac = envv.get_observation()\n",
        "\n",
        "        if batch_size:\n",
        "            ac = {k: torch.tensor(v).expand(*batch_size, *torch.tensor(v).shape) for k, v in ac.items()}\n",
        "\n",
        "        td = TensorDict(\n",
        "            {\"params\": ac},\n",
        "            batch_size=batch_size,\n",
        "            device=torch.device(\"cpu\"),\n",
        "        )\n",
        "        if batch_size:\n",
        "            td = td.expand(batch_size).contiguous()\n",
        "        return td\n",
        "\n",
        "    def _make_spec(self, td_agents):\n",
        "        self.unbatched_observation_spec = CompositeSpec(\n",
        "            agents=CompositeSpec(\n",
        "                observat=BoundedTensorSpec(\n",
        "                    low=td_agents['params']['obsState&Fuel_min'].values,\n",
        "                    high=td_agents['params']['obsState&Fuel_max'].values,\n",
        "                    shape=td_agents['params']['obsState&Fuel_max'].shape,\n",
        "                    dtype=torch.float32,\n",
        "                    device=self.device\n",
        "                ),\n",
        "                position_key=BoundedTensorSpec(\n",
        "                    low=td_agents['params']['Date_min'],\n",
        "                    high=td_agents['params']['Date_max'],\n",
        "                    shape=(1,),\n",
        "                    dtype=torch.float32,\n",
        "                    device=self.device\n",
        "                ),\n",
        "            )\n",
        "        )\n",
        "        self.unbatched_reward_spec = CompositeSpec(\n",
        "            agents=BoundedTensorSpec(\n",
        "                low=td_agents['params']['rewardState&reward_min'].values,\n",
        "                high=td_agents['params']['rewardState&reward_max'].values,\n",
        "                shape=td_agents['params']['rewardState&reward_max'].shape,\n",
        "                dtype=torch.float32,\n",
        "                device=self.device\n",
        "            )\n",
        "        )\n",
        "        self.unbatched_action_spec = DiscreteTensorSpec(\n",
        "            n=3,\n",
        "            shape=(13,),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "        self.input_spec = CompositeSpec(agents=self.action_spec )\n",
        "        self.unbatched_done_spec = DiscreteTensorSpec(n=2, shape=torch.Size([1]), dtype=torch.bool).to(self.device)\n",
        "\n",
        "        self.action_spec = self.unbatched_action_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "        self.observation_spec = self.unbatched_observation_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "        self.reward_spec = self.unbatched_reward_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "        self.done_spec = self.unbatched_done_spec.expand(self.batch_size_tuple).to(self.device)\n",
        "\n",
        "    def set_seed(self, seed: int):\n",
        "        self.rng = torch.manual_seed(seed)\n",
        "\n",
        "    def get_discount_spec(self):\n",
        "        return self.discount_spec\n",
        "\n",
        "    def _reset(self, tensordict=None, **kwargs):\n",
        "        if tensordict is None:\n",
        "            td = self.gen_params()\n",
        "            obs_max = td['params']['obsState&Fuel_max'].clone().detach()\n",
        "            obs_min = td['params']['obsState&Fuel_min'].clone().detach()\n",
        "            random_numbers = torch.rand((1,), device=self.device)\n",
        "\n",
        "            observation = torch.add(torch.mul(random_numbers, torch.add(obs_max, -obs_min)), obs_min)\n",
        "            observation = observation.reshape(1, 13, 1, 1).expand(1, 13, *self.convo_dim)\n",
        "            dones = torch.zeros(*self.batch_size, self.n_agents, dtype=torch.bool, device=self.device)\n",
        "\n",
        "            return TensorDict(\n",
        "                {\n",
        "                    \"agents\": {\n",
        "                        \"observation\": {\n",
        "                            \"observat\": observation,\n",
        "                            \"position_key\": td['params']['Date_max'].reshape(1, 1, 1, 1).expand(1, 1, *self.convo_dim),\n",
        "                        }\n",
        "                    },\n",
        "                    \"terminated\": dones.clone(),\n",
        "                },\n",
        "                batch_size=self.batch_size,\n",
        "                device=self.device,\n",
        "            )\n",
        "\n",
        "    def _step(self, tensordict):\n",
        "        return _step(self, tensordict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n*action_spec:\", env.full_action_spec)\n",
        "print(\"\\n*reward_spec:\", env.full_reward_spec)\n",
        "print(\"\\n*done_spec:\", env.full_done_spec)\n",
        "print(\"\\n*observation_spec:\", env.observation_spec)\n",
        "\n",
        "print(\"\\n-action_keys:\", env.action_keys)\n",
        "print(\"\\n-reward_keys:\", env.reward_keys)\n",
        "print(\"\\n-done_keys:\", env.done_keys)\n",
        "\n",
        "print(\"input_spec:\", env.input_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "print(\"action_spec (as defined by input_spec):\", env.action_spec)\n",
        "td = env.reset()\n",
        "print(\"reset tensordict\", td)\n",
        "\n",
        "\n",
        "\n",
        "check_env_specs(env)\n",
        "\n",
        "env = AnFuelpriceEnv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MMSyH5mzcpcw",
        "outputId": "e7ddd434-8e41-4809-a23b-162d00ab3c55"
      },
      "id": "MMSyH5mzcpcw",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*action_spec: Composite(\n",
            ",\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*reward_spec: Composite(\n",
            "    agent_0: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_2: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*done_spec: Composite(\n",
            "    done: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*observation_spec: Composite(\n",
            "    agents: Composite(\n",
            "        observat: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_2: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        position_key: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_2: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "-action_keys: []\n",
            "\n",
            "-reward_keys: ['agent_0', 'agent_1', 'agent_2']\n",
            "\n",
            "-done_keys: ['done', 'terminated']\n",
            "input_spec: Composite(\n",
            "    full_state_spec: Composite(\n",
            "    ,\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    full_action_spec: Composite(\n",
            "    ,\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "reward_spec: Composite(\n",
            "    agent_0: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_2: UnboundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-2b83736760b4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_spec:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reward_spec:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"action_spec (as defined by input_spec):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0mtd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reset tensordict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36maction_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                 )\n\u001b[1;32m   1112\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                 \u001b[0;31m# the key may have changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36maction_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;34m\"action_key requested but more than one key present in the environment\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             )\n\u001b[0;32m-> 1019\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;31m# Action spec: action specs belong to input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}