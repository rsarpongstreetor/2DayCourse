{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsarpongstreetor/2DayCourse/blob/master/exp44.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20326118",
      "metadata": {
        "id": "20326118"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2422f32f",
      "metadata": {
        "id": "2422f32f"
      },
      "source": [
        "## Install BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b10fd32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b10fd32",
        "outputId": "3ffeb706-737f-4b0e-9256-008f6512908f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'BenchMARL'...\n",
            "remote: Enumerating objects: 2267, done.\u001b[K\n",
            "remote: Total 2267 (delta 0), reused 0 (delta 0), pack-reused 2267 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2267/2267), 483.32 KiB | 5.97 MiB/s, done.\n",
            "Resolving deltas: 100% (1430/1430), done.\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!git clone https://github.com/facebookresearch/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd7b69b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cd7b69b",
        "outputId": "9d4d87be-167f-4589-a4c8-327af64948ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/BenchMARL\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "%cd /content/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f32b88e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4f32b88e",
        "outputId": "58bed572-0b63-49c0-ae7b-1374e3a5d784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0 torchvision-0.21.0 triton-3.2.0\n",
            "Obtaining file:///content/BenchMARL\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchrl~=0.7.0 (from benchmarl==1.4.0)\n",
            "  Downloading torchrl-0.7.0-cp311-cp311-manylinux1_x86_64.whl.metadata (39 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (4.67.1)\n",
            "Collecting hydra-core (from benchmarl==1.4.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (0.21.0)\n",
            "Collecting av<14 (from benchmarl==1.4.0)\n",
            "  Downloading av-13.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (3.1.1)\n",
            "Collecting tensordict>=0.7.0 (from torchrl~=0.7.0->benchmarl==1.4.0)\n",
            "  Downloading tensordict-0.7.0-cp311-cp311-manylinux1_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core->benchmarl==1.4.0)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core->benchmarl==1.4.0)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->benchmarl==1.4.0) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core->benchmarl==1.4.0) (6.0.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.7.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.10.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.0.2)\n",
            "Downloading av-13.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.0/34.0 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchrl-0.7.0-cp311-cp311-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensordict-0.7.0-cp311-cp311-manylinux1_x86_64.whl (397 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.8/397.8 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: benchmarl, antlr4-python3-runtime\n",
            "  Building editable for benchmarl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benchmarl: filename=benchmarl-1.4.0-0.editable-py3-none-any.whl size=3797 sha256=238c34a9cdf1e798f7b18fec9bba22b833b309c5962c0de0706495c618bfff8b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x9jycwe_/wheels/d1/dc/58/2f83c40b8458f8cd6be0bee519061fa93523762dfc8aad5e9b\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=3721f0008a03d3ecb11298f232433e263fa761e31d07f5eec6f792b70181ae99\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built benchmarl antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf, av, hydra-core, tensordict, torchrl, benchmarl\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 av-13.1.0 benchmarl-1.4.0 hydra-core-1.3.2 omegaconf-2.3.0 tensordict-0.7.0 torchrl-0.7.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "d924dc42e5f540d688289ff38b1ae25c",
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title\n",
        "!pip install -U torch torchvision\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "585d3a35",
      "metadata": {
        "id": "585d3a35"
      },
      "source": [
        "## Install VMAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2e551b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2e551b1",
        "outputId": "b63183ee-52b5-497d-bbeb-ce2da8910ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vmas\n",
            "  Downloading vmas-1.5.0.tar.gz (217 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/217.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.5/217.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vmas) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from vmas) (2.6.0)\n",
            "Collecting pyglet<=1.5.27 (from vmas)\n",
            "  Downloading pyglet-1.5.27-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (from vmas) (0.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from vmas) (1.17.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym->vmas) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym->vmas) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->vmas) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->vmas) (3.0.2)\n",
            "Downloading pyglet-1.5.27-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: vmas\n",
            "  Building wheel for vmas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vmas: filename=vmas-1.5.0-py3-none-any.whl size=257528 sha256=4767dd8d53ffcee9fecc85eae4a77280054c5db113be33599e887b83da509df6\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/ab/3b/f1eb0befe556b53a3f78b4780554c29dca0cb781fb664f6a81\n",
            "Successfully built vmas\n",
            "Installing collected packages: pyglet, vmas\n",
            "Successfully installed pyglet-1.5.27 vmas-1.5.0\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!pip install vmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33d72783",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33d72783",
        "outputId": "76c4c2c2-c115-4972-b115-d7165eb4a83a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [Connected to cloud.r-\r                                                                                                    \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                                                    \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connecte\r                                                                                                    \rGet:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,523 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,907 kB]\n",
            "Get:13 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [66.7 kB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,309 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,665 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,606 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,653 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [57.8 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\n",
            "Fetched 21.4 MB in 3s (6,163 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libfontenc1 libglu1-mesa libxfont2 libxkbfile1 libxtst6 libxxf86dga1 x11-xkb-utils\n",
            "  xfonts-base xfonts-encodings xfonts-utils xserver-common\n",
            "Suggested packages:\n",
            "  libgle3 python3-numpy mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libfontenc1 libglu1-mesa libxfont2 libxkbfile1 libxtst6 libxxf86dga1 python3-opengl\n",
            "  x11-utils x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 15 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 8,871 kB of archives.\n",
            "After this operation, 20.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-opengl all 3.1.5+dfsg-1 [605 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.12 [864 kB]\n",
            "Fetched 8,871 kB in 0s (37.6 MB/s)\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../00-freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../01-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../02-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../03-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../04-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../05-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../06-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package python3-opengl.\n",
            "Preparing to unpack .../07-python3-opengl_3.1.5+dfsg-1_all.deb ...\n",
            "Unpacking python3-opengl (3.1.5+dfsg-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../08-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../09-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../10-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../11-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../12-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../13-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../14-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up python3-opengl (3.1.5+dfsg-1) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7a90f1261890>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title\n",
        "!apt-get update\n",
        "!apt-get install -y x11-utils python3-opengl xvfb\n",
        "!pip install pyvirtualdisplay\n",
        "import pyvirtualdisplay\n",
        "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nQGSKzolqGjf",
      "metadata": {
        "id": "nQGSKzolqGjf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "913e9ce7-e360-437e-9bf1-3d3cb39e996b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchrl) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl) (3.1.1)\n",
            "Requirement already satisfied: tensordict>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from torchrl) (0.7.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.7.0->torchrl) (3.10.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->torchrl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->torchrl) (3.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: TensorDict in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from TensorDict) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from TensorDict) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from TensorDict) (3.1.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from TensorDict) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from TensorDict) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->TensorDict) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->TensorDict) (3.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-opengl is already the newest version (3.1.5+dfsg-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.11)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n",
            "Collecting drive\n",
            "  Downloading drive-0.4.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: google-api-python-client<3.0.0,>=2.64.0 in /usr/local/lib/python3.11/dist-packages (from drive) (2.160.0)\n",
            "Collecting httplib2<0.21.0,>=0.20.4 (from drive)\n",
            "  Downloading httplib2-0.20.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: oauth2client<5.0.0,>=4.1.3 in /usr/local/lib/python3.11/dist-packages (from drive) (4.1.3)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.0.10 in /usr/local/lib/python3.11/dist-packages (from drive) (3.1.5)\n",
            "Collecting python-magic<0.5.0,>=0.4.27 (from drive)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.64.0->drive) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.64.0->drive) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.64.0->drive) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.64.0->drive) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<0.21.0,>=0.20.4->drive) (3.2.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client<5.0.0,>=4.1.3->drive) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client<5.0.0,>=4.1.3->drive) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client<5.0.0,>=4.1.3->drive) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client<5.0.0,>=4.1.3->drive) (1.17.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl<4.0.0,>=3.0.10->drive) (2.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.64.0->drive) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.64.0->drive) (4.25.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.64.0->drive) (1.26.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.64.0->drive) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client<3.0.0,>=2.64.0->drive) (5.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.64.0->drive) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.64.0->drive) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.64.0->drive) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.64.0->drive) (2025.1.31)\n",
            "Downloading drive-0.4.4-py3-none-any.whl (15 kB)\n",
            "Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: python-magic, httplib2, drive\n",
            "  Attempting uninstall: httplib2\n",
            "    Found existing installation: httplib2 0.22.0\n",
            "    Uninstalling httplib2-0.22.0:\n",
            "      Successfully uninstalled httplib2-0.22.0\n",
            "Successfully installed drive-0.4.4 httplib2-0.20.4 python-magic-0.4.27\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "httplib2"
                ]
              },
              "id": "ec603f174b14490f908eb587dd048029"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install torchrl\n",
        "!pip install  tensorboard\n",
        "!pip install TensorDict\n",
        "!pip install pyyaml\n",
        "!apt-get install python3-opengl\n",
        "!pip install torch_geometric\n",
        "!pip install drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rsarpongstreetor/environmentcustomev\n",
        "%cd Taskcutomenv # Navigate to the Task_cutomenv directory\n",
        "!touch __init__.py # Create __init__.py\n",
        "%cd .. # Navigate back to the previous directory\n",
        "!pip install -e Taskcutomenv\n",
        "!git clone https://github.com/rsarpongstreetor/Taskcutomenv\n",
        "%cd environmentcustomev # Navigate to the environment-_customev directory\n",
        "!touch __init__.py # Create __init__.py\n",
        "%cd .. # Navigate back to the previous directory\n",
        "!pip install -e environmentcustomev\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbRRxGGJL9T0",
        "outputId": "915407c1-7ea9-4b4d-d9b3-4a529435821e"
      },
      "id": "QbRRxGGJL9T0",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'environmentcustomev' already exists and is not an empty directory.\n",
            "[Errno 2] No such file or directory: 'Taskcutomenv # Navigate to the Task_cutomenv directory'\n",
            "/content/BenchMARL\n",
            "[Errno 2] No such file or directory: '.. # Navigate back to the previous directory'\n",
            "/content/BenchMARL\n",
            "Obtaining file:///content/BenchMARL/Taskcutomenv\n",
            "\u001b[31mERROR: file:///content/BenchMARL/Taskcutomenv does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0mfatal: destination path 'Taskcutomenv' already exists and is not an empty directory.\n",
            "[Errno 2] No such file or directory: 'environmentcustomev # Navigate to the environment-_customev directory'\n",
            "/content/BenchMARL\n",
            "[Errno 2] No such file or directory: '.. # Navigate back to the previous directory'\n",
            "/content/BenchMARL\n",
            "Obtaining file:///content/BenchMARL/environmentcustomev\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/rsarpongstreetor/anfuelpriceenv\n",
        "%cd anfuelpriceenv # Navigate to the anfuelpriceenv directory\n",
        "!touch __init__.py # Create __init__.py\n",
        "%cd .. # Navigate back to the previous directory\n",
        "!pip install -e anfuelpriceenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZBij7aT2H75",
        "outputId": "f383f9d9-55f1-46ea-a382-140bed2eb719"
      },
      "id": "PZBij7aT2H75",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'anfuelpriceenv'...\n",
            "remote: Enumerating objects: 415, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 415 (delta 76), reused 0 (delta 0), pack-reused 283 (from 2)\u001b[K\n",
            "Receiving objects: 100% (415/415), 164.35 KiB | 14.94 MiB/s, done.\n",
            "Resolving deltas: 100% (234/234), done.\n",
            "[Errno 2] No such file or directory: 'anfuelpriceenv # Navigate to the anfuelpriceenv directory'\n",
            "/content/BenchMARL\n",
            "[Errno 2] No such file or directory: '.. # Navigate back to the previous directory'\n",
            "/content/BenchMARL\n",
            "Obtaining file:///content/BenchMARL/anfuelpriceenv\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (2.6.0)\n",
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: tensordict in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->AnFuelpriceEnv==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->AnFuelpriceEnv==0.1.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->AnFuelpriceEnv==0.1.0) (2025.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tensordict->AnFuelpriceEnv==0.1.0) (3.1.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict->AnFuelpriceEnv==0.1.0) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensordict->AnFuelpriceEnv==0.1.0) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->AnFuelpriceEnv==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->AnFuelpriceEnv==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->AnFuelpriceEnv==0.1.0) (3.0.2)\n",
            "Installing collected packages: AnFuelpriceEnv\n",
            "  Running setup.py develop for AnFuelpriceEnv\n",
            "Successfully installed AnFuelpriceEnv-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import NONE\n",
        "import torch_geometric\n",
        "from torch import nn\n",
        "from benchmarl.environments import VmasTask\n",
        "import torch\n",
        "\n",
        "\n",
        "from benchmarl.experiment import Experiment, ExperimentConfig\n",
        "from benchmarl.models import SequenceModelConfig, GnnConfig, MlpConfig\n",
        "from benchmarl.algorithms import IppoConfig, MappoConfig, QmixConfig, MasacConfig\n",
        "from benchmarl.environments.customenv.common import CustomEnvTask\n",
        "#from benchmarl.task.customenv import task_1\n",
        "import yaml # Import the yaml module\n",
        "from anfuelpriceenv.AnFuelpriceEnv import AnFuelpriceEnv  # Updated import statement\n",
        "#from content.BenchMARL.environmentcustomev import CustomEnvTask\n",
        "\n",
        "\n",
        "#from benchmarl.task.customenv import task_1\n",
        "import yaml # Import the yaml module\n",
        "#from benchmarl.environments.customenv.common\n",
        "#,VmasTask.SIMPLE_CRYPTO.get_from_yaml()\n",
        "\n",
        "#with open('/content/BenchMARL/BenchMARL/benchmarl/conf/task/customenv/task_2.yaml', 'r') as f:\n",
        "  #  task_config = yaml.safe_load(f)\n",
        "# Access the env_args and task name from the config\n",
        "#env_args = task_config.get('env_args', {})  # Get 'env_args' if present, otherwise empty dict\n",
        "#task_name = env_args.get('AnFuelpriceEnv', {}).get('task') # Get task name under 'AnFuelpriceEnv'\n",
        "\n",
        "# Check if task_name is retrieved successfully\n",
        "#if task_name is None:\n",
        " #   raise ValueError(\"Task name not found in the YAML configuration.\")\n",
        "\n",
        "# Assuming CustomTask and task_2 are defined elsewhere\n",
        "#task_class = getattr(CustomTask, task_2)\n",
        "#task = task_class.get_from_yaml(task_config) # Instantiate the subclass with the config\n",
        "#from benchmarl.task.customenv import task_2  # Import task_1 from customenv module\n",
        "#env=AnFuelpriceEnv()\n",
        "#from benchmarl.environments.customenv import task_2 # Adjust import path if needed\n",
        "#task =  task_2\n",
        "# Get task configuration from YAML\n",
        "\n",
        "\n",
        "from pickle import NONE\n",
        "import torch_geometric\n",
        "from torch import nn\n",
        "from benchmarl.environments import VmasTask\n",
        "import torch\n",
        "\n",
        "\n",
        "from benchmarl.experiment import Experiment, ExperimentConfig\n",
        "from benchmarl.models import SequenceModelConfig, GnnConfig, MlpConfig\n",
        "from benchmarl.algorithms import IppoConfig, MappoConfig, QmixConfig, MasacConfig\n",
        "#from benchmarl.environmentscustomenv.common import CustomEnvTask\n",
        "#from benchmarl.Taskcustomenv import task_1 # This was commented out\n",
        "import yaml # Import the yaml module\n",
        "from anfuelpriceenv.AnFuelpriceEnv import AnFuelpriceEnv  # Updated import statement\n",
        "#,VmasTask.SIMPLE_CRYPTO.get_from_yaml()\n",
        "\n",
        "\n",
        "from benchmarl.models import SequenceModelConfig, GnnConfig, MlpConfig\n",
        "from benchmarl.algorithms import IppoConfig, MappoConfig, QmixConfig, MasacConfig\n",
        "from typing import Callable, Dict, List, Optional\n",
        "\n",
        "from benchmarl.environments.common import Task\n",
        "from benchmarl.utils import DEVICE_TYPING\n",
        "\n",
        "from tensordict import TensorDictBase\n",
        "from torchrl.data import CompositeSpec\n",
        "from torchrl.envs import EnvBase\n",
        "from anfuelpriceenv.AnFuelpriceEnv  import AnFuelpriceEnv\n",
        "#from benchmarl.environments.customenv.common import CustomEnvTask\n",
        "#from benchmarl.task.customenv import task_1\n",
        "import yaml # Import the yaml module\n",
        "#from benchmarl.environments.customenv.common import CustomEnvTask\n",
        "#from benchmarl.task.customenv import task_1\n",
        "import yaml # Import the yaml module\n",
        "\n",
        "\n",
        "\n",
        "class CustomEnvTask(Task):\n",
        "    # Your task names.\n",
        "    # Their config will be loaded from conf/task/customenv\n",
        "\n",
        "    TASK_1 = None  # Loaded automatically from conf/task/customenv/task_1\n",
        "    TASK_2 = None  # Loaded automatically from conf/task/customenv/task_2\n",
        "\n",
        "    def get_env_fun(\n",
        "        self,\n",
        "        num_envs: int,\n",
        "        continuous_actions: bool,\n",
        "        seed: Optional[int],\n",
        "        device: DEVICE_TYPING,\n",
        "    ) -> Callable[[], EnvBase]:\n",
        "        return lambda: AnFuelpriceEnv(\n",
        "            scenario=self.name.lower(),\n",
        "            num_envs=num_envs,  # Number of vectorized envs (do not use this param if the env is not vectorized)\n",
        "            continuous_actions=continuous_actions,  # Ignore this param if your env does not have this choice\n",
        "            seed=seed,\n",
        "            device=device,\n",
        "            categorical_actions=True,  # If your env has discrete actions, they need to be categorical (TorchRL can help with this)\n",
        "            **self.config,  # Pass the loaded config (this is what is in your yaml\n",
        "        )\n",
        "\n",
        "    def supports_continuous_actions(self) -> bool:\n",
        "        # Does the environment support continuous actions?\n",
        "        return True\n",
        "\n",
        "    def supports_discrete_actions(self) -> bool:\n",
        "        # Does the environment support discrete actions?\n",
        "        return True\n",
        "\n",
        "    def has_render(self, env: EnvBase) -> bool:\n",
        "        # Does the env have a env.render(mode=\"rgb_array\") or env.render() function?\n",
        "        return True\n",
        "\n",
        "    def max_steps(self, env: EnvBase) -> int:\n",
        "        # Maximum number of steps for a rollout during evaluation\n",
        "        return 100\n",
        "\n",
        "    def group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "        # The group map mapping group names to agent names\n",
        "        # The data in the tensordict will havebe presented this way\n",
        "        return {\"agents\": [agent.name for agent in env.agents]}\n",
        "\n",
        "    def observation_spec(self, env: EnvBase) -> CompositeSpec:\n",
        "        # A spec for the observation.\n",
        "        # Must be a CompositeSpec with one (group_name, observation_key) entry per group.\n",
        "        return env.full_observation_spec\n",
        "\n",
        "    def action_spec(self, env: EnvBase) -> CompositeSpec:\n",
        "        # A spec for the action.\n",
        "        # If provided, must be a CompositeSpec with one (group_name, \"action\") entry per group.\n",
        "        return env.full_action_spec\n",
        "\n",
        "    def state_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the state.\n",
        "        # If provided, must be a CompositeSpec with one \"state\" entry\n",
        "        return None\n",
        "\n",
        "    def action_mask_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the action mask.\n",
        "        # If provided, must be a CompositeSpec with one (group_name, \"action_mask\") entry per group.\n",
        "        return None\n",
        "\n",
        "    def info_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the info.\n",
        "        # If provided, must be a CompositeSpec with one (group_name, \"info\") entry per group (this entry can be composite).\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def env_name() -> str:\n",
        "        # The name of the environment in the benchmarl/conf/task folder\n",
        "        return \"customenv\"\n",
        "\n",
        "    def log_info(self, batch: TensorDictBase) -> Dict[str, float]:\n",
        "        # Optionally return a str->float dict with extra things to log\n",
        "        # This function has access to the collected batch and is optional\n",
        "        return {}\n",
        "\n",
        "        # Add supports_continuous_actions function to task_2\n",
        "    def supports_continuous_actions():\n",
        "        from torchrl.data import BoundedTensorSpec, UnboundedContinuousTensorSpec, DiscreteTensorSpec\n",
        "        # Check if your environment supports continuous actions\n",
        "        # and return True or False accordingly\n",
        "        # For example, if your environment uses Box action spaces:\n",
        "        return hasattr(env.full_action_spec, 'shape') and len(env.full_action_spec.shape) > 0\n",
        "\n",
        "    def supports_discrete_actions():\n",
        "        return isinstance(env.full_action_spec, DiscreteTensorSpec)\n",
        "\n",
        "\n",
        "env=AnFuelpriceEnv()\n",
        "task = CustomEnvTask.TASK_1.get_from_yaml()\n",
        "# Get task configuration from YAML\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Assign the function to the task_2 module\n",
        "#task_1.supports_continuous_actions = supports_continuous_actions # Also assign these to CustomEnvTask.TASK_1\n",
        "#task_1.supports_discrete_actions = supports_discrete_actions\n",
        "CustomEnvTask.TASK_1.supports_continuous_actions = supports_continuous_actions\n",
        "CustomEnvTask.TASK_1.supports_discrete_actions = supports_discrete_actions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " # Adjust import path if needed\n",
        "task =  task_1.get_from_yaml()\n",
        "# Get task configuration from YAML\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Assign the function to the task_2 module\n",
        "task_1.supports_continuous_actions = supports_continuous_actions\n",
        "task_1.supports_discrete_actions = supports_discrete_actions\n",
        "experiment = Experiment(\n",
        "\n",
        "    algorithm_config=MappoConfig.get_from_yaml(),\n",
        "    model_config=GnnConfig(\n",
        "        topology=\"full\",\n",
        "        self_loops=False,\n",
        "        # Corrected position_key to access 'position_key' directly\n",
        "        # under the 'agents' and 'observation' keys\n",
        "        position_key=None,\n",
        "        pos_features=0,\n",
        "        exclude_pos_from_node_features=False,\n",
        "        gnn_class=torch_geometric.nn.conv.GATv2Conv,\n",
        "        gnn_kwargs={},\n",
        "    ),\n",
        "\n",
        "    critic_model_config=SequenceModelConfig(\n",
        "        model_configs=[\n",
        "            MlpConfig(num_cells=[8], activation_class=nn.Tanh, layer_class=nn.Linear),\n",
        "            # Removed position_key from the critic model\n",
        "            GnnConfig(\n",
        "                topology=\"full\",\n",
        "                self_loops=False,\n",
        "                gnn_class=torch_geometric.nn.conv.GraphConv,\n",
        "            ),\n",
        "            MlpConfig(num_cells=[6], activation_class=nn.Tanh, layer_class=nn.Linear),\n",
        "        ],\n",
        "        intermediate_sizes=[5, 3],\n",
        "    ),\n",
        "    seed=0,\n",
        "    config=ExperimentConfig.get_from_yaml(),\n",
        "\n",
        "    task=task,\n",
        "    #loggers=[\"tensorboard\"],\n",
        "    #save_folder='C:\\\\Users\\\\Richard Sarpong-Stre\\\\OneDrive\\\\Desktop\\\\usreslts\\\\results' #Replace with valid path\n",
        "\n",
        "\n",
        ")\n",
        "experiment.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "u8VqHBmv2lHo",
        "outputId": "2a23d4ae-fd91-4b90-d7d2-e7637c2dcf4c"
      },
      "id": "u8VqHBmv2lHo",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6115: DeprecationWarning: The DiscreteTensorSpec has been deprecated and will be removed in v0.8. Please use Categorical instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6115: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6115: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.8. Please use Bounded instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py:1105: DeprecationWarning: You are querying a non-trivial, single action_spec, i.e., there is only one action known by the environment but it is not named `'action'`. Currently, env.action_spec returns the leaf but for consistency with the setter, this will return the full spec instead (from v0.8 and on).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py:1304: DeprecationWarning: You are querying a non-trivial, single reward_spec, i.e., there is only one reward known by the environment but it is not named `'reward'`. Currently, env.reward_spec returns the leaf but for consistency with the setter, this will return the full spec instead (from v0.8 and on).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "TaskConfig.__init__() got an unexpected keyword argument 'env_name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-93570ceb814f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAnFuelpriceEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomEnvTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTASK_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_from_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;31m# Get task configuration from YAML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BenchMARL/benchmarl/environments/common.py\u001b[0m in \u001b[0;36mget_from_yaml\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_yaml_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_type_check_task_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BenchMARL/benchmarl/environments/common.py\u001b[0m in \u001b[0;36m_type_check_task_config\u001b[0;34m(environemnt_name, task_name, config, warn_on_missing_dataclass)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask_config_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtask_config_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_missing_dataclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: TaskConfig.__init__() got an unexpected keyword argument 'env_name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import NONE\n",
        "from benchmarl.models import SequenceModelConfig, GnnConfig, MlpConfig\n",
        "from benchmarl.algorithms import IppoConfig, MappoConfig, QmixConfig, MasacConfig\n",
        "from typing import Callable, Dict, List, Optional\n",
        "from benchmarl.environments.common import Task\n",
        "from benchmarl.utils import DEVICE_TYPING\n",
        "from benchmarl.experiment import Experiment, ExperimentConfig\n",
        "from tensordict import TensorDictBase\n",
        "from torchrl.envs import EnvBase\n",
        "from anfuelpriceenv.AnFuelpriceEnv  import AnFuelpriceEnv\n",
        "\n",
        "import torch\n",
        "import pickle\n",
        "import torch_geometric\n",
        "from torch import nn\n",
        "from torchrl.data import TensorSpec\n",
        "from torchrl.data import CompositeSpec\n",
        "from tensordict import TensorDict\n",
        "from benchmarl.environments import VmasTask\n",
        "\n",
        "from benchmarl.utils import DEVICE_TYPING\n",
        "import yaml # Import the yaml modu\n",
        "from typing import Dict as TypingDict, Any, Union, List, Optional\n",
        "import torch\n",
        "import numpy as np\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "from torchrl.modules import MultiAgentConvNet\n",
        "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec, DiscreteTensorSpec\n",
        "from torchrl.envs import (\n",
        "    CatTensors,\n",
        "    EnvBase,\n",
        "    Transform,\n",
        "    UnsqueezeTransform,\n",
        "    RewardSum,  # Importing RewardSum\n",
        "    TransformedEnv,\n",
        ")\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import google.colab\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.distributions import Normal\n",
        "from benchmarl.models import GnnConfig, MlpConfig, SequenceModelConfig\n",
        "from benchmarl.algorithms import MappoConfig\n",
        "from benchmarl.algorithms.common import Algorithm\n",
        "\n",
        "from benchmarl.conf.Task.customenv import task_1\n",
        "from benchmarl.environments.customenv.common import CustomEnvTask\n",
        "\n",
        "\n",
        "\n",
        "# ... (rest of your imports and task definition)\n",
        "class Mappo(Algorithm):\n",
        "    def __init__(self, share_param_critic=False, clip_epsilon=0.2, entropy_coef=0.01, critic_coef=0.5, loss_critic_type=\"mse\", lmbda=0.95, scale_mapping=False, use_tanh_normal=False, minibatch_advantage=False, policy_class=None, **kwargs): # Add policy_class here\n",
        "        super().__init__(**kwargs)\n",
        "        self.share_param_critic = share_param_critic\n",
        "        self.clip_epsilon = clip_epsilon\n",
        "        self.entropy_coef = entropy_coef\n",
        "        self.critic_coef = critic_coef\n",
        "        self.loss_critic_type = loss_critic_type\n",
        "        self.lmbda = lmbda\n",
        "        self.scale_mapping = scale_mapping\n",
        "        self.use_tanh_normal = use_tanh_normal\n",
        "        self.minibatch_advantage = minibatch_advantage\n",
        "        self.policy_class = policy_class  # Add policy_class as an attribute\n",
        "\n",
        "\n",
        "class GnnConfig(GnnConfig):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.gnn_kwargs = {\"activation\": nn.Tanh()}\n",
        "\n",
        "class CriticGnnConfig(GnnConfig):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.gnn_kwargs = {\"activation\": nn.Tanh()}\n",
        "\n",
        "class MappoConfig(MappoConfig):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.policy_class = Normal  # Assuming you'll use Gaussian policies\n",
        "\n",
        "class MyCustomEnvTask:\n",
        "    def __init__(self, env_args=None):\n",
        "        # Initialize config to an empty dictionary by default\n",
        "        self.config = {} if env_args is None else env_args\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "google.colab.drive.mount('/content/drive')\n",
        "\n",
        "def is_valid_data(data):\n",
        "    return isinstance(data, dict) or (isinstance(data, list) and all(isinstance(item, dict) for item in data))\n",
        "from torchrl.envs.utils import check_env_specs # This line imports the missing function\n",
        "import requests\n",
        "import torch\n",
        "from gym import spaces  # Import spaces from gym\n",
        "\n",
        "class MyCustomEnvTask:\n",
        "    def __init__(self, env_args=None):\n",
        "        self.config = {} if env_args is None else env_args\n",
        "\n",
        "    def get_env_fun(self, num_envs=1, continuous_actions=True, seed=None, **kwargs):\n",
        "        def make_env():\n",
        "            # Create a new dictionary with only allowed arguments:\n",
        "            allowed_kwargs = {k: v for k, v in kwargs.items()\n",
        "                              if k in ['td_params', 'seed', 'device']}\n",
        "            # Remove 'scenario' from kwargs if present:\n",
        "            kwargs.pop('scenario', None)\n",
        "            return AnFuelpriceEnv(seed=seed, **allowed_kwargs)\n",
        "\n",
        "        if num_envs > 1:\n",
        "            return make_env\n",
        "        else:\n",
        "            return make_env\n",
        "\n",
        "\n",
        "class CustomEnvTask(Task):\n",
        "    # Your task names.\n",
        "    # Their config will be loaded from conf/task/customenv\n",
        "\n",
        "    TASK_1 = None  # Loaded automatically from conf/task/customenv/task_1\n",
        "    TASK_2 = None  # Loaded automatically from conf/task/customenv/task_2\n",
        "\n",
        "    def get_env_fun(\n",
        "        self,\n",
        "        num_envs: int,\n",
        "        continuous_actions: bool,\n",
        "        seed: Optional[int],\n",
        "        device: DEVICE_TYPING,\n",
        "    ) -> Callable[[], EnvBase]:\n",
        "        config = self.config if self.config is not None else {}\n",
        "        return lambda: AnFuelpriceEnv(\n",
        "            scenario=self.name.lower(),\n",
        "            num_envs=num_envs,  # Number of vectorized envs (do not use this param if the env is not vectorized)\n",
        "            continuous_actions=continuous_actions,  # Ignore this param if your env does not have this choice\n",
        "            seed=seed,\n",
        "            device=device,\n",
        "            categorical_actions=True,  # If your env has discrete actions, they need to be categorical (TorchRL can help with this)\n",
        "            **self.config,  # Pass the loaded config (this is what is in your yaml\n",
        "        )\n",
        "\n",
        "    def supports_continuous_actions(self) -> bool:\n",
        "        # Does the environment support continuous actions?\n",
        "        return True\n",
        "\n",
        "    def supports_discrete_actions(self) -> bool:\n",
        "        # Does the environment support discrete actions?\n",
        "        return True\n",
        "\n",
        "    def has_render(self, env: EnvBase) -> bool:\n",
        "        # Does the env have a env.render(mode=\"rgb_array\") or env.render() function?\n",
        "        return True\n",
        "\n",
        "    def max_steps(self, env: EnvBase) -> int:\n",
        "        # Maximum number of steps for a rollout during evaluation\n",
        "        return 100\n",
        "\n",
        "    def group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "        # The group map mapping group names to agent names\n",
        "        # The data in the tensordict will havebe presented this way\n",
        "        return {\"agents\": [agent.name for agent in env.agents]}\n",
        "\n",
        "    def observation_spec(self, env: EnvBase) -> CompositeSpec:\n",
        "        # A spec for the observation.\n",
        "        # Must be a CompositeSpec with one (group_name, observation_key) entry per group.\n",
        "        return env.full_observation_spec\n",
        "\n",
        "    def action_spec(self, env: EnvBase) -> CompositeSpec:\n",
        "        # A spec for the action.\n",
        "        # If provided, must be a CompositeSpec with one (group_name, \"action\") entry per group.\n",
        "        return env.full_action_spec\n",
        "\n",
        "    def state_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the state.\n",
        "        # If provided, must be a CompositeSpec with one \"state\" entry\n",
        "        return None\n",
        "\n",
        "    def action_mask_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the action mask.\n",
        "        # If provided, must be a CompositeSpec with one (group_name, \"action_mask\") entry per group.\n",
        "        return None\n",
        "\n",
        "    def info_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the info.\n",
        "        # If provided, must be a CompositeSpec with one (group_name, \"info\") entry per group (this entry can be composite).\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def env_name() -> str:\n",
        "        # The name of the environment in the benchmarl/conf/task folder\n",
        "        return \"customenv\"\n",
        "\n",
        "    def log_info(self, batch: TensorDictBase) -> Dict[str, float]:\n",
        "        # Optionally return a str->float dict with extra things to log\n",
        "        # This function has access to the collected batch and is optional\n",
        "        return {}\n",
        "\n",
        "        # Add supports_continuous_actions function to task_2\n",
        "    def supports_continuous_actions(self) -> bool:\n",
        "        # Does the environment support continuous actions?\n",
        "        # Check if your environment supports continuous actions\n",
        "        # and return True or False accordingly\n",
        "        # For example, if your environment uses Box action spaces:\n",
        "        from torchrl.data import BoundedTensorSpec, UnboundedContinuousTensorSpec, DiscreteTensorSpec\n",
        "        env = self.get_env_fun(1, True, None, \"cpu\")()\n",
        "        return hasattr(env.full_action_spec, 'shape') and len(env.full_action_spec.shape) > 0\n",
        "\n",
        "\n",
        "    def supports_discrete_actions(self) -> bool:\n",
        "        # Does the environment support discrete actions?\n",
        "        from torchrl.data import BoundedTensorSpec, UnboundedContinuousTensorSpec, DiscreteTensorSpec\n",
        "        env = self.get_env_fun(1, True, None, \"cpu\")()\n",
        "        return isinstance(env.full_action_spec, DiscreteTensorSpec)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create an instance of your custom task class\n",
        "my_custom_task = MyCustomEnvTask()\n",
        "\n",
        "\n",
        "task_1 = CustomEnvTask.TASK_1  # Assuming TASK_1 is the desired task name\n",
        "\n",
        "\n",
        "# Assign the functions to the task object\n",
        "task_1.supports_continuous_actions = task_1.supports_continuous_actions\n",
        "\n",
        "task_1.supports_discrete_actions = task_1.supports_discrete_actions\n",
        "\n",
        "#\n",
        "\n",
        "# Use task_1 instead of task_1.get_from_yaml()\n",
        "\n",
        "\n",
        "task = task_1\n",
        "\n",
        "# ... (Other necessary code)\n",
        "\n",
        "experiment = Experiment(\n",
        "    algorithm_config=MappoConfig.get_from_yaml(),\n",
        "    model_config=GnnConfig(\n",
        "        topology=\"full\",\n",
        "        self_loops=False,\n",
        "        position_key=None,\n",
        "        pos_features=0,\n",
        "        exclude_pos_from_node_features=False,\n",
        "        gnn_class=torch_geometric.nn.conv.GATv2Conv,\n",
        "        gnn_kwargs={},),\n",
        "\n",
        "\n",
        "    critic_model_config=SequenceModelConfig(\n",
        "        model_configs=[\n",
        "            MlpConfig(num_cells=[8], activation_class=nn.Tanh, layer_class=nn.Linear),\n",
        "            CriticGnnConfig( # Using CriticGnnConfig here\n",
        "                topology=\"full\",\n",
        "                self_loops=False,\n",
        "                gnn_class=torch_geometric.nn.conv.GraphConv,\n",
        "            ),\n",
        "            MlpConfig(num_cells=[6], activation_class=nn.Tanh, layer_class=nn.Linear),\n",
        "        ],\n",
        "        intermediate_sizes=[5, 3],\n",
        "    ),\n",
        "    seed=0,\n",
        "    config=ExperimentConfig.get_from_yaml(),\n",
        "\n",
        "    task=task,\n",
        "    #loggers=[\"tensorboard\"],\n",
        "    #save_folder='C:\\\\Users\\\\Richard Sarpong-Stre\\\\OneDrive\\\\Desktop\\\\usreslts\\\\results' #Replace with valid path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ")\n",
        "experiment.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "i6G4hlCD84dZ",
        "outputId": "12ceb94a-e47e-4dad-b5ba-a156676ad2d8"
      },
      "id": "i6G4hlCD84dZ",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'benchmarl.conf.Task'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-cc7aa2e72531>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbenchmarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlgorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbenchmarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomenv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtask_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbenchmarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomEnvTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'benchmarl.conf.Task'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa7225f",
      "metadata": {
        "id": "caa7225f"
      },
      "source": [
        "# Launch from command line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30075032",
      "metadata": {
        "id": "30075032"
      },
      "source": [
        "To launch an experiment from the command line you can do"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5369898f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5369898f",
        "outputId": "f92c5fdb-5c95-44af-90d7-f14e73df3ec7",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "mean return = -6.000116348266602: 100% 2/2 [01:14<00:00, 37.27s/it]\n"
          ]
        }
      ],
      "source": [
        "!python benchmarl/run.py algorithm=mappo task=vmas/balance experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23f9338f",
      "metadata": {
        "id": "23f9338f"
      },
      "source": [
        "You can run benchmarks as multi-runs like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90a135ea",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "90a135ea",
        "scrolled": false,
        "outputId": "f54fb162-4357-4054-f6ba-4c83c90bb485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-02-09 21:44:49,283][HYDRA] Launching 12 jobs locally\n",
            "[2025-02-09 21:44:49,283][HYDRA] \t#0 : algorithm=mappo task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "mean return = -6.000116348266602: 100% 2/2 [01:14<00:00, 37.48s/it]\n",
            "[2025-02-09 21:46:04,751][HYDRA] \t#1 : algorithm=mappo task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "mean return = -5.960851669311523: 100% 2/2 [01:13<00:00, 36.99s/it]\n",
            "[2025-02-09 21:47:19,018][HYDRA] \t#2 : algorithm=mappo task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/vmas/simulator/utils.py:136: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  colormap = cm.get_cmap(cmap_name, cmap_res)(range(cmap_res))[:, :-1]\n",
            "mean return = 3.817323923110962: 100% 2/2 [02:00<00:00, 60.13s/it]\n",
            "[2025-02-09 21:49:23,565][HYDRA] \t#3 : algorithm=mappo task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: mappo, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  clip_epsilon: 0.2\n",
            "  entropy_coef: 0.0\n",
            "  critic_coef: 1.0\n",
            "  loss_critic_type: l2\n",
            "  lmbda: 0.9\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "  minibatch_advantage: false\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "mean return = 4.166626930236816: 100% 2/2 [01:59<00:00, 59.93s/it]\n",
            "[2025-02-09 21:51:28,253][HYDRA] \t#4 : algorithm=qmix task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "mean return = -9.352529525756836: 100% 2/2 [01:04<00:00, 32.43s/it]\n",
            "[2025-02-09 21:52:33,400][HYDRA] \t#5 : algorithm=qmix task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "mean return = -5.238662242889404: 100% 2/2 [01:04<00:00, 32.48s/it]\n",
            "[2025-02-09 21:53:38,662][HYDRA] \t#6 : algorithm=qmix task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "mean return = 6.936652660369873: 100% 2/2 [01:52<00:00, 56.16s/it]\n",
            "[2025-02-09 21:55:35,276][HYDRA] \t#7 : algorithm=qmix task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: qmix, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  mixing_embed_dim: 32\n",
            "  delay_value: true\n",
            "  loss_function: l2\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "mean return = 10.524405479431152: 100% 2/2 [01:53<00:00, 56.54s/it]\n",
            "[2025-02-09 21:57:32,704][HYDRA] \t#8 : algorithm=masac task=vmas/balance seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "mean return = -5.443538665771484: 100% 2/2 [01:39<00:00, 49.96s/it]\n",
            "[2025-02-09 21:59:12,922][HYDRA] \t#9 : algorithm=masac task=vmas/balance seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/balance\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 4\n",
            "  random_package_pos_on_line: true\n",
            "  package_mass: 5.0\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "mean return = -6.2703399658203125: 100% 2/2 [01:41<00:00, 50.92s/it]\n",
            "[2025-02-09 22:00:55,298][HYDRA] \t#10 : algorithm=masac task=vmas/sampling seed=0 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 0\n",
            "\n",
            "mean return = 2.822174310684204: 100% 2/2 [02:29<00:00, 74.68s/it]\n",
            "[2025-02-09 22:03:29,900][HYDRA] \t#11 : algorithm=masac task=vmas/sampling seed=1 experiment.max_n_iters=2 experiment.loggers=[]\n",
            "\n",
            "Algorithm: masac, Task: vmas/sampling\n",
            "\n",
            "Loaded config:\n",
            "\n",
            "experiment:\n",
            "  sampling_device: cpu\n",
            "  train_device: cpu\n",
            "  buffer_device: cpu\n",
            "  share_policy_params: true\n",
            "  prefer_continuous_actions: true\n",
            "  collect_with_grad: false\n",
            "  parallel_collection: false\n",
            "  gamma: 0.99\n",
            "  lr: 5.0e-05\n",
            "  adam_eps: 1.0e-06\n",
            "  clip_grad_norm: true\n",
            "  clip_grad_val: 5.0\n",
            "  soft_target_update: true\n",
            "  polyak_tau: 0.005\n",
            "  hard_target_update_frequency: 5\n",
            "  exploration_eps_init: 0.8\n",
            "  exploration_eps_end: 0.01\n",
            "  exploration_anneal_frames: null\n",
            "  max_n_iters: 2\n",
            "  max_n_frames: 3000000\n",
            "  on_policy_collected_frames_per_batch: 6000\n",
            "  on_policy_n_envs_per_worker: 10\n",
            "  on_policy_n_minibatch_iters: 45\n",
            "  on_policy_minibatch_size: 400\n",
            "  off_policy_collected_frames_per_batch: 6000\n",
            "  off_policy_n_envs_per_worker: 10\n",
            "  off_policy_n_optimizer_steps: 1000\n",
            "  off_policy_train_batch_size: 128\n",
            "  off_policy_memory_size: 1000000\n",
            "  off_policy_init_random_frames: 0\n",
            "  off_policy_use_prioritized_replay_buffer: false\n",
            "  off_policy_prb_alpha: 0.6\n",
            "  off_policy_prb_beta: 0.4\n",
            "  evaluation: true\n",
            "  render: true\n",
            "  evaluation_interval: 120000\n",
            "  evaluation_episodes: 10\n",
            "  evaluation_deterministic_actions: true\n",
            "  loggers: []\n",
            "  project_name: benchmarl\n",
            "  create_json: true\n",
            "  save_folder: null\n",
            "  restore_file: null\n",
            "  restore_map_location: null\n",
            "  checkpoint_interval: 0\n",
            "  checkpoint_at_end: false\n",
            "  keep_checkpoints_num: 3\n",
            "algorithm:\n",
            "  share_param_critic: true\n",
            "  num_qvalue_nets: 2\n",
            "  loss_function: l2\n",
            "  delay_qvalue: true\n",
            "  target_entropy: auto\n",
            "  discrete_target_entropy_weight: 0.2\n",
            "  alpha_init: 1.0\n",
            "  min_alpha: null\n",
            "  max_alpha: null\n",
            "  fixed_alpha: false\n",
            "  scale_mapping: biased_softplus_1.0\n",
            "  use_tanh_normal: true\n",
            "task:\n",
            "  max_steps: 100\n",
            "  n_agents: 3\n",
            "  shared_rew: false\n",
            "  n_gaussians: 3\n",
            "  lidar_range: 0.2\n",
            "  cov: 0.05\n",
            "  collisions: true\n",
            "  spawn_same_pos: false\n",
            "model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "critic_model:\n",
            "  name: mlp\n",
            "  num_cells:\n",
            "  - 256\n",
            "  - 256\n",
            "  layer_class: torch.nn.Linear\n",
            "  activation_class: torch.nn.Tanh\n",
            "  activation_kwargs: null\n",
            "  norm_class: null\n",
            "  norm_kwargs: null\n",
            "seed: 1\n",
            "\n",
            "mean return = 2.9178502559661865: 100% 2/2 [02:30<00:00, 75.13s/it]\n"
          ]
        }
      ],
      "source": [
        "!python benchmarl/run.py -m algorithm=mappo,qmix,masac task=vmas/balance,vmas/sampling seed=0,1 experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b01091a",
      "metadata": {
        "id": "0b01091a"
      },
      "source": [
        "# Launch from a python script"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c6dc69",
      "metadata": {
        "id": "67c6dc69"
      },
      "source": [
        "You can also load and launch your experiments from within a script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c5b5fcd",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2c5b5fcd",
        "outputId": "43a4b645-d9f4-4d17-b5d4-791fd371e159"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "mean return = -6.000116348266602: 100%|██████████| 2/2 [01:11<00:00, 35.81s/it]\n"
          ]
        }
      ],
      "source": [
        "from benchmarl.algorithms import MappoConfig\n",
        "from benchmarl.environments import VmasTask\n",
        "from benchmarl.experiment import Experiment, ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas/balance.yaml\"\n",
        "task = VmasTask.BALANCE.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/algorithm/mappo.yaml\"\n",
        "algorithm_config = MappoConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/model/layers/mlp.yaml\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "experiment = Experiment(\n",
        "    task=task,\n",
        "    algorithm_config=algorithm_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        "    seed=0,\n",
        "    config=experiment_config,\n",
        ")\n",
        "experiment.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20864e3",
      "metadata": {
        "id": "a20864e3"
      },
      "source": [
        "You can also run multiple experiments in a Benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec3bd4b",
      "metadata": {
        "id": "6ec3bd4b"
      },
      "outputs": [],
      "source": [
        "from benchmarl.algorithms import MappoConfig, MasacConfig, QmixConfig\n",
        "from benchmarl.benchmark import Benchmark\n",
        "from benchmarl.environments import VmasTask\n",
        "from benchmarl.experiment import ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas\"\n",
        "tasks = [VmasTask.BALANCE.get_from_yaml(), VmasTask.SAMPLING.get_from_yaml()]\n",
        "# Loads from \"benchmarl/conf/algorithm\"\n",
        "algorithm_configs = [\n",
        "    MappoConfig.get_from_yaml(),\n",
        "    QmixConfig.get_from_yaml(),\n",
        "    MasacConfig.get_from_yaml(),\n",
        "]\n",
        "# Loads from \"benchmarl/conf/model/layers\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "benchmark = Benchmark(\n",
        "    algorithm_configs=algorithm_configs,\n",
        "    tasks=tasks,\n",
        "    seeds={0, 1},\n",
        "    experiment_config=experiment_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        ")\n",
        "benchmark.run_sequential()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}