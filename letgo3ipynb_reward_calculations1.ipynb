{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsarpongstreetor/2DayCourse/blob/master/letgo3ipynb_reward_calculations1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4i_dlI0pJgrt"
      },
      "id": "4i_dlI0pJgrt"
    },
    {
      "cell_type": "markdown",
      "id": "20326118",
      "metadata": {
        "id": "20326118"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2422f32f",
      "metadata": {
        "id": "2422f32f"
      },
      "source": [
        "## Install BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "8b10fd32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b10fd32",
        "outputId": "a366f1c0-07ad-48fb-c708-ebdc3565174c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'BenchMARL' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!git clone https://github.com/facebookresearch/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "6cd7b69b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cd7b69b",
        "outputId": "06834e28-fafc-40c0-a5dd-9b5bf2df86f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BenchMARL\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "%cd /content/BenchMARL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4f32b88e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f32b88e",
        "outputId": "dc598ac7-0ed5-4586-9846-d163538a723c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Obtaining file:///content/BenchMARL\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchrl~=0.7.0 in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (0.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (4.67.1)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (1.3.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (0.21.0)\n",
            "Requirement already satisfied: av<14 in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (13.1.0)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (3.1.1)\n",
            "Requirement already satisfied: tensordict>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (0.7.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core->benchmarl==1.4.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core->benchmarl==1.4.0) (4.9.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->benchmarl==1.4.0) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core->benchmarl==1.4.0) (6.0.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.7.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.10.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.0.2)\n",
            "Building wheels for collected packages: benchmarl\n",
            "  Building editable for benchmarl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benchmarl: filename=benchmarl-1.4.0-0.editable-py3-none-any.whl size=3797 sha256=7c84adff588308fccaaf23c26aea0455858f4758e5425af6452a8374a90d494b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-10mb9ncc/wheels/d1/dc/58/2f83c40b8458f8cd6be0bee519061fa93523762dfc8aad5e9b\n",
            "Successfully built benchmarl\n",
            "Installing collected packages: benchmarl\n",
            "  Attempting uninstall: benchmarl\n",
            "    Found existing installation: benchmarl 1.4.0\n",
            "    Uninstalling benchmarl-1.4.0:\n",
            "      Successfully uninstalled benchmarl-1.4.0\n",
            "Successfully installed benchmarl-1.4.0\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!pip install -U torch torchvision\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "585d3a35",
      "metadata": {
        "id": "585d3a35"
      },
      "source": [
        "## Install VMAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "d2e551b1",
      "metadata": {
        "id": "d2e551b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9461dd29-527c-4285-e2fe-95ef67fef2af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vmas in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vmas) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from vmas) (2.6.0)\n",
            "Requirement already satisfied: pyglet<=1.5.27 in /usr/local/lib/python3.11/dist-packages (from vmas) (1.5.27)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (from vmas) (0.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from vmas) (1.17.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym->vmas) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym->vmas) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->vmas) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->vmas) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->vmas) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!pip install vmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "33d72783",
      "metadata": {
        "id": "33d72783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34ba837d-7473-42a7-e87f-6ae8944461ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connected to r2u.stat.illinois.edu (192\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 257 kB in 2s (113 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+5build2).\n",
            "python3-opengl is already the newest version (3.1.5+dfsg-1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.11/dist-packages (3.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7c63edf58610>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#@title\n",
        "!apt-get update\n",
        "!apt-get install -y x11-utils python3-opengl xvfb\n",
        "!pip install pyvirtualdisplay\n",
        "import pyvirtualdisplay\n",
        "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install torch\n",
        "!pip install torchrl\n",
        "!pip install  tensorboard\n",
        "!pip install wandb\n",
        "!pip install TensorDict\n",
        "!pip install pyyaml\n",
        "!pip install torch_geometric\n",
        "!apt-get install python3-opengl\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l-yMWldyWGMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09880f3f-d13b-4a6c-ce68-ae765eb2c774"
      },
      "id": "l-yMWldyWGMO",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.11/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchrl) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl) (3.1.1)\n",
            "Requirement already satisfied: tensordict>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from torchrl) (0.7.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.7.0->torchrl) (3.10.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->torchrl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->torchrl) (3.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: TensorDict in /usr/local/lib/python3.11/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from TensorDict) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from TensorDict) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from TensorDict) (3.1.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from TensorDict) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from TensorDict) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->TensorDict) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->TensorDict) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->TensorDict) (3.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-opengl is already the newest version (3.1.5+dfsg-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install BenchMARL\n",
        "!git clone https://github.com/facebookresearch/BenchMARL\n",
        "%cd /content/BenchMARL # Navigate into the BenchMARL directory\n",
        "!pip install -e BenchMARL  # Install the package in editable mode\n",
        "%cd /content #Navigate back to original directory\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qveXPf2YcdSW",
        "outputId": "fb368a15-1dfb-4869-db32-d57de295874c"
      },
      "id": "qveXPf2YcdSW",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'BenchMARL' already exists and is not an empty directory.\n",
            "[Errno 2] No such file or directory: '/content/BenchMARL # Navigate into the BenchMARL directory'\n",
            "/content/BenchMARL\n",
            "Obtaining file:///content/BenchMARL/BenchMARL\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchrl~=0.7.0 in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (0.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (4.67.1)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (1.3.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (0.21.0)\n",
            "Requirement already satisfied: av<14 in /usr/local/lib/python3.11/dist-packages (from benchmarl==1.4.0) (13.1.0)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (3.1.1)\n",
            "Requirement already satisfied: tensordict>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from torchrl~=0.7.0->benchmarl==1.4.0) (0.7.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core->benchmarl==1.4.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core->benchmarl==1.4.0) (4.9.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->benchmarl==1.4.0) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core->benchmarl==1.4.0) (6.0.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.7.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.10.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->torchrl~=0.7.0->benchmarl==1.4.0) (3.0.2)\n",
            "Building wheels for collected packages: benchmarl\n",
            "  Building editable for benchmarl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benchmarl: filename=benchmarl-1.4.0-0.editable-py3-none-any.whl size=3796 sha256=5edbddc8bcaf084477236d170982358917066cec5b53dc1bdc45106004a47cc3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0bite6te/wheels/e5/4c/bc/8b06876d997ea1eb007995116b58c9caa4affc7bc7b7142dda\n",
            "Successfully built benchmarl\n",
            "Installing collected packages: benchmarl\n",
            "  Attempting uninstall: benchmarl\n",
            "    Found existing installation: benchmarl 1.4.0\n",
            "    Uninstalling benchmarl-1.4.0:\n",
            "      Successfully uninstalled benchmarl-1.4.0\n",
            "Successfully installed benchmarl-1.4.0\n",
            "[Errno 2] No such file or directory: '/content #Navigate back to original directory'\n",
            "/content/BenchMARL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find / -name \"anfuelpriceenv\" -type d -exec rm -rf {} +"
      ],
      "metadata": {
        "id": "mu7z3s4rdOH4"
      },
      "id": "mu7z3s4rdOH4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install custom environment package\n",
        "!git clone https://github.com/rsarpongstreetor/anfuelpriceenv\n",
        "%cd anfuelpriceenv # Navigate to the anfuelpriceenv directory\n",
        "!touch __init__.py # Create __init__.py\n",
        "%cd .. # Navigate back to the previous directory\n",
        "!pip install -e anfuelpriceenv"
      ],
      "metadata": {
        "id": "QBfAjCWvdMnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034e36a5-74e6-46ce-d6d9-563e1f036362"
      },
      "id": "QBfAjCWvdMnu",
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'anfuelpriceenv'...\n",
            "remote: Enumerating objects: 456, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 456 (delta 14), reused 0 (delta 0), pack-reused 431 (from 1)\u001b[K\n",
            "Receiving objects: 100% (456/456), 183.35 KiB | 915.00 KiB/s, done.\n",
            "Resolving deltas: 100% (264/264), done.\n",
            "[Errno 2] No such file or directory: 'anfuelpriceenv # Navigate to the anfuelpriceenv directory'\n",
            "/content/BenchMARL\n",
            "[Errno 2] No such file or directory: '.. # Navigate back to the previous directory'\n",
            "/content/BenchMARL\n",
            "Obtaining file:///content/BenchMARL/anfuelpriceenv\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (2.6.0)\n",
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: tensordict in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from AnFuelpriceEnv==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->AnFuelpriceEnv==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->AnFuelpriceEnv==0.1.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->AnFuelpriceEnv==0.1.0) (2025.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tensordict->AnFuelpriceEnv==0.1.0) (3.1.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict->AnFuelpriceEnv==0.1.0) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensordict->AnFuelpriceEnv==0.1.0) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->AnFuelpriceEnv==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->AnFuelpriceEnv==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->AnFuelpriceEnv==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->AnFuelpriceEnv==0.1.0) (3.0.2)\n",
            "Installing collected packages: AnFuelpriceEnv\n",
            "  Running setup.py develop for AnFuelpriceEnv\n",
            "Successfully installed AnFuelpriceEnv-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyvirtualdisplay\n",
        "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "display.start()\n",
        "# %%\n",
        "import pyvirtualdisplay\n",
        "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "display.start()\n",
        "import multiprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import NormalParamExtractor\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.envs import (Compose, DoubleToFloat, ObservationNorm, StepCounter, TransformedEnv)\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type, step_mdp\n",
        "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from tqdm import tqdm\n",
        "import google.colab\n",
        "import pygame\n",
        "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
        "import random\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "import plotly.express as px\n",
        "import pandas\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "from google.colab import drive\n",
        "google.colab.drive.mount('/content/drive')\n",
        "from collections import defaultdict\n",
        "from typing import Optional, Any, Dict, List, Union, TypedDict\n",
        "import torchrl\n",
        "import numpy as np\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "from torchrl.modules import MultiAgentConvNet\n",
        "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec, DiscreteTensorSpec\n",
        "from torchrl.envs import (\n",
        "    CatTensors,\n",
        "    EnvBase,\n",
        "    Transform,\n",
        "    TransformedEnv,\n",
        "    UnsqueezeTransform,\n",
        ")\n",
        "\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "import tensordict as td\n",
        "import yaml # Import the yaml library for loading YAML files\n",
        "from benchmarl.algorithms import MappoConfig\n",
        "from benchmarl.environments import VmasTask # Import VmasTask instead of CustomEnvTask\n",
        "from benchmarl.experiment import Experiment, ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30FNjZrog_df",
        "outputId": "db368038-565e-445c-b0a1-cc5535b20149"
      },
      "id": "30FNjZrog_df",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Assuming you are in the main project directory\n",
        "file_path = 'anfuelpriceenv/task_1.yaml'\n",
        "\n",
        "# Open and load the YAML file\n",
        "with open(file_path, 'r') as file:\n",
        "    task_1_data = yaml.safe_load(file)\n",
        "\n",
        "# Access the data (e.g., printing it)\n",
        "print(task_1_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBpjjwyzh04h",
        "outputId": "1f6048ec-4f1b-46cc-8870-2b2b6399b1d8"
      },
      "id": "YBpjjwyzh04h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'defaults': [None, '_self_'], 'max_steps': 100, 'supports_continuous_actions': True, 'supports_discrete_actions': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CustomEnvTask"
      ],
      "metadata": {
        "id": "AjcEWkuLiQKu"
      },
      "id": "AjcEWkuLiQKu"
    },
    {
      "source": [
        "from benchmarl.models import SequenceModelConfig, GnnConfig, MlpConfig\n",
        "from benchmarl.algorithms import IppoConfig, MappoConfig, QmixConfig, MasacConfig\n",
        "from typing import Callable, Dict, List, Optional\n",
        "\n",
        "from benchmarl.environments.common import Task\n",
        "from benchmarl.utils import DEVICE_TYPING\n",
        "\n",
        "from tensordict import TensorDictBase\n",
        "from torchrl.data import CompositeSpec, DiscreteTensorSpec, TensorSpec, UnboundedContinuousTensorSpec\n",
        "from torchrl.envs import EnvBase\n",
        "from anfuelpriceenv.AnFuelpriceEnv import AnFuelpriceEnv\n",
        "# from benchmarl.environments.customenv.common import CustomEnvTask\n",
        "# from benchmarl.task.customenv import task_1\n",
        "import yaml  # Import the yaml module\n",
        "\n",
        "\n",
        "# AnFuelpriceEnv =AnFuelpriceEnv ()\n",
        "\n",
        "class CustomEnvTask(Task):\n",
        "    # Your task names.\n",
        "    # Their config will be loaded from conf/task/customenv\n",
        "\n",
        "    TASK_1 = None  # Loaded automatically from conf/task/customenv/task_1\n",
        "    TASK_2 = None  # Loaded automatically from conf/task/customenv/task_2\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)  # Initialize the parent class\n",
        "\n",
        "        # Ensure self.config is a dictionary; load from YAML if necessary\n",
        "        if self.config is None:\n",
        "            with open(f\"anfuelpriceenv/{self.name.lower()}.yaml\", 'r') as file:\n",
        "                self.config = yaml.safe_load(file)\n",
        "        elif not isinstance(self.config, dict):\n",
        "            self.config = {}\n",
        "\n",
        "    def get_env_fun( self,num_envs: int, continuous_actions: bool, seed: Optional[int], device: DEVICE_TYPING,) -> Callable[[], EnvBase]:\n",
        "        return lambda: AnFuelpriceEnv(\n",
        "            scenario=self.name.lower(),\n",
        "            # num_envs=num_envs,  # Number of vectorized envs (do not use this param if the env is not vectorized)\n",
        "            continuous_actions=continuous_actions,  # Ignore this param if your env does not have this choice\n",
        "            seed=seed,\n",
        "            device=device,\n",
        "            categorical_actions=True,  # If your env has discrete actions, they need to be categorical (TorchRL can help with this)\n",
        "            **self.config,  # Pass the loaded config (this is what is in your yaml\n",
        "        )\n",
        "\n",
        "    def supports_continuous_actions(self) -> bool:\n",
        "        # Does the environment support continuous actions?\n",
        "        return True\n",
        "\n",
        "    def supports_discrete_actions(self) -> bool:\n",
        "        # Does the environment support discrete actions?\n",
        "        return True\n",
        "\n",
        "    def has_render(self, env: EnvBase) -> bool:\n",
        "        # Does the env have a env.render(mode=\"rgb_array\") or env.render() function?\n",
        "        return True\n",
        "\n",
        "    def max_steps(self, env: EnvBase) -> int:\n",
        "        # Maximum number of steps for a rollout during evaluation\n",
        "        return 100\n",
        "\n",
        "    def group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "       # The group map mapping group names to agent names\n",
        "        # The data in the tensordict will havebe presented this way\n",
        "        # Access agent names from dictionary keys if env.agents is a dictionary\n",
        "        \"\"\" if hasattr(env, 'n_agents'):\n",
        "            return {\"agents\": list(range(env.n_agents))}  # Changed to a list of agent indices\n",
        "        elif isinstance(env.agents, dict):\n",
        "            return {\"agents\": list(env.agents.keys())}  # Get keys from dictionary if it's a dictionary\n",
        "        elif hasattr(env, 'possible_agents'):  # Check if 'possible_agents' exists\n",
        "            return {\"agents\": env.possible_agents}  # Use 'possible_agents' if available\n",
        "        else:  # Fallback if neither condition is met\n",
        "            return {\"agents\": [agent.name for agent in env.agents]}  # This is unlikely to happen, but here as a fallback\"\"\"\n",
        "        return {\"agents\": [agent[\"name\"] for agent in env.agents]}  # This is unlikely to happen, but here as a fallback\n",
        "\n",
        "        \"\"\" def observation_spec(self, env: EnvBase) -> CompositeSpec:\n",
        "        \"Get the observation spec for a single agent.\"\"\n",
        "        agent_obs_spec = env.observation_spec[\"agents\"][\"observation\"][\"observat\"]  # Accessing \"observat\" directly\n",
        "        agent_pos_spec = env.observation_spec[\"agents\"][\"observation\"][\"position_key\"]  # Accessing \"position_key\" (Date)\n",
        "\n",
        "        # Assuming your observation space is continuous and bounded:\n",
        "        if isinstance(agent_obs_spec, BoundedTensorSpec) and isinstance(agent_pos_spec, BoundedTensorSpec):\n",
        "            return CompositeSpec(\n",
        "                agents=CompositeSpec(\n",
        "                    observation=CompositeSpec(\n",
        "                        observat=agent_obs_spec,\n",
        "                        position_key=agent_pos_spec\n",
        "                    ),\n",
        "                )\n",
        "            )\n",
        "        # If it's DiscreteTensorSpec (unlikely for both, but handling for completeness):\n",
        "        elif isinstance(agent_obs_spec, DiscreteTensorSpec) and isinstance(agent_pos_spec, DiscreteTensorSpec):\n",
        "            return CompositeSpec(\n",
        "                agents=CompositeSpec(\n",
        "                    observation=CompositeSpec(\n",
        "                        observat=agent_obs_spec,\n",
        "                        position_key=agent_pos_spec\n",
        "                    ),\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            # Handle other cases or raise an error if unexpected type\n",
        "            raise TypeError(f\"Unexpected type for agent_obs_spec or agent_pos_spec: {type(agent_obs_spec)}, {type(agent_pos_spec)}\")\n",
        "\n",
        "\n",
        "        agent_obs_spec = env.observation_spec[\"agents\"][\"observation\"][\"observat\"]  # Accessing \"observat\" directly\n",
        "\n",
        "\n",
        "        # Assuming \"observation\" is a key within agent_obs_spec that holds the actual spec\n",
        "        # Navigate to the relevant BoundedTensorSpec or BoundedContinuous\n",
        "        if isinstance(agent_obs_spec, CompositeSpec) and \"observation\" in agent_obs_spec:\n",
        "            agent_obs_spec = agent_obs_spec[\"observation\"]\n",
        "        if isinstance(agent_obs_spec, CompositeSpec):\n",
        "            agent_obs_spec = agent_obs_spec[list(agent_obs_spec.keys())[0]]\n",
        "\n",
        "        # Get the observation space\n",
        "        observation_space = agent_obs_spec.space\n",
        "\n",
        "\n",
        "      # Check if observation space has 'low' and 'high' attribute\n",
        "        if hasattr(observation_space, 'low') and hasattr(observation_space, 'high'):\n",
        "          low_bound = observation_space.low\n",
        "          high_bound = observation_space.high\n",
        "\n",
        "            # Ensure low_bound and high_bound have the same shape\n",
        "          if low_bound.shape != high_bound.shape:\n",
        "            raise ValueError(\"low_bound and high_bound must have the same shape.\")\n",
        "            # **Change here: Use the shape of low_bound or high_bound directly**\n",
        "            shape = low_bound.shape  # or high_bound.shape\n",
        "          else:\n",
        "                return CompositeSpec(\n",
        "                            agents=CompositeSpec(\n",
        "                                observation=BoundedTensorSpec(\n",
        "                                    low=low_bound,\n",
        "                                    high=high_bound,\n",
        "                                    dtype=agent_obs_spec.dtype,\n",
        "                                    device=env.device,\n",
        "                                ),\n",
        "                            )\n",
        "                        )\n",
        "\n",
        "        else:\n",
        "            # Assum ing your Discrete space has an 'n' attribute (number of discrete values)\n",
        "            n = observation_space.n\n",
        "            shape = (env.n_agents,)  # Assuming observation shape is (n_agents,)\n",
        "\n",
        "            return CompositeSpec(\n",
        "                agents=CompositeSpec(\n",
        "                    observation=DiscreteTensorSpec(n=n, shape=shape, device=env.device),\n",
        "                )\n",
        "            )\"\"\"\n",
        "\n",
        "\n",
        "    def observation_spec(self, env: EnvBase) -> CompositeSpec:\n",
        "        \"\"\"Get the observation spec for a single agent.\"\"\"\n",
        "        # Assuming your observation spec is already nested correctly:\n",
        "        return env.observation_spec[\"agents\", \"observation\"]\n",
        "\n",
        "\n",
        "    def state_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the state.\n",
        "        # If provided, must be a CompositeSpec with one \"state\" entry\n",
        "        return None\n",
        "\n",
        "    def action_mask_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the action mask.\n",
        "        # If provided, must be a CompositeSpec with one (group_name, \"action_mask\") entry per group.\n",
        "        return None\n",
        "\n",
        "    def info_spec(self, env: EnvBase) -> Optional[CompositeSpec]:\n",
        "        # A spec for the info.\n",
        "        # If provided, must be a CompositeSpec with one (group_name, \"info\") entry per group (this entry can be composite).\n",
        "        # A spec for the info.\n",
        "        # If provided, must be a CompositeSpec with one (group_name, \"info\") entry per group (this entry can be composite).\n",
        "        # Assuming rewards have shape (13, 9, 9):\n",
        "        reward_spec = BoundedTensorSpec(\n",
        "            low=torch.tensor([[-float('inf')] * 9] * 9),\n",
        "            high=torch.tensor([[float('inf')] * 9] * 9),\n",
        "            shape=(13, 9, 9),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "        return CompositeSpec({\n",
        "            \"agents\": CompositeSpec({\"info\": CompositeSpec({\"reward\": reward_spec})})\n",
        "        })\n",
        "\n",
        "\n",
        "    def action_spec(self, env: EnvBase) -> CompositeSpec:\n",
        "        #Example of an action_spec\n",
        "        #return CompositeSpec(agents=DiscreteTensorSpec(5,shape=(1,)))\n",
        "        return env.action_spec  # Modified line\n",
        "        \"\"\"This method needs to be implemented to define the action space\n",
        "        of your custom environment. It should return a `CompositeSpec`\n",
        "        representing the action space.\n",
        "\n",
        "        For example, if your environment has a discrete action space\n",
        "        with 5 actions for each of 2 agents, you would return:\"\"\"\n",
        "\n",
        "    def env_name(self) -> str:\n",
        "          # Provide the name of your custom environment here\n",
        "          return \"AnFuelpriceEnv\" #or any suitable name"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "qmBGr1m-39Cn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71dfcb73-fe43-4a1a-e112-240b228d32f8"
      },
      "id": "qmBGr1m-39Cn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The DiscreteTensorSpec has been deprecated and will be removed in v0.8. Please use Categorical instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.8. Please use Bounded instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*action_spec: Composite(\n",
            "    agent_0: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_1: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*reward_spec: Composite(\n",
            "    agent_0: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*done_spec: Composite(\n",
            "    done: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*observation_spec: Composite(\n",
            "    agents: Composite(\n",
            "        observat: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        position_key: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "-action_keys: ['agent_0', 'agent_1']\n",
            "\n",
            "-reward_keys: ['agent_0', 'agent_1']\n",
            "\n",
            "-done_keys: ['done', 'terminated']\n",
            "input_spec: Composite(\n",
            "    full_state_spec: Composite(\n",
            "    ,\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    full_action_spec: Composite(\n",
            "        agent_0: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        agent_1: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "reward_spec: Composite(\n",
            "    agent_0: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "action_spec (as defined by input_spec): Composite(\n",
            "    agent_0: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_1: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "reset tensordict TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                agent_0: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False),\n",
            "                agent_1: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False)},\n",
            "            batch_size=torch.Size([10, 10]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10, 10]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-a97e11387be4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompositeSpec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiscreteTensorSpec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorSpec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnboundedContinuousTensorSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnvBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0manfuelpriceenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAnFuelpriceEnv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnFuelpriceEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# from benchmarl.environments.customenv.common import CustomEnvTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# from benchmarl.task.customenv import task_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/anfuelpriceenv/AnFuelpriceEnv.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m \u001b[0mcheck_env_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/utils.py\u001b[0m in \u001b[0;36mcheck_env_specs\u001b[0;34m(env, return_contiguous, check_dtype, seed, tensordict)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0mfake_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_tensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m     real_tensordict = env.rollout(\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mreturn_contiguous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_contiguous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[0m\n\u001b[1;32m   3129\u001b[0m         }\n\u001b[1;32m   3130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbreak_when_any_done\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3131\u001b[0;31m             tensordicts = self._rollout_stop_early(\n\u001b[0m\u001b[1;32m   3132\u001b[0m                 \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m                 \u001b[0mbreak_when_any_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbreak_when_any_done\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m_rollout_stop_early\u001b[0;34m(self, break_when_any_done, break_when_all_done, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[0m\n\u001b[1;32m   3270\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3271\u001b[0m                     \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_device_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3272\u001b[0;31m             \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3273\u001b[0m             \u001b[0mtd_append\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1974\u001b[0;31m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_proc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext_preset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m             \u001b[0;31m# tensordict could already have a \"next\" key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m_step_proc_data\u001b[0;34m(self, next_tensordict_out)\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 ]\n\u001b[1;32m   2066\u001b[0m             )\n\u001b[0;32m-> 2067\u001b[0;31m             \u001b[0mactual_reward_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2068\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mactual_reward_shape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_reward_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m                 \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_reward_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric  # Make sure the torch_geometric package is installed\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.13.0+cu118.html #Install torch-scatter\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu118.html #Install torch-sparse\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-1.13.0+cu118.html #Install torch-cluster\n",
        "\n",
        "import torch_geometric # explicitly import the library in your code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lJ32ST6jX6R",
        "outputId": "2b7f09ee-493a-49c4-a806-14c338528005"
      },
      "id": "1lJ32ST6jX6R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=547369 sha256=f107e322fd08e7493c181cc4ddef2f1346aeb5d09a6dde83023d673efe5fdc1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp311-cp311-linux_x86_64.whl size=1127935 sha256=e4aaf25b514dba92211e461778cc87ed0f1157718ca608a8b92f5a59df916d9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/e2/1e/299c596063839303657c211f587f05591891cc6cf126d94d21\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu118.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of CustomEnvTask\n",
        "custom_env_task = CustomEnvTask.TASK_1\n",
        "\n",
        "  # Set the task name\n",
        "\n",
        "# Get the task from YAML using the instance and its member\n",
        "task =custom_env_task\n",
        "\n",
        "experiment = Experiment(\n",
        "    algorithm_config=MappoConfig.get_from_yaml(),\n",
        "    model_config=GnnConfig(\n",
        "        topology=\"full\",\n",
        "        self_loops=False,\n",
        "        position_key=None,\n",
        "        pos_features=0,\n",
        "        exclude_pos_from_node_features=False,\n",
        "        gnn_class=torch_geometric.nn.conv.GATv2Conv,\n",
        "        gnn_kwargs={},),\n",
        "\n",
        "\n",
        "    critic_model_config=SequenceModelConfig(\n",
        "        model_configs=[\n",
        "            MlpConfig(num_cells=[8], activation_class=nn.Tanh, layer_class=nn.Linear),\n",
        "            GnnConfig( # Using GnnConfig here (removed CriticGnnConfig)\n",
        "                topology=\"full\",\n",
        "                self_loops=False,\n",
        "                gnn_class=torch_geometric.nn.conv.GraphConv,\n",
        "            ),\n",
        "            MlpConfig(num_cells=[6], activation_class=nn.Tanh, layer_class=nn.Linear),\n",
        "        ],\n",
        "        intermediate_sizes=[5, 3],\n",
        "    ),\n",
        "    seed=0,\n",
        "    config=ExperimentConfig.get_from_yaml(),\n",
        "\n",
        "    task=task,\n",
        "    #loggers=[\"tensorboard\"],\n",
        "    #save_folder='C:\\\\Users\\\\Richard Sarpong-Stre\\\\OneDrive\\\\Desktop\\\\usreslts\\\\results' #Replace with valid path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ")\n",
        "experiment.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "wk1_tDh5lhys",
        "outputId": "3a770f24-b847-4dfc-a4de-61e15021b78e"
      },
      "id": "wk1_tDh5lhys",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CustomEnvTask' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-29796f3d6ad5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create an instance of CustomEnvTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcustom_env_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomEnvTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTASK_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# Set the task name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CustomEnvTask' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EjnZs_l-J8YX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ec3804d-d685-4c80-f96e-005bd69ec837"
      },
      "id": "EjnZs_l-J8YX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The DiscreteTensorSpec has been deprecated and will be removed in v0.8. Please use Categorical instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The BoundedTensorSpec has been deprecated and will be removed in v0.8. Please use Bounded instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/tensor_specs.py:6294: DeprecationWarning: The CompositeSpec has been deprecated and will be removed in v0.8. Please use Composite instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*action_spec: Composite(\n",
            "    agent_0: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_1: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_2: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*reward_spec: Composite(\n",
            "    agent_0: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_2: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*done_spec: Composite(\n",
            "    done: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "*observation_spec: Composite(\n",
            "    agents: Composite(\n",
            "        observat: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_2: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        position_key: Composite(\n",
            "            agent_0: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_1: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            agent_2: BoundedContinuous(\n",
            "                shape=torch.Size([10, 10, 1, 9, 9]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10, 10])),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "\n",
            "-action_keys: ['agent_0', 'agent_1', 'agent_2']\n",
            "\n",
            "-reward_keys: ['agent_0', 'agent_1', 'agent_2']\n",
            "\n",
            "-done_keys: ['done', 'terminated']\n",
            "input_spec: Composite(\n",
            "    full_state_spec: Composite(\n",
            "    ,\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    full_action_spec: Composite(\n",
            "        agent_0: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        agent_1: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        agent_2: DiscreteTensorSpec(\n",
            "            shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "            space=CategoricalBox(n=3),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=discrete),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "reward_spec: Composite(\n",
            "    agent_0: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_1: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    agent_2: BoundedContinuous(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "action_spec (as defined by input_spec): Composite(\n",
            "    agent_0: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_1: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    agent_2: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 10, 13, 9, 9]),\n",
            "        space=CategoricalBox(n=3),\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10, 10]))\n",
            "reset tensordict TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                agent_0: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False),\n",
            "                agent_1: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False),\n",
            "                agent_2: TensorDict(\n",
            "                    fields={\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([10, 10, 13, 9, 9]), device=cpu, dtype=torch.float64, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([10, 10, 1, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([10, 10]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 10]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False)},\n",
            "            batch_size=torch.Size([10, 10]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10, 10]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-70ddfc915bdb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m \u001b[0mcheck_env_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/utils.py\u001b[0m in \u001b[0;36mcheck_env_specs\u001b[0;34m(env, return_contiguous, check_dtype, seed, tensordict)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0mfake_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_tensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m     real_tensordict = env.rollout(\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mreturn_contiguous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_contiguous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[0m\n\u001b[1;32m   3129\u001b[0m         }\n\u001b[1;32m   3130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbreak_when_any_done\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3131\u001b[0;31m             tensordicts = self._rollout_stop_early(\n\u001b[0m\u001b[1;32m   3132\u001b[0m                 \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m                 \u001b[0mbreak_when_any_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbreak_when_any_done\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m_rollout_stop_early\u001b[0;34m(self, break_when_any_done, break_when_all_done, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[0m\n\u001b[1;32m   3270\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3271\u001b[0m                     \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_device_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3272\u001b[0;31m             \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3273\u001b[0m             \u001b[0mtd_append\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1974\u001b[0;31m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_proc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext_preset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m             \u001b[0;31m# tensordict could already have a \"next\" key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m_step_proc_data\u001b[0;34m(self, next_tensordict_out)\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 ]\n\u001b[1;32m   2066\u001b[0m             )\n\u001b[0;32m-> 2067\u001b[0;31m             \u001b[0mactual_reward_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2068\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mactual_reward_shape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_reward_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m                 \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_reward_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa7225f",
      "metadata": {
        "id": "caa7225f"
      },
      "source": [
        "# Launch from command line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30075032",
      "metadata": {
        "id": "30075032"
      },
      "source": [
        "To launch an experiment from the command line you can do"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5369898f",
      "metadata": {
        "scrolled": false,
        "id": "5369898f"
      },
      "outputs": [],
      "source": [
        "!python benchmarl/run.py algorithm=mappo task=vmas/balance experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23f9338f",
      "metadata": {
        "id": "23f9338f"
      },
      "source": [
        "You can run benchmarks as multi-runs like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90a135ea",
      "metadata": {
        "scrolled": false,
        "id": "90a135ea"
      },
      "outputs": [],
      "source": [
        "!python benchmarl/run.py -m algorithm=mappo,qmix,masac task=vmas/balance,vmas/sampling seed=0,1 experiment.max_n_iters=2 \"experiment.loggers=[]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b01091a",
      "metadata": {
        "id": "0b01091a"
      },
      "source": [
        "# Launch from a python script"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c6dc69",
      "metadata": {
        "id": "67c6dc69"
      },
      "source": [
        "You can also load and launch your experiments from within a script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c5b5fcd",
      "metadata": {
        "id": "2c5b5fcd"
      },
      "outputs": [],
      "source": [
        "from benchmarl.algorithms import MappoConfig\n",
        "from benchmarl.environments import VmasTask\n",
        "from benchmarl.experiment import Experiment, ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas/balance.yaml\"\n",
        "task = VmasTask.BALANCE.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/algorithm/mappo.yaml\"\n",
        "algorithm_config = MappoConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/model/layers/mlp.yaml\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "experiment = Experiment(\n",
        "    task=task,\n",
        "    algorithm_config=algorithm_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        "    seed=0,\n",
        "    config=experiment_config,\n",
        ")\n",
        "experiment.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20864e3",
      "metadata": {
        "id": "a20864e3"
      },
      "source": [
        "You can also run multiple experiments in a Benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec3bd4b",
      "metadata": {
        "id": "6ec3bd4b"
      },
      "outputs": [],
      "source": [
        "from benchmarl.algorithms import MappoConfig, MasacConfig, QmixConfig\n",
        "from benchmarl.benchmark import Benchmark\n",
        "from benchmarl.environments import VmasTask\n",
        "from benchmarl.experiment import ExperimentConfig\n",
        "from benchmarl.models.mlp import MlpConfig\n",
        "\n",
        "# Loads from \"benchmarl/conf/experiment/base_experiment.yaml\"\n",
        "experiment_config = ExperimentConfig.get_from_yaml()\n",
        "# Loads from \"benchmarl/conf/task/vmas\"\n",
        "tasks = [VmasTask.BALANCE.get_from_yaml(), VmasTask.SAMPLING.get_from_yaml()]\n",
        "# Loads from \"benchmarl/conf/algorithm\"\n",
        "algorithm_configs = [\n",
        "    MappoConfig.get_from_yaml(),\n",
        "    QmixConfig.get_from_yaml(),\n",
        "    MasacConfig.get_from_yaml(),\n",
        "]\n",
        "# Loads from \"benchmarl/conf/model/layers\"\n",
        "model_config = MlpConfig.get_from_yaml()\n",
        "critic_model_config = MlpConfig.get_from_yaml()\n",
        "\n",
        "experiment_config.max_n_iters = 2\n",
        "experiment_config.loggers = []\n",
        "\n",
        "benchmark = Benchmark(\n",
        "    algorithm_configs=algorithm_configs,\n",
        "    tasks=tasks,\n",
        "    seeds={0, 1},\n",
        "    experiment_config=experiment_config,\n",
        "    model_config=model_config,\n",
        "    critic_model_config=critic_model_config,\n",
        ")\n",
        "benchmark.run_sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good good good"
      ],
      "metadata": {
        "id": "4vgM3nzdZcKr"
      },
      "id": "4vgM3nzdZcKr"
    },
    {
      "source": [
        "from torchrl.envs import GymEnv\n",
        "from torchrl.envs import set_gym_backend\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict as TypingDict, Any, Union, List, Optional\n",
        "from torchrl.envs import EnvBase, TransformedEnv\n",
        "from torchrl.data import CompositeSpec, BoundedTensorSpec, DiscreteTensorSpec, UnboundedContinuousTensorSpec\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "from torchrl.envs.utils import check_env_specs\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "import os  # Import os for file existence check\n",
        "from typing import Dict, List  # Import Dict and List here\n",
        "from torchrl.envs.transforms import RewardSum  # changed the location of the import\n",
        "from torchrl.envs import EnvBase\n",
        "from torchrl.data import Unbounded, Composite, Bounded, Binary\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "import tensordict\n",
        "\n",
        "class DDataenv:\n",
        "    def __init__(self, data_path: str, data_columns: List[str], data_type: Any = np.float32):\n",
        "        self.data_path = data_path\n",
        "        self.data_columns = data_columns\n",
        "        self.data_type = data_type\n",
        "        self.data = None\n",
        "\n",
        "    def load_data(self) -> pd.DataFrame:\n",
        "        if not os.path.exists(self.data_path):\n",
        "            raise FileNotFoundError(f\"Data file not found at {self.data_path}\")\n",
        "\n",
        "        with open(self.data_path, 'rb') as f:\n",
        "            self.data = torch.load(f, weights_only=False)\n",
        "\n",
        "        self.data = np.array(self.data)\n",
        "        if len(self.data.shape) >= 3:\n",
        "            self.data = self.data.reshape(self.data.shape[1], self.data.shape[2])\n",
        "\n",
        "        if not isinstance(self.data, pd.DataFrame):\n",
        "            self.data = pd.DataFrame(self.data, columns=self.data_columns)\n",
        "\n",
        "        return self.data\n",
        "\n",
        "    def get_observation(self) -> TypingDict[str, Union[np.ndarray, TypingDict[str, float]]]:\n",
        "        if self.data is None:\n",
        "            self.load_data()\n",
        "\n",
        "        random_row_index = np.random.choice(self.data.shape[0], 1, replace=False)[0]\n",
        "        observation = self.data.iloc[random_row_index, :].to_numpy().astype(self.data_type)\n",
        "        describe_data = self.data.describe()\n",
        "\n",
        "        observation_dict = {\n",
        "            'obsState&Fuel': observation[0:13],\n",
        "            'Date': observation[-1],\n",
        "            'rewardState&reward': observation[13:26],\n",
        "            'actionState&action': observation[26:39],\n",
        "            'obsState&Fuel_max': describe_data.loc['max'][0:13].values,\n",
        "            'obsState&Fuel_min': describe_data.loc['min'][0:13].values,\n",
        "            'Date_max': describe_data['Date'].max(),\n",
        "            'Date_min': describe_data['Date'].min(),\n",
        "            'rewardState&reward_max': describe_data.loc['max'][13:26].values,\n",
        "            'rewardState&reward_min': describe_data.loc['min'][13:26].values,\n",
        "            'actionState&action_max': describe_data.loc['max'][26:39].values,\n",
        "            'actionState&action_min': describe_data.loc['min'][26:39].values,\n",
        "        }\n",
        "        return observation_dict\n",
        "\n",
        "\n",
        "def _step(tensordict):\n",
        "    td = env.gen_params(env.batch_size)\n",
        "    n_agents = env.n_agents\n",
        "\n",
        "    # Initialize a dictionary to store agent data\n",
        "    agents = {f\"agent_{i}\": {} for i in range(env.n_agents)}\n",
        "\n",
        "    for i in range(n_agents):\n",
        "\n",
        "        # Initialize lists to store data for each agent within the batch\n",
        "        agent_i_date = []\n",
        "        agent_i_action = []\n",
        "        agent_i_rew = []\n",
        "        agent_i_new_obs = []\n",
        "        agent_i_date2 = []\n",
        "        agent_i_action2 = []\n",
        "        agent_i_rew2 = []\n",
        "        agent_i_new_obs2 = []\n",
        "\n",
        "        for _ in range(env.convo_dim[0]):\n",
        "            td = env.gen_params(env.batch_size)\n",
        "            obs = td['params', 'obsState&Fuel'].clone().detach()\n",
        "            reward = td['params', 'rewardState&reward'].clone().detach()\n",
        "            action = td['params', 'actionState&action'].clone().detach()\n",
        "            Date = td['params', 'Date'].clone().detach()\n",
        "\n",
        "            new_obs = torch.add(obs, torch.stack([action_i * reward_i for action_i, reward_i in zip(action, reward)]))\n",
        "            new_obs = torch.reshape(new_obs, (13,))\n",
        "\n",
        "            # Append data to agent-specific lists\n",
        "            agent_i_new_obs.append(new_obs)\n",
        "            agent_i_rew.append(reward)\n",
        "            agent_i_date.append(Date)\n",
        "            agent_i_action.append(action)\n",
        "\n",
        "\n",
        "        # Stack data for the current agent\n",
        "        en_Date = torch.stack(agent_i_date, dim=-1) if agent_i_date else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        en_action = torch.stack(agent_i_action, dim=-1) if agent_i_action else torch.empty(env.batch_size, 13, device=env.device)\n",
        "        en_reward = torch.stack(agent_i_rew, dim=-1) if agent_i_rew else torch.empty(env.batch_size, 13, device=env.device)  # Check if agent_i_rew is empty\n",
        "        en_new_obs = torch.stack(agent_i_new_obs, dim=-1) if agent_i_new_obs else torch.empty(env.batch_size, 13, device=env.device)\n",
        "\n",
        "        for _  in range(env.convo_dim[1]):\n",
        "           agent_i_new_obs2.append(en_new_obs)\n",
        "           agent_i_rew2.append(en_reward)\n",
        "           agent_i_date2.append(en_Date)\n",
        "           agent_i_action2.append(en_action)\n",
        "\n",
        "        en_Date2 = torch.stack(agent_i_date2, dim=-1)\n",
        "        en_action2 = torch.stack(agent_i_action2, dim=-1)\n",
        "        en_reward2 = torch.stack(agent_i_rew2, dim=-1)\n",
        "        en_new_obs2 = torch.stack(agent_i_new_obs2, dim=-1)\n",
        "\n",
        "\n",
        "        # Expansion for batch size\n",
        "        expanded_agent_Date = en_Date2.reshape( 1, 1,*en_Date2.shape).expand(tuple(env.batch_size) + (en_Date.shape[-1], *env.convo_dim))\n",
        "        expanded_agent_new_obs = en_new_obs2.reshape(1, 1,*en_new_obs2.shape ).expand(tuple(env.batch_size) + (13, *env.convo_dim))\n",
        "        expanded_agent_reward = en_reward2.reshape(1, 1,*en_reward2.shape, ).expand(tuple(env.batch_size) + (13, *env.convo_dim)) # Modified\n",
        "        expanded_agent_action = en_action2.reshape( 1, 1,*en_new_obs2.shape,).expand(tuple(env.batch_size) + (13, *env.convo_dim))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Store data in agent-specific dictionary\n",
        "        agents[f\"agent_{i}\"][\"observation\"] = {\"observat\": expanded_agent_new_obs.unsqueeze(2), \"position_key\": expanded_agent_Date.unsqueeze(2)}\n",
        "        # Ensure 'reward' is under the \"agents\" key\n",
        "        agents[f\"agent_{i}\"][\"reward\"] = expanded_agent_reward\n",
        "        # Change reward calculation here\n",
        "        episode_reward = torch.sum(expanded_agent_reward, dim=2, keepdim=True)  # Modified\n",
        "\n",
        "        agents[f\"agent_{i}\"][\"action\"] = expanded_agent_action\n",
        "\n",
        "        if agents[f\"agent_{i}\"][\"reward\"].numel() == 0:\n",
        "           agents[f\"agent_{i}\"][\"reward\"] = torch.zeros(1, device=env.device)\n",
        "\n",
        "\n",
        "\n",
        "    ttd_action = TensorDict(\n",
        "        {\n",
        "           f\"agent_{i}\": {\n",
        "                    \"action\": agents[f\"agent_{i}\"][\"action\"],  # Access action from agent dictionary\n",
        "                }\n",
        "                for i in range(env.n_agents)\n",
        "            },\n",
        "\n",
        "        batch_size=env.batch_size,\n",
        "        device=env.device,\n",
        "    )\n",
        "\n",
        "    reward_vector = torch.zeros(13, device=env.device, dtype=torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "    dones = torch.zeros((*env.batch_size, 1), dtype=torch.bool)\n",
        "\n",
        "    next_tensordict = TensorDict(\n",
        "              {\n",
        "                      {f\"agent_{i}\": {\n",
        "                          \"reward\": agents[f\"agent_{i}\"][\"reward\"],\n",
        "                          \"observation\": agents[f\"agent_{i}\"][\"observation\"],\n",
        "                          \"action\": agents[f\"agent_{i}\"][\"action\"] ,\n",
        "                          \"episode_reward\": episode_reward,\n",
        "\n",
        "                       } for i in range(env.n_agents)\n",
        "                       },\n",
        "                      \"terminated\":dones\n",
        "              },\n",
        "                batch_size=env.batch_size, device=env.device)\n",
        "\n",
        "    print(\"Output TensorDict from _step:\", next_tensordict)  # Add this line for debugging\n",
        "    return next_tensordict\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\" agent = {f\"agent_{i}\": {} for i in range(env.n_agents)}\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _reset(self, tensordict=None):\n",
        "    if tensordict is not None and \"_reset\" not in tensordict:\n",
        "        tensordict.clear()\n",
        "    else:\n",
        "        tensordict = TensorDict({}, batch_size=self.batch_size, device=self.device)\n",
        "\n",
        "        td = self.gen_params(self.batch_size)\n",
        "\n",
        "        obs_max = td['params', 'obsState&Fuel_max'].clone().detach()\n",
        "        obs_min = td['params', 'obsState&Fuel_min'].clone().detach()\n",
        "        Date = td['params', 'Date_max'].clone().detach()\n",
        "\n",
        "        n_agents = self.n_agents\n",
        "\n",
        "        # Create a dictionary to store agent data\n",
        "        agent_data = {f\"agent_{i}\": {} for i in range(n_agents)}\n",
        "\n",
        "        for i in range(n_agents):\n",
        "            random_numbers = torch.rand(1, device=self.device)\n",
        "            obs = torch.add(torch.mul(random_numbers, torch.add(obs_max, -obs_min)), obs_min)\n",
        "            Date = td['params', 'Date_max'].clone().detach()\n",
        "\n",
        "           #obs = obs.reshape(tuple(self.batch_size) + (13,))\n",
        "           # Date = Date.reshape(tuple(self.batch_size) + (1,))\n",
        "\n",
        "            # Expand to include batch size\n",
        "            expanded_obs = obs.unsqueeze(-1).unsqueeze(-1).expand(tuple(self.batch_size) + (13, *self.convo_dim))\n",
        "            expanded_Date = Date.unsqueeze(-1).unsqueeze(-1).expand(tuple(self.batch_size) + (1, *self.convo_dim))\n",
        "\n",
        "            # Store data in the agent_data dictionary\n",
        "            agent_data[f\"agent_{i}\"][\"observation\"] = {\n",
        "                \"observat\": expanded_obs.unsqueeze(2),\n",
        "                \"position_key\": expanded_Date.unsqueeze(2),\n",
        "            }\n",
        "\n",
        "        # Create the tensordict with agent data\n",
        "        expanded_agent_observations = TensorDict(\n",
        "            {\"agents\": agent_data},\n",
        "            batch_size=self.batch_size,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        dones = torch.zeros((*self.batch_size, 1), dtype=torch.bool, device=self.device)\n",
        "\n",
        "        # Construct the final tensordict\n",
        "        return TensorDict(\n",
        "            {\n",
        "                **expanded_agent_observations,  # Include agent data\n",
        "                \"terminated\": dones.clone()\n",
        "            },\n",
        "            batch_size=self.batch_size,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "\n",
        "def make_composite_from_td(td):\n",
        "    composite = CompositeSpec(\n",
        "        {\n",
        "            key: make_composite_from_td(tensor)\n",
        "            if isinstance(tensor, TensorDictBase)\n",
        "            else UnboundedContinuousTensorSpec(\n",
        "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
        "            )\n",
        "            for key, tensor in td.items()\n",
        "        },\n",
        "        shape=td.shape,\n",
        "    )\n",
        "    return composite\n",
        "\n",
        "\n",
        "def _make_spec(self, td_agents):\n",
        "    action_specs = []\n",
        "    observation_specs = []\n",
        "    reward_specs = []\n",
        "    Info_specs = []\n",
        "\n",
        "    td_agents = self.gen_params(self)  # Or td_agents = self.gen_params() if no batch size is needed\n",
        "    agent = {f\"agent_{i}\": {} for i in range(self.n_agents)}\n",
        "\n",
        "    obs_max = td_agents['params', 'obsState&Fuel_max'].clone().detach()\n",
        "    obs_min = td_agents['params', 'obsState&Fuel_min'].clone().detach()\n",
        "    reward_max = td_agents['params', 'rewardState&reward_max'].clone().detach()\n",
        "    reward_min = td_agents['params', 'rewardState&reward_min'].clone().detach()\n",
        "    action_max = td_agents['params', 'actionState&action_max'].clone().detach()\n",
        "    action_min = td_agents['params', 'actionState&action_min'].clone().detach()\n",
        "    Date_max = td_agents['params', 'Date_max'].clone().detach()\n",
        "    Date_min = td_agents['params', 'Date_min'].clone().detach()\n",
        "\n",
        "    # Reshape the tensors to (n_agents, 13, *convo_dim) before the loop\n",
        "    # Assuming obs_max, obs_min, reward_max, reward_min, action_max, action_min have shape (13,)\n",
        "    # and Date_max, Date_min have shape (1,)\n",
        "\n",
        "    # Reshape tensors before expanding\n",
        "    obs_max = obs_max.reshape(1, 13, 1, 1).expand(1, 13, *self.convo_dim)\n",
        "    obs_min = obs_min.reshape(1, 13, 1, 1).expand(1, 13, *self.convo_dim)\n",
        "    reward_max = reward_max.reshape(1, 13, 1, 1).expand(1, 13, *self.convo_dim)\n",
        "    reward_min = reward_min.reshape(1, 13, 1, 1).expand(1, 13, *self.convo_dim)\n",
        "    action_max = action_max.reshape(1, 13, 1, 1).expand(1, 13, *self.convo_dim)\n",
        "    action_min = action_min.reshape(1, 13, 1, 1).expand(1, 13, *self.convo_dim)\n",
        "    Date_max = Date_max.reshape(1, 1, 1, 1).expand(1, 1, *self.convo_dim)\n",
        "    Date_min = Date_min.reshape(1, 1, 1, 1).expand(1, 1, *self.convo_dim)\n",
        "\n",
        "    # print(obs_max.shape)\n",
        "    # print(obs_min.shape)\n",
        "    # print(reward_max.shape)\n",
        "    # print(reward_min.shape)\n",
        "    # print(action_max.shape)\n",
        "    # print(action_min.shape)\n",
        "\n",
        "    for i in range(self.n_agents):\n",
        "        # Creating action, reward, observation, and date specs for each agent\n",
        "\n",
        "        agent_i_reward_spec = BoundedTensorSpec(low=reward_min[i], high=reward_max[i],\n",
        "                                               shape=reward_max[i].shape, dtype=torch.float32)\n",
        "        reward_i_value_low = torch.sum(agent_i_reward_spec.low, dim=0).unsqueeze(0)\n",
        "            # .reshape(tuple((1,) + tuple(self.convo_dim)))\n",
        "\n",
        "        reward_i_value_high = torch.sum(agent_i_reward_spec.high, dim=0).unsqueeze(0)\n",
        "            # .reshape(tuple((1,) + tuple(self.convo_dim)))\n",
        "        # Modification here to fix error\n",
        "        agent_i_reward_spec = BoundedTensorSpec(low=reward_i_value_low, high=reward_i_value_high,\n",
        "                                               shape=reward_i_value_low.shape, dtype=torch.float32)\n",
        "\n",
        "        agent_i_action_spec = DiscreteTensorSpec(n=3, shape=action_max[i].shape, dtype=torch.int32)\n",
        "        agent_i_observat_spec = BoundedTensorSpec(low=obs_min[i], high=obs_max[i], shape=obs_max[i].shape,\n",
        "                                                 dtype=torch.float32)\n",
        "        agent_i_Date_spec = BoundedTensorSpec(low=Date_min[i], high=Date_max[i], shape=Date_max[i].shape,\n",
        "                                             dtype=torch.float32)\n",
        "\n",
        "        agent_i_observation_spec = CompositeSpec(\n",
        "            observat=agent_i_observat_spec.unsqueeze(0),\n",
        "            position_key=agent_i_Date_spec.unsqueeze(0),\n",
        "        )\n",
        "\n",
        "        reward_specs.append(agent_i_reward_spec)\n",
        "        observation_specs.append(agent_i_observation_spec)\n",
        "        action_specs.append(agent_i_action_spec)\n",
        "        Info_specs.append(agent_i_Date_spec)\n",
        "        #print(agent_i_action_spec)\n",
        "\n",
        "    # Assuming all agents have the same action and reward specs\n",
        "    # action_spec_shape = action_specs[0].shape  # Get the shape from the first agent\n",
        "    # reward_spec_shape = reward_specs[0].shape  # Get the shape from the first agent\n",
        "    # observation_spec_shape = observation_specs[0].shape\n",
        "    self.done_spec_unbatched = DiscreteTensorSpec(n=2, shape=torch.Size([1]), dtype=torch.bool).to(self.device)\n",
        "    self.reward_spec_unbatched = CompositeSpec(\n",
        "        {\n",
        "            \"agents\": CompositeSpec(\n",
        "                {\"reward\": reward_specs[0]},\n",
        "                shape=(1,)  # Changed to concatenate tuples\n",
        "            )\n",
        "        }\n",
        "    )\n",
        "    self.observation_spec_unbatched = CompositeSpec(\n",
        "        {\n",
        "            \"agents\": CompositeSpec(\n",
        "                {\"observation\": observation_specs[0]},\n",
        "                shape=(1,)  # Changed to concatenate tuples\n",
        "            )\n",
        "        }\n",
        "    )\n",
        "    self.action_spec_unbatched = CompositeSpec(\n",
        "        {\n",
        "            \"agents\": CompositeSpec(\n",
        "                {\"action\": action_specs[0]},\n",
        "                shape=action_max[i].shape\n",
        "            )\n",
        "        }\n",
        "    )\n",
        "\n",
        "    self.full_state_spec = self.observation_spec_unbatched.expand(self.batch_size).to(self.device)\n",
        "    # self.observation_spec = self.observation_spec_unbatched.expand(self.batch_size_tuple).to(self.device)\n",
        "    self.full_done_spec = self.done_spec_unbatched.expand(self.batch_size_tuple).to(self.device)\n",
        "    # Fix to resolve the AttributeError\n",
        "    self.full_reward_spec = self.reward_spec_unbatched.expand(self.batch_size + reward_i_value_low.shape).to(self.device)  # Modified\n",
        "    self.full_action_spec = self.action_spec_unbatched.expand(self.batch_size + (13, 9, 9)).to(self.device)\n",
        "\n",
        "    #print(self.reward_spec.shape)\n",
        "    #print(self.action_spec.shape)\n",
        "    #print(self.observation_spec.shape)\n",
        "    #print(self.done_spec.shape)\n",
        "\n",
        "\n",
        "def gen_params(batch_size=torch.Size()) -> TensorDictBase:\n",
        "    if batch_size is None or (isinstance(batch_size, list) and len(batch_size) == 0):\n",
        "        batch_size = torch.Size([])\n",
        "    data_path = '/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/DataDic.pt'\n",
        "    data_columns = ['Forex', 'WTI', 'Brent', 'OPEC', 'Fuelprice5', 'Fuelprice6', 'Fuelprice7', 'Fuelprice8',\n",
        "                    'Fuelprice9', 'Fuelprice10', 'Fuelprice11', 'Fuelprice12', 'Fuelprice13',\n",
        "                    'reward0', 'reward1', 'reward2', 'reward3', 'reward4', 'reward5', 'reward6', 'reward7', 'reward8',\n",
        "                    'reward9', 'reward10', 'reward11', 'reward12',\n",
        "                    'action0', 'action1', 'action2', 'action3', 'action4', 'action5', 'action6', 'action7', 'action8',\n",
        "                    'action9', 'action10', 'action11', 'action12', 'Date']\n",
        "    envv = DDataenv(data_path, data_columns)  # Assuming DDataenv is your data environment class\n",
        "\n",
        "    ac = envv.get_observation()\n",
        "\n",
        "    if batch_size:\n",
        "        # Change here: Convert batch_size to a tuple if it's not already\n",
        "        if not isinstance(batch_size, tuple):\n",
        "            batch_size = (batch_size,)  # Convert to tuple\n",
        "        ac = {k: torch.tensor(v).expand(*batch_size, *torch.tensor(v).shape) for k, v in ac.items()}\n",
        "\n",
        "    td = TensorDict({\"params\": ac}, batch_size=batch_size,\n",
        "                    device=torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    if batch_size:\n",
        "        td = td.expand(batch_size).contiguous()\n",
        "    return td\n",
        "\n",
        "\n",
        "def _set_seed(self, seed: 45):\n",
        "    self.rng = torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "def full_info_spec(self):\n",
        "    return {}\n",
        "\n",
        "\n",
        "def group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "    return {\"agents\": [agent[\"name\"] for agent in env.agents]}\n",
        "\n",
        "\n",
        "class AnFuelpriceEnv(EnvBase):\n",
        "    metadata = {\n",
        "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
        "        \"render_fps\": 30,\n",
        "    }\n",
        "    Scenario = \"USDATA_1\"\n",
        "    batch_locked = False\n",
        "\n",
        "    def __init__(self, td_params=None, seed=None, device=\"cpu\", categorical_actions=True, continuous_actions=True, **kwargs):\n",
        "        if td_params is None:\n",
        "            td_params = gen_params()\n",
        "\n",
        "\n",
        "        _ = kwargs.pop(\"scenario\", None)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.n_agents =1\n",
        "        self.convo_dim = [9, 9]\n",
        "        self.batch_size = (9, 9)  # Corrected batch size to a single-element tuple\n",
        "        self.batch_size_tuple = torch.Size([self.batch_size]) if isinstance(self.batch_size,\n",
        "                                                                            int) else torch.Size(self.batch_size)\n",
        "\n",
        "        super().__init__(device=device, batch_size=self.batch_size, )\n",
        "\n",
        "        self._make_spec(td_params)\n",
        "\n",
        "        if seed is None:\n",
        "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
        "        self.set_seed(seed)\n",
        "\n",
        "    def gen_params(self, batch_size=None):\n",
        "        return gen_params(batch_size)\n",
        "\n",
        "\n",
        "    def get_supports_continuous_actions(self):\n",
        "        return hasattr(env.full_action_spec, 'shape') and len(env.full_action_spec.shape) > 0\n",
        "\n",
        "    def get_supports_discrete_actions(self):\n",
        "        return isinstance(env.full_action_spec, DiscreteTensorSpec)\n",
        "\n",
        "    def get_observation_spec(self):\n",
        "        return self.observation_spec\n",
        "\n",
        "    def get_full_action_spec(self):\n",
        "        return self.full_action_spec\n",
        "\n",
        "    def get_full_reward_spec(self):\n",
        "        return self.full_reward_spec\n",
        "\n",
        "    def get_done_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    def get_group_map(self, env: EnvBase) -> Dict[str, List[str]]:\n",
        "        return {\"agents\": [agent[\"name\"] for agent in env.agents]}\n",
        "\n",
        "    def get_full_info_spec(self):\n",
        "        return {}\n",
        "\n",
        "    def get_discount_spec(self):\n",
        "        return self.discount_spec\n",
        "\n",
        "    @property\n",
        "    def terminated_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    @property\n",
        "    def truncated_spec(self):\n",
        "        return self.done_spec\n",
        "\n",
        "    @property\n",
        "    def get_env_name(self):\n",
        "        return \"AnFuelpriceEnv\"\n",
        "\n",
        "    gen_params = staticmethod(gen_params)\n",
        "    _make_spec = _make_spec\n",
        "    _reset = _reset\n",
        "    _step = staticmethod(_step)\n",
        "    _set_seed = _set_seed\n",
        "    full_info_spec = full_info_spec\n",
        "\n",
        "\n",
        "env = AnFuelpriceEnv()\n",
        "print(\"\\n*action_spec:\", env.full_action_spec)\n",
        "print(\"\\n*reward_spec:\", env.full_reward_spec)\n",
        "print(\"\\n*done_spec:\", env.full_done_spec)\n",
        "print(\"\\n*observation_spec:\", env.observation_spec)\n",
        "\n",
        "print(\"\\n-action_keys:\", env.action_keys)\n",
        "print(\"\\n-reward_keys:\", env.reward_keys)\n",
        "print(\"\\n-done_keys:\", env.done_keys)\n",
        "\n",
        "print(\"input_spec:\", env.input_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "print(\"action_spec (as defined by input_spec):\", env.action_spec)\n",
        "td = env.reset()\n",
        "print(\"reset tensordict\", td)\n",
        "\n",
        "\n",
        "\n",
        "check_env_specs(env)\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "moOGczpASp9T",
        "outputId": "76f157ea-b04d-487d-92d8-7067b9c98bdb"
      },
      "id": "moOGczpASp9T",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-145-b896793c20bd>, line 176)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-145-b896793c20bd>\"\u001b[0;36m, line \u001b[0;32m176\u001b[0m\n\u001b[0;31m    \"terminated\":dones\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.rollout(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "MVZ2Fn3y7J9_",
        "outputId": "90db35df-a7b5-41d9-e368-caf71da849f0"
      },
      "id": "MVZ2Fn3y7J9_",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output TensorDict from _step: TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                agent_0: TensorDict(\n",
            "                    fields={\n",
            "                        action: Tensor(shape=torch.Size([9, 9, 13, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([9, 9, 1, 13, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([9, 9, 1, 9, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([9, 9]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False),\n",
            "                        reward: Tensor(shape=torch.Size([9, 9, 13, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                    batch_size=torch.Size([9, 9]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False)},\n",
            "            batch_size=torch.Size([9, 9]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([9, 9, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([9, 9]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-66e52b62149c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[0m\n\u001b[1;32m   3129\u001b[0m         }\n\u001b[1;32m   3130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbreak_when_any_done\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3131\u001b[0;31m             tensordicts = self._rollout_stop_early(\n\u001b[0m\u001b[1;32m   3132\u001b[0m                 \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m                 \u001b[0mbreak_when_any_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbreak_when_any_done\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m_rollout_stop_early\u001b[0;34m(self, break_when_any_done, break_when_all_done, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[0m\n\u001b[1;32m   3270\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3271\u001b[0m                     \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_device_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3272\u001b[0;31m             \u001b[0mtensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3273\u001b[0m             \u001b[0mtd_append\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbreak_when_all_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1974\u001b[0;31m         \u001b[0mnext_tensordict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_proc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tensordict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext_preset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m             \u001b[0;31m# tensordict could already have a \"next\" key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchrl/envs/common.py\u001b[0m in \u001b[0;36m_step_proc_data\u001b[0;34m(self, next_tensordict_out)\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 ]\n\u001b[1;32m   2066\u001b[0m             )\n\u001b[0;32m-> 2067\u001b[0;31m             \u001b[0mactual_reward_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2068\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mactual_reward_shape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_reward_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m                 \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_reward_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ghhg=_step(tensordict)\n",
        "print(ghhg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr11f2VbKWDp",
        "outputId": "f2648d41-849e-42af-eabf-f12130428756"
      },
      "id": "Xr11f2VbKWDp",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output TensorDict from _step: TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                agent_0: TensorDict(\n",
            "                    fields={\n",
            "                        action: Tensor(shape=torch.Size([9, 9, 13, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([9, 9, 1, 13, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([9, 9, 1, 9, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([9, 9]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False),\n",
            "                        reward: Tensor(shape=torch.Size([9, 9, 13, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                    batch_size=torch.Size([9, 9]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False)},\n",
            "            batch_size=torch.Size([9, 9]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([9, 9, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([9, 9]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n",
            "TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                agent_0: TensorDict(\n",
            "                    fields={\n",
            "                        action: Tensor(shape=torch.Size([9, 9, 13, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                        observation: TensorDict(\n",
            "                            fields={\n",
            "                                observat: Tensor(shape=torch.Size([9, 9, 1, 13, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                                position_key: Tensor(shape=torch.Size([9, 9, 1, 9, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                            batch_size=torch.Size([9, 9]),\n",
            "                            device=cpu,\n",
            "                            is_shared=False),\n",
            "                        reward: Tensor(shape=torch.Size([9, 9, 13, 9, 9]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                    batch_size=torch.Size([9, 9]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False)},\n",
            "            batch_size=torch.Size([9, 9]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([9, 9, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([9, 9]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torchrl.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSPRqyiInuPr",
        "outputId": "ba936ca5-afc4-4e10-b380-367cbbe031b3"
      },
      "id": "qSPRqyiInuPr",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C0zAL7w4YICi"
      },
      "id": "C0zAL7w4YICi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VEta6dQM5mve"
      },
      "id": "VEta6dQM5mve"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}